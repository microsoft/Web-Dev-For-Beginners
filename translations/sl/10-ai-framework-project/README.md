<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2c4ae5688e34b4b8b09d52aec56c79e",
  "translation_date": "2025-10-25T00:27:30+00:00",
  "source_file": "10-ai-framework-project/README.md",
  "language_code": "sl"
}
-->
# Okvir za umetno inteligenco

Ste se kdaj po캜utili preobremenjeni, ko ste posku코ali zgraditi aplikacije z umetno inteligenco od za캜etka? Niste edini! Okviri za umetno inteligenco so kot 코vicarski no za razvoj AI - mo캜na orodja, ki vam lahko prihranijo 캜as in glavobole pri gradnji inteligentnih aplikacij. Pomislite na AI okvir kot na dobro organizirano knji쬹ico: ponuja vnaprej pripravljene komponente, standardizirane API-je in pametne abstrakcije, da se lahko osredoto캜ite na re코evanje te쬬v namesto na podrobnosti implementacije.

V tej lekciji bomo raziskali, kako lahko okviri, kot je LangChain, spremenijo neko캜 zapletene naloge integracije AI v 캜isto, berljivo kodo. Odkrijte, kako se spopasti z izzivi iz resni캜nega sveta, kot so sledenje pogovorom, izvajanje klicev orodij in upravljanje razli캜nih modelov AI prek enotnega vmesnika.

Ko bomo kon캜ali, boste vedeli, kdaj uporabiti okvire namesto surovih API klicev, kako u캜inkovito uporabljati njihove abstrakcije in kako zgraditi AI aplikacije, ki so pripravljene za uporabo v resni캜nem svetu. Raziskujmo, kaj lahko AI okviri naredijo za va코e projekte.

## Zakaj izbrati okvir?

Torej, pripravljeni ste zgraditi AI aplikacijo - super! Ampak tukaj je stvar: imate ve캜 razli캜nih poti, po katerih lahko greste, in vsaka ima svoje prednosti in slabosti. To je nekako tako, kot da bi izbirali med hojo, kolesarjenjem ali vo쬹jo, da pridete nekam - vse vas bodo pripeljale tja, vendar bo izku코nja (in trud) popolnoma druga캜na.

Raz캜lenimo tri glavne na캜ine, kako lahko vklju캜ite AI v svoje projekte:

| Pristop | Prednosti | Najbolj primerno za | Premisleki |
|---------|-----------|---------------------|------------|
| **Neposredni HTTP zahtevki** | Popoln nadzor, brez odvisnosti | Enostavna vpra코anja, u캜enje osnov | Bolj obse쬹a koda, ro캜no obravnavanje napak |
| **Integracija SDK** | Manj osnovne kode, optimizacija za specifi캜ne modele | Aplikacije z enim modelom | Omejeno na specifi캜ne ponudnike |
| **AI okviri** | Enoten API, vgrajene abstrakcije | Aplikacije z ve캜 modeli, kompleksni delovni tokovi | Krivulja u캜enja, mo쬹a pretirana abstrakcija |

### Prednosti okvirov v praksi

```mermaid
graph TD
    A[Your Application] --> B[AI Framework]
    B --> C[OpenAI GPT]
    B --> D[Anthropic Claude]
    B --> E[GitHub Models]
    B --> F[Local Models]
    
    B --> G[Built-in Tools]
    G --> H[Memory Management]
    G --> I[Conversation History]
    G --> J[Function Calling]
    G --> K[Error Handling]
```

**Zakaj so okviri pomembni:**
- **Zdru쬿jejo** ve캜 AI ponudnikov pod enoten vmesnik
- **Samodejno upravljajo** spomin pogovorov
- **Ponujajo** vnaprej pripravljena orodja za obi캜ajne naloge, kot so vdelave in klicanje funkcij
- **Upravljajo** obravnavanje napak in logiko ponovnih poskusov
- **Pretvarjajo** kompleksne delovne tokove v berljive metode

> 游눠 **Nasvet**: Uporabite okvire, ko preklapljate med razli캜nimi AI modeli ali gradite kompleksne funkcije, kot so agenti, spomin ali klicanje orodij. Dr쬴te se neposrednih API-jev, ko se u캜ite osnov ali gradite preproste, osredoto캜ene aplikacije.

**Zaklju캜ek**: Tako kot izbira med specializiranimi orodji obrtnika in celotno delavnico gre za ujemanje orodja z nalogo. Okviri so odli캜ni za kompleksne, bogate z zna캜ilnostmi aplikacije, medtem ko neposredni API-ji dobro delujejo za enostavne primere uporabe.

## Uvod

V tej lekciji se bomo nau캜ili:

- Uporabiti skupni AI okvir.
- Re코evati obi캜ajne te쬬ve, kot so pogovori, uporaba orodij, spomin in kontekst.
- To izkoristiti za gradnjo AI aplikacij.

## Va코 prvi AI poziv

Za캜nimo z osnovami tako, da ustvarimo va코o prvo AI aplikacijo, ki po코lje vpra코anje in prejme odgovor. Tako kot je Arhimed odkril princip izpodrivanja v svoji kopeli, v캜asih najpreprostej코a opa쬬nja vodijo do najmo캜nej코ih spoznanj - in okviri omogo캜ajo dostop do teh spoznanj.

### Nastavitev LangChain z modeli GitHub

Uporabili bomo LangChain za povezavo z modeli GitHub, kar je precej super, saj vam omogo캜a brezpla캜en dostop do razli캜nih AI modelov. Najbolj코i del? Za za캜etek potrebujete le nekaj preprostih konfiguracijskih parametrov:

```python
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

# Send a simple prompt
response = llm.invoke("What's the capital of France?")
print(response.content)
```

**Raz캜lenimo, kaj se tukaj dogaja:**
- **Ustvari** LangChain odjemalca z uporabo razreda `ChatOpenAI` - to je va코 prehod do AI!
- **Konfigurira** povezavo z modeli GitHub z va코im avtentikacijskim 쬰tonom
- **Dolo캜i**, kateri AI model uporabiti (`gpt-4o-mini`) - pomislite na to kot na izbiro va코ega AI asistenta
- **Po코lje** va코e vpra코anje z metodo `invoke()` - tukaj se zgodi 캜arovnija
- **Izvle캜e** in prika쬰 odgovor - in voil, klepetate z AI!

> 游댢 **Opomba o nastavitvi**: 캛e uporabljate GitHub Codespaces, imate sre캜o - `GITHUB_TOKEN` je 쬰 nastavljen za vas! Delate lokalno? Brez skrbi, samo ustvariti morate osebni dostopni 쬰ton z ustreznimi dovoljenji.

**Pri캜akovani izhod:**
```text
The capital of France is Paris.
```

```mermaid
sequenceDiagram
    participant App as Your Python App
    participant LC as LangChain
    participant GM as GitHub Models
    participant AI as GPT-4o-mini
    
    App->>LC: llm.invoke("What's the capital of France?")
    LC->>GM: HTTP request with prompt
    GM->>AI: Process prompt
    AI->>GM: Generated response
    GM->>LC: Return response
    LC->>App: response.content
```

## Gradnja pogovornega AI

Prvi primer prikazuje osnove, vendar je to le en sam izmenjava - postavite vpra코anje, dobite odgovor in to je to. V resni캜nih aplikacijah 쬰lite, da si va코 AI zapomni, o 캜em ste razpravljali, tako kot sta Watson in Holmes gradila svoje raziskovalne pogovore skozi 캜as.

Tu postane LangChain 코e posebej uporaben. Ponuja razli캜ne vrste sporo캜il, ki pomagajo strukturirati pogovore in omogo캜ajo, da va코 AI dobi osebnost. Gradili boste izku코nje klepeta, ki ohranjajo kontekst in zna캜aj.

### Razumevanje vrst sporo캜il

Pomislite na te vrste sporo캜il kot na razli캜ne "klobuke", ki jih udele쬰nci nosijo v pogovoru. LangChain uporablja razli캜ne razrede sporo캜il za sledenje, kdo kaj govori:

| Vrsta sporo캜ila | Namen | Primer uporabe |
|-----------------|-------|----------------|
| `SystemMessage` | Dolo캜a osebnost in vedenje AI | "Vi ste koristen asistent za kodiranje" |
| `HumanMessage` | Predstavlja uporabni코ki vnos | "Razlo쬴, kako delujejo funkcije" |
| `AIMessage` | Shrani odgovore AI | Prej코nji odgovori AI v pogovoru |

### Ustvarjanje va코ega prvega pogovora

Ustvarimo pogovor, kjer na코 AI prevzame dolo캜eno vlogo. Naj bo to kapitan Picard - lik, znan po svoji diplomatski modrosti in vodstvenih sposobnostih:

```python
messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]
```

**Raz캜lenitev nastavitve pogovora:**
- **Vzpostavi** vlogo in osebnost AI prek `SystemMessage`
- **Ponuja** za캜etno uporabni코ko vpra코anje prek `HumanMessage`
- **Ustvari** osnovo za ve캜kratni pogovor

Celotna koda za ta primer izgleda takole:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]


# works
response  = llm.invoke(messages)
print(response.content)
```

Videti bi morali rezultat, podoben:

```text
I am Captain Jean-Luc Picard, the commanding officer of the USS Enterprise (NCC-1701-D), a starship in the United Federation of Planets. My primary mission is to explore new worlds, seek out new life and new civilizations, and boldly go where no one has gone before. 

I believe in the importance of diplomacy, reason, and the pursuit of knowledge. My crew is diverse and skilled, and we often face challenges that test our resolve, ethics, and ingenuity. Throughout my career, I have encountered numerous species, grappled with complex moral dilemmas, and have consistently sought peaceful solutions to conflicts.

I hold the ideals of the Federation close to my heart, believing in the importance of cooperation, understanding, and respect for all sentient beings. My experiences have shaped my leadership style, and I strive to be a thoughtful and just captain. How may I assist you further?
```

Da ohranite kontinuiteto pogovora (namesto da bi vsaki캜 ponastavili kontekst), morate odgovore dodajati na seznam sporo캜il. Tako kot ustne tradicije, ki so ohranjale zgodbe skozi generacije, ta pristop gradi trajen spomin:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]


# works
response  = llm.invoke(messages)

print(response.content)

print("---- Next ----")

messages.append(response)
messages.append(HumanMessage(content="Now that I know about you, I'm Chris, can I be in your crew?"))

response  = llm.invoke(messages)

print(response.content)

```

Kar kul, kajne? Tukaj se dogaja to, da dvakrat kli캜emo LLM - najprej samo z na코ima za캜etnima dvema sporo캜iloma, nato pa 코e enkrat s celotno zgodovino pogovora. To je, kot da AI dejansko sledi na코emu klepetu!

Ko za쬰nete to kodo, boste dobili drugi odgovor, ki zveni nekako takole:

```text
Welcome aboard, Chris! It's always a pleasure to meet those who share a passion for exploration and discovery. While I cannot formally offer you a position on the Enterprise right now, I encourage you to pursue your aspirations. We are always in need of talented individuals with diverse skills and backgrounds. 

If you are interested in space exploration, consider education and training in the sciences, engineering, or diplomacy. The values of curiosity, resilience, and teamwork are crucial in Starfleet. Should you ever find yourself on a starship, remember to uphold the principles of the Federation: peace, understanding, and respect for all beings. Your journey can lead you to remarkable adventures, whether in the stars or on the ground. Engage!
```

To bom vzel kot morda ;)

## Pretakanje odgovorov

Ste 쬰 opazili, kako se zdi, da ChatGPT "tipka" svoje odgovore v realnem 캜asu? To je pretakanje v akciji. Tako kot opazovanje spretnosti kaligrafa pri delu - videti, kako se znaki pojavljajo potezo za potezo, namesto da se materializirajo takoj - pretakanje naredi interakcijo bolj naravno in zagotavlja takoj코nje povratne informacije.

### Implementacija pretakanja z LangChain

```python
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
    streaming=True
)

# Stream the response
for chunk in llm.stream("Write a short story about a robot learning to code"):
    print(chunk.content, end="", flush=True)
```

**Zakaj je pretakanje super:**
- **Prikazuje** vsebino, medtem ko se ustvarja - konec nerodnega 캜akanja!
- **Uporabniki** imajo ob캜utek, da se nekaj dejansko dogaja
- **Zdi se** hitreje, tudi 캜e tehni캜no ni
- **Uporabniki** lahko za캜nejo brati, medtem ko AI 코e vedno "razmi코lja"

> 游눠 **Nasvet za uporabni코ko izku코njo**: Pretakanje resni캜no blesti, ko gre za dalj코e odgovore, kot so razlage kode, ustvarjalno pisanje ali podrobni vodi캜i. Va코i uporabniki bodo navdu코eni, ko bodo videli napredek, namesto da bi strmeli v prazen zaslon!

## Predloge za pozive

Predloge za pozive delujejo kot retori캜ne strukture, uporabljene v klasi캜ni retoriki - pomislite, kako bi Ciceron prilagodil svoje vzorce govora za razli캜ne ob캜instva, hkrati pa ohranil enako prepri캜ljivo strukturo. Omogo캜ajo vam ustvarjanje ve캜krat uporabnih pozivov, kjer lahko zamenjate razli캜ne dele informacij, ne da bi morali vse napisati na novo. Ko nastavite predlogo, samo izpolnite spremenljivke z 쬰lenimi vrednostmi.

### Ustvarjanje ve캜krat uporabnih pozivov

```python
from langchain_core.prompts import ChatPromptTemplate

# Define a template for code explanations
template = ChatPromptTemplate.from_messages([
    ("system", "You are an expert programming instructor. Explain concepts clearly with examples."),
    ("human", "Explain {concept} in {language} with a practical example for {skill_level} developers")
])

# Use the template with different values
questions = [
    {"concept": "functions", "language": "JavaScript", "skill_level": "beginner"},
    {"concept": "classes", "language": "Python", "skill_level": "intermediate"},
    {"concept": "async/await", "language": "JavaScript", "skill_level": "advanced"}
]

for question in questions:
    prompt = template.format_messages(**question)
    response = llm.invoke(prompt)
    print(f"Topic: {question['concept']}\n{response.content}\n---\n")
```

**Zakaj boste vzljubili uporabo predlog:**
- **Ohranja** va코e pozive dosledne po celotni aplikaciji
- **Brez ve캜** zme코njave z zdru쬰vanjem nizov - samo 캜iste, preproste spremenljivke
- **Va코 AI** se obna코a predvidljivo, ker struktura ostaja enaka
- **Posodobitve** so enostavne - spremenite predlogo enkrat in je popravljena povsod

## Strukturiran izhod

Ste se kdaj frustrirali, ko ste posku코ali raz캜leniti AI odgovore, ki se vrnejo kot nestrukturirano besedilo? Strukturiran izhod je kot u캜enje va코ega AI, da sledi sistemati캜nemu pristopu, ki ga je Linnaeus uporabil za biolo코ko klasifikacijo - organizirano, predvidljivo in enostavno za delo. Lahko zahtevate JSON, specifi캜ne podatkovne strukture ali katero koli obliko, ki jo potrebujete.

### Dolo캜anje shem izhoda

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel, Field

class CodeReview(BaseModel):
    score: int = Field(description="Code quality score from 1-10")
    strengths: list[str] = Field(description="List of code strengths")
    improvements: list[str] = Field(description="List of suggested improvements")
    overall_feedback: str = Field(description="Summary feedback")

# Set up the parser
parser = JsonOutputParser(pydantic_object=CodeReview)

# Create prompt with format instructions
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a code reviewer. {format_instructions}"),
    ("human", "Review this code: {code}")
])

# Format the prompt with instructions
chain = prompt | llm | parser

# Get structured response
code_sample = """
def calculate_average(numbers):
    return sum(numbers) / len(numbers)
"""

result = chain.invoke({
    "code": code_sample,
    "format_instructions": parser.get_format_instructions()
})

print(f"Score: {result['score']}")
print(f"Strengths: {', '.join(result['strengths'])}")
```

**Zakaj je strukturiran izhod prelomnica:**
- **Ni ve캜** ugibanja, v kak코ni obliki boste dobili odgovor - vedno je dosleden
- **Neposredno se pove쬰** z va코imi bazami podatkov in API-ji brez dodatnega dela
- **Zajame** nenavadne AI odgovore, preden pokvarijo va코o aplikacijo
- **Naredi** va코o kodo 캜istej코o, ker to캜no veste, s 캜im delate

## Klicanje orodij

Zdaj pridemo do ene najmo캜nej코ih funkcij: orodja. Tako svojemu AI omogo캜ite prakti캜ne sposobnosti, ki presegajo pogovor. Tako kot so srednjeve코ki cehi razvili specializirana orodja za dolo캜ene obrti, lahko svoj AI opremite s fokusiranimi instrumenti. Opisujete, katera orodja so na voljo, in ko nekdo zahteva nekaj, kar ustreza, lahko va코 AI ukrepa.

### Uporaba Python-a

Dodajmo nekaj orodij, kot je prikazano:

```python
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

tools = [add]

functions = {
    "add": lambda a, b: a + b
}
```

Kaj se tukaj dogaja? Ustvarjamo na캜rt za orodje, imenovano `add`. Z dedovanjem iz `TypedDict` in uporabo teh elegantnih tipov `Annotated` za `a` in `b` dajemo LLM jasno sliko o tem, kaj to orodje po캜ne in kaj potrebuje. Slovar `functions` je kot na코 orodjar - pove na코i kodi, kaj to캜no storiti, ko se AI odlo캜i uporabiti dolo캜eno orodje.

Poglejmo, kako naslednji캜 pokli캜emo LLM s tem orodjem:

```python
llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)
```

Tukaj pokli캜emo `bind_tools` z na코im nizom `tools`, s 캜imer LLM `llm_with_tools` zdaj pozna to orodje.

Za uporabo tega novega LLM lahko vnesemo naslednjo kodo:

```python
query = "What is 3 + 12?"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

Zdaj, ko pokli캜emo `invoke` na tem novem LLM, ki ima orodja, se morda lastnost `tool_calls` napolni. 캛e je tako, ima katero koli identificirano orodje lastnosti `name` in `args`, ki identificirajo, katero orodje naj se pokli캜e in s katerimi argumenti. Celotna koda izgleda takole:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

tools = [add]

functions = {
    "add": lambda a, b: a + b
}

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)

query = "What is 3 + 12?"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

Ko za쬰nete to kodo, bi morali videti izhod, podoben:

```text
TOOL CALL:  15
CONTENT: 
```

AI je preu캜il "Kaj je 3 + 12" in to prepoznal kot nalogo za orodje `add`. Tako kot izku코en knji쬹i캜ar ve, na kateri vir se obrniti glede na vrsto zastavljenega vpra코anja, je to ugotovil na podlagi imena orodja, opisa in specifikacij polja. Rezultat 15 izhaja iz na코ega slovarja `functions`, ki izvaja orodje:

```python
print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
```

### Bolj zanimivo orodje, ki kli캜e spletni API

Se코tevanje 코tevilk prikazuje koncept, vendar prava orodja obi캜ajno izvajajo bolj zapletene operacije, kot je klicanje spletnih API-jev. Raz코irimo na코 primer, da AI pridobi vsebino z interneta - podobno kot so telegrafisti neko캜 povezovali oddaljene lokacije:

```python
class joke(TypedDict):
    """Tell a joke."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    category: Annotated[str, ..., "The joke category"]

def get_joke(category: str) -> str:
    response = requests.get(f"https://api.chucknorris.io/jokes/random?category={category}", headers={"Accept": "application/json"})
    if response.status_code == 200:
        return response.json().get("value", f"Here's a {category} joke!")
    return f"Here's a {category} joke!"

functions = {
    "add": lambda a, b: a + b,
    "joke": lambda category: get_joke(category)
}

query = "Tell me a joke about animals"

# the rest of the code is the same
```

Zdaj, 캜e za쬰nete to kodo, boste dobili odgovor, ki pravi nekaj takega:

```text
TOOL CALL:  Chuck Norris once rode a nine foot grizzly bear through an automatic car wash, instead of taking a shower.
CONTENT:  
```

Tukaj je celotna koda:

```python
from langchain_openai import ChatOpenAI
import requests
import os
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

class joke(TypedDict):
    """Tell a joke."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    category: Annotated[str, ..., "The joke category"]

tools = [add, joke]

def get_joke(category: str) -> str:
    response = requests.get(f"https://api.chucknorris.io/jokes/random?category={category}", headers={"Accept": "application/json"})
    if response.status_code == 200:
        return response.json().get("value", f"Here's a {category} joke!")
    return f"Here's a {category} joke!"

functions = {
    "add": lambda a, b: a + b,
    "joke": lambda category: get_joke(category)
}

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)

query = "Tell me a joke about animals"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        # print("TOOL CALL: ", tool)
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

## Vdelave in obdelava dokumentov

Vdelave predstavljajo eno najbolj elegantnih re코itev v sodobni AI. Predstavljajte si, da lahko vsak kos besedila pretvorite v numeri캜ne koordinate, ki zajemajo njegov pomen. To캜no to po캜nejo vdelave - pretvarjajo besedilo v to캜ke v ve캜dimenzionalnem prostoru, kjer se podobni koncepti zdru쬿jejo. To je kot imeti koordinatni sistem za ideje, podobno kot je Mendelejev organiziral periodni sistem po atomskih lastnostih.

### Ustvarjanje in uporaba vdelav

```python
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter

# Initialize embeddings
embeddings = OpenAIEmbeddings(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="text-embedding-3-small"
)

# Load and split documents
loader = TextLoader("documentation.txt")
documents = loader.load()

text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(documents)

# Create vector store
vectorstore = FAISS.from_documents(texts, embeddings)

# Perform similarity search
query = "How do I handle user authentication?"
similar_docs = vectorstore.similarity_search(query, k=3)

for doc in similar_docs:
    print(f"Relevant content: {doc.page_content[:200]}...")
```

### Nalagalniki dokumentov za razli캜ne formate

```python
from langchain_community.document_loaders import (
    PyPDFLoader,
    CSVLoader,
    JSONLoader,
    WebBaseLoader
)

# Load different document types
pdf_loader = PyPDFLoader("manual.pdf")
csv_loader = CSVLoader("data.csv")
json_loader = JSONLoader("config.json")
web_loader = WebBaseLoader("https://example.com/docs")

# Process all documents
all_documents = []
for loader in [pdf_loader, csv_loader, json_loader, web_loader]:
    docs = loader.load()
    all_documents.extend(docs)
```

**Kaj lahko storite z vdelavami:**
- **Zgradite** iskanje, ki dejansko razume, kaj mislite, ne le ujemanje klju캜nih besed
- **Ustvarite** AI, ki lahko odgovarja na vpra코anja o va코ih dokumentih
- **Naredite** priporo캜ilne sisteme, ki predlagajo resni캜no relevantno vsebino
- **Samodejno** organizirajte in kategorizirajte svojo vsebino

## Gradnja celovite AI aplikacije

Zdaj bomo zdru쬴li vse, kar ste se nau캜ili, v celovito aplikacijo - asistenta za kodiranje, ki lahko odgovarja na vpra코anja, uporablja orodja in ohranja spomin na pogovor. Tako kot je tiskarski stroj zdru쬴l obstoje캜e tehnologije (premi캜ni tisk, 캜rnilo, papir in pritisk) v nekaj prelomnega, bomo zdru쬴li na코e AI komponente v nekaj prakti캜nega in uporabnega.

### Primer celovite aplikacije

```python
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_community.vectorstores import FAISS
from typing_extensions import Annotated, TypedDict
import os
import requests

class CodingAssistant:
    def __init__(self):
        self.llm = ChatOpenAI(
            api_key=os.environ["GITHUB_TOKEN"],
            base_url="https://models.github.ai/inference",
            model="openai/gpt-4o-mini"
        )
        
        self.conversation_history = [
            SystemMessage(content="""You are an expert coding assistant. 
            Help users learn programming concepts, debug code, and write better software.
            Use tools when needed and maintain a helpful, encouraging tone.""")
        ]
        
        # Define tools
        self.setup_tools()
    
    def setup_tools(self):
        class web_search(TypedDict):
            """Search for programming documentation or examples."""
            query: Annotated[str, "Search query for programming help"]
        
        class code_formatter(TypedDict):
            """Format and validate code snippets."""
            code: Annotated[str, "Code to format"]
            language: Annotated[str, "Programming language"]
        
        self.tools = [web_search, code_formatter]
        self.llm_with_tools = self.llm.bind_tools(self.tools)
    
    def chat(self, user_input: str):
        # Add user message to conversation
        self.conversation_history.append(HumanMessage(content=user_input))
        
        # Get AI response
        response = self.llm_with_tools.invoke(self.conversation_history)
        
        # Handle tool calls if any
        if response.tool_calls:
            for tool_call in response.tool_calls:
                tool_result = self.execute_tool(tool_call)
                print(f"游댢 Tool used: {tool_call['name']}")
                print(f"游늵 Result: {tool_result}")
        
        # Add AI response to conversation
        self.conversation_history.append(response)
        
        return response.content
    
    def execute_tool(self, tool_call):
        tool_name = tool_call['name']
        args = tool_call['args']
        
        if tool_name == 'web_search':
            return f"Found documentation for: {args['query']}"
        elif tool_name == 'code_formatter':
            return f"Formatted {args['language']} code: {args['code'][:50]}..."
        
        return "Tool execution completed"

# Usage example
assistant = CodingAssistant()

print("游뱄 Coding Assistant Ready! Type 'quit' to exit.\n")

while True:
    user_input = input("You: ")
    if user_input.lower() == 'quit':
        break
    
    response = assistant.chat(user_input)
    print(f"游뱄 Assistant: {response}\n")
```

**Arhitektura aplikacije:**

```mermaid
graph TD
    A[User Input] --> B[Coding Assistant]
    B --> C[Conversation Memory]
    B --> D[Tool Detection]
    B --> E[LLM Processing]
    
    D --> F[Web Search Tool]
    D --> G[Code Formatter Tool]
    
    E --> H[Response Generation]
    F --> H
    G --> H
    
    H --> I[User Interface]
    H --> C
```

**Klju캜ne funkcije, ki smo jih implementirali:**
- **Si zapomni** celoten pogovor za kontinuiteto konteksta
- **Izvaja dejanja** prek klicanja orodij, ne le pogovora
- **Sledi** predvidljivim vzorcem interakcije
- **Samodejno upravlja** obravnavanje napak in kompleksne delovne tokove

## Naloga: Zgradite svojega AI asistenta za u캜enje

**Cilj**: Ustvarite AI aplikacijo, ki pomaga 코tudentom pri u캜enju programskih konceptov z zagotavljanjem raz
3. **Personalizirano u캜enje**: Uporabite sistemska sporo캜ila za prilagoditev odgovorov razli캜nim stopnjam znanja
4. **Oblikovanje odgovorov**: Uvedite strukturiran izhod za vpra코anja kviza

### Koraki izvedbe

**Korak 1: Priprava okolja**
```bash
pip install langchain langchain-openai
```

**Korak 2: Osnovna funkcionalnost klepeta**
- Ustvarite razred `StudyAssistant`
- Implementirajte pomnilnik pogovora
- Dodajte konfiguracijo osebnosti za podporo izobra쬰vanju

**Korak 3: Dodajanje izobra쬰valnih orodij**
- **Razlaga kode**: Raz캜leni kodo na razumljive dele
- **Generator kvizov**: Ustvari vpra코anja o konceptih programiranja
- **Sledilnik napredka**: Spremlja obravnavane teme

**Korak 4: Izbolj코ane funkcije (neobvezno)**
- Implementirajte preto캜ne odgovore za bolj코o uporabni코ko izku코njo
- Dodajte nalaganje dokumentov za vklju캜itev u캜nih gradiv
- Ustvarite vdelave za iskanje vsebine na podlagi podobnosti

### Merila za ocenjevanje

| Funkcija | Odli캜no (4) | Dobro (3) | Zadovoljivo (2) | Potrebno izbolj코anje (1) |
|----------|-------------|-----------|-----------------|--------------------------|
| **Potek pogovora** | Naravni, kontekstualno zavedni odgovori | Dobro ohranjanje konteksta | Osnovni pogovor | Brez pomnilnika med izmenjavami |
| **Integracija orodij** | Ve캜 uporabnih orodij deluje brezhibno | 2+ orodji pravilno implementirani | 1-2 osnovni orodji | Orodja ne delujejo |
| **Kakovost kode** | 캛ista, dobro dokumentirana, obravnava napake | Dobra struktura, nekaj dokumentacije | Osnovna funkcionalnost deluje | Slaba struktura, brez obravnave napak |
| **Izobra쬰valna vrednost** | Resni캜no koristno za u캜enje, prilagodljivo | Dobra podpora u캜enju | Osnovne razlage | Omejena izobra쬰valna korist |

### Vzorec strukture kode

```python
class StudyAssistant:
    def __init__(self, skill_level="beginner"):
        # Initialize LLM, tools, and conversation memory
        pass
    
    def explain_code(self, code, language):
        # Tool: Explain how code works
        pass
    
    def generate_quiz(self, topic, difficulty):
        # Tool: Create practice questions
        pass
    
    def chat(self, user_input):
        # Main conversation interface
        pass

# Example usage
assistant = StudyAssistant(skill_level="intermediate")
response = assistant.chat("Explain how Python functions work")
```

**Dodatni izzivi:**
- Dodajte mo쬹ost glasovnega vnosa/iznosa
- Implementirajte spletni vmesnik z uporabo Streamlit ali Flask
- Ustvarite bazo znanja iz u캜nih gradiv z uporabo vdelav
- Dodajte sledenje napredku in personalizirane u캜ne poti

## Povzetek

游꿀 Zdaj ste obvladali osnove razvoja AI okvirjev in se nau캜ili, kako zgraditi sofisticirane AI aplikacije z uporabo LangChain. Kot da bi zaklju캜ili celovito vajeni코tvo, ste pridobili obse쬰n nabor ve코캜in. Poglejmo, kaj ste dosegli.

### Kaj ste se nau캜ili

**Osnovni koncepti okvirja:**
- **Prednosti okvirja**: Razumevanje, kdaj izbrati okvirje namesto neposrednih API klicev
- **Osnove LangChain**: Nastavitev in konfiguracija povezav z AI modeli
- **Vrste sporo캜il**: Uporaba `SystemMessage`, `HumanMessage` in `AIMessage` za strukturirane pogovore

**Napredne funkcije:**
- **Klicanje orodij**: Ustvarjanje in integracija prilagojenih orodij za izbolj코ane AI zmogljivosti
- **Pomnilnik pogovora**: Ohranjanje konteksta skozi ve캜 izmenjav v pogovoru
- **Preto캜ni odgovori**: Implementacija dostave odgovorov v realnem 캜asu
- **Predloge za pozive**: Gradnja ve캜krat uporabnih, dinami캜nih pozivov
- **Strukturiran izhod**: Zagotavljanje doslednih, raz캜lenljivih AI odgovorov
- **Vdelave**: Ustvarjanje semanti캜nega iskanja in zmo쬹osti obdelave dokumentov

**Prakti캜ne aplikacije:**
- **Gradnja celovitih aplikacij**: Zdru쬰vanje ve캜 funkcij v produkcijsko pripravljene aplikacije
- **Obravnava napak**: Implementacija robustnega upravljanja napak in validacije
- **Integracija orodij**: Ustvarjanje prilagojenih orodij, ki raz코irjajo zmogljivosti AI

### Klju캜ne to캜ke

> 游꿢 **Zapomnite si**: AI okvirji, kot je LangChain, so v bistvu va코i najbolj코i prijatelji, ki skrivajo kompleksnost in so polni funkcij. Popolni so, ko potrebujete pomnilnik pogovora, klicanje orodij ali 쬰lite delati z ve캜 AI modeli, ne da bi izgubili razum.

**Odlo캜anje o integraciji AI:**

```mermaid
flowchart TD
    A[AI Integration Need] --> B{Simple single query?}
    B -->|Yes| C[Direct API calls]
    B -->|No| D{Need conversation memory?}
    D -->|No| E[SDK Integration]
    D -->|Yes| F{Need tools or complex features?}
    F -->|No| G[Framework with basic setup]
    F -->|Yes| H[Full framework implementation]
    
    C --> I[HTTP requests, minimal dependencies]
    E --> J[Provider SDK, model-specific]
    G --> K[LangChain basic chat]
    H --> L[LangChain with tools, memory, agents]
```

### Kam naprej?

**Za캜nite graditi zdaj:**
- Uporabite te koncepte in zgradite nekaj, kar vas navdu코uje!
- Preizkusite razli캜ne AI modele prek LangChain - to je kot igri코캜e AI modelov
- Ustvarite orodja, ki re코ujejo dejanske te쬬ve, s katerimi se soo캜ate pri delu ali projektih

**Pripravljeni na naslednjo stopnjo?**
- **AI agenti**: Zgradite AI sisteme, ki lahko sami na캜rtujejo in izvajajo kompleksne naloge
- **RAG (Generacija z obogatenim iskanjem)**: Zdru쬴te AI z lastnimi bazami znanja za super zmogljive aplikacije
- **Multi-modalni AI**: Delajte s tekstom, slikami in zvokom skupaj - mo쬹osti so neskon캜ne!
- **Produkcijska implementacija**: Nau캜ite se, kako raz코iriti svoje AI aplikacije in jih spremljati v resni캜nem svetu

**Pridru쬴te se skupnosti:**
- Skupnost LangChain je odli캜na za spremljanje novosti in u캜enje najbolj코ih praks
- GitHub Models vam omogo캜a dostop do najnovej코ih AI zmogljivosti - popolno za eksperimentiranje
- Nadaljujte z vadbo razli캜nih primerov uporabe - vsak projekt vas bo nau캜il nekaj novega

Zdaj imate znanje za gradnjo inteligentnih, pogovornih aplikacij, ki lahko ljudem pomagajo re코evati resni캜ne te쬬ve. Kot renesan캜ni mojstri, ki so zdru쬰vali umetni코ko vizijo s tehni캜nimi ve코캜inami, lahko zdaj zdru쬴te AI zmogljivosti s prakti캜no uporabo. Vpra코anje je: kaj boste ustvarili? 游

## Izziv GitHub Copilot Agent 游

Uporabite na캜in Agent za dokon캜anje naslednjega izziva:

**Opis:** Zgradite naprednega AI asistenta za pregled kode, ki zdru쬿je ve캜 funkcij LangChain, vklju캜no s klicanjem orodij, strukturiranim izhodom in pomnilnikom pogovora, da zagotovi celovite povratne informacije o predlo쬰nih kodah.

**Poziv:** Ustvarite razred CodeReviewAssistant, ki implementira:
1. Orodje za analizo kompleksnosti kode in predlaganje izbolj코av
2. Orodje za preverjanje kode glede na najbolj코e prakse
3. Strukturiran izhod z uporabo Pydantic modelov za dosledno obliko pregleda
4. Pomnilnik pogovora za sledenje seansam pregleda
5. Glavni vmesnik za klepet, ki lahko obravnava predlo쬰ne kode in zagotovi podrobne, izvedljive povratne informacije

Asistent mora biti sposoben pregledati kodo v ve캜 programskih jezikih, ohraniti kontekst med ve캜 predlo쬰nimi kodami v eni seansi in zagotoviti tako povzetke kot podrobne predloge za izbolj코ave.

Ve캜 o [na캜inu agent](https://code.visualstudio.com/blogs/2025/02/24/introducing-copilot-agent-mode) si preberite tukaj.

---

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo storitve za prevajanje z umetno inteligenco [Co-op Translator](https://github.com/Azure/co-op-translator). 캛eprav si prizadevamo za natan캜nost, vas prosimo, da upo코tevate, da lahko avtomatizirani prevodi vsebujejo napake ali neto캜nosti. Izvirni dokument v njegovem maternem jeziku naj se 코teje za avtoritativni vir. Za klju캜ne informacije priporo캜amo profesionalni 캜love코ki prevod. Ne odgovarjamo za morebitne nesporazume ali napa캜ne razlage, ki bi nastale zaradi uporabe tega prevoda.