<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3925b6a1c31c60755eaae4d578232c25",
  "translation_date": "2026-01-06T22:29:41+00:00",
  "source_file": "10-ai-framework-project/README.md",
  "language_code": "sv"
}
-->
# AI-ramverk

Har du n√•gonsin k√§nt dig √∂verv√§ldigad n√§r du f√∂rs√∂kt bygga AI-applikationer fr√•n grunden? Du √§r inte ensam! AI-ramverk √§r som en schweizisk arm√©kniv f√∂r AI-utveckling - de √§r kraftfulla verktyg som kan spara dig tid och huvudv√§rk n√§r du bygger intelligenta applikationer. T√§nk p√• ett AI-ramverk som ett v√§lorganiserat bibliotek: det tillhandah√•ller f√§rdiga komponenter, standardiserade API:er och smarta abstraktioner s√• att du kan fokusera p√• att l√∂sa problem ist√§llet f√∂r att k√§mpa med implementationsdetaljer.

I den h√§r lektionen ska vi utforska hur ramverk som LangChain kan f√∂rvandla vad som tidigare var komplexa AI-integrationsuppgifter till ren, l√§sbar kod. Du kommer att uppt√§cka hur du hanterar verkliga utmaningar som att h√•lla reda p√• konversationer, implementera verktygsanrop och jonglera olika AI-modeller genom ett enhetligt gr√§nssnitt.

N√§r vi √§r klara kommer du att veta n√§r du ska anv√§nda ramverk ist√§llet f√∂r r√•a API-anrop, hur du anv√§nder deras abstraktioner effektivt, och hur du bygger AI-applikationer som √§r redo f√∂r verklig anv√§ndning. L√•t oss utforska vad AI-ramverk kan g√∂ra f√∂r dina projekt.

## ‚ö° Vad du kan g√∂ra p√• n√§sta 5 minuter

**Snabbstartsv√§g f√∂r upptagna utvecklare**

```mermaid
flowchart LR
    A[‚ö° 5 minuter] --> B[Installera LangChain]
    B --> C[Skapa ChatOpenAI-klient]
    C --> D[Skicka f√∂rsta prompt]
    D --> E[Se ramverkets kraft]
```
- **Minut 1**: Installera LangChain: `pip install langchain langchain-openai`
- **Minut 2**: St√§ll in din GitHub-token och importera ChatOpenAI-klienten
- **Minut 3**: Skapa en enkel konversation med system- och m√§nniskomeddelanden
- **Minut 4**: L√§gg till ett grundl√§ggande verktyg (som en add-funktion) och se AI:s verktygsanrop
- **Minut 5**: Upplev skillnaden mellan r√•a API-anrop och ramverksabstraktion

**Snabb testkod**:
```python
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini"
)

response = llm.invoke([
    SystemMessage(content="You are a helpful coding assistant"),
    HumanMessage(content="Explain Python functions briefly")
])
print(response.content)
```

**Varf√∂r detta √§r viktigt**: P√• 5 minuter kommer du att uppleva hur AI-ramverk f√∂rvandlar komplex AI-integration till enkla metodanrop. Detta √§r grunden som driver produktionsklara AI-applikationer.

## Varf√∂r v√§lja ett ramverk?

S√• du √§r redo att bygga en AI-app - fantastiskt! Men h√§r √§r saken: du har flera olika v√§gar att ta, och varje har sina f√∂r- och nackdelar. Det √§r lite som att v√§lja mellan att g√•, cykla eller k√∂ra bil f√∂r att ta sig n√•gonstans - alla tar dig dit, men upplevelsen (och anstr√§ngningen) blir helt annorlunda.

L√•t oss bryta ner de tre huvudsakliga s√§tten du kan integrera AI i dina projekt:

| Tillv√§gag√•ngss√§tt | F√∂rdelar | Passar b√§st f√∂r | √ñverv√§ganden |
|-------------------|----------|-----------------|--------------|
| **Direkta HTTP-f√∂rfr√•gningar** | Full kontroll, inga beroenden | Enkla f√∂rfr√•gningar, l√§ra sig grunderna | Mer omst√§ndlig kod, manuell felhantering |
| **SDK-integration** | Mindre boilerplate, modell-specifik optimering | Applikationer med en modell | Begr√§nsad till specifika leverant√∂rer |
| **AI-ramverk** | Enhetligt API, inbyggda abstraktioner | Applikationer med flera modeller, komplexa arbetsfl√∂den | Inl√§rningskurva, potentiell √∂ver-abstraktion |

### Ramverkets f√∂rdelar i praktiken

```mermaid
graph TD
    A[Din Applikation] --> B[AI-ramverk]
    B --> C[OpenAI GPT]
    B --> D[Anthropic Claude]
    B --> E[GitHub-modeller]
    B --> F[Lokala modeller]
    
    B --> G[Inbyggda Verktyg]
    G --> H[Minneshantering]
    G --> I[Samtalshistorik]
    G --> J[Funktionsanrop]
    G --> K[Fels√∂kning]
```
**Varf√∂r ramverk √§r viktiga:**
- **Samlar** flera AI-leverant√∂rer under ett gr√§nssnitt
- **Hanterar** konversationsminne automatiskt
- **Tillhandah√•ller** f√§rdiga verktyg f√∂r vanliga uppgifter som inb√§ddningar och funktionsanrop
- **Sk√∂ter** felhantering och repetitionslogik
- **F√∂rvandlar** komplexa arbetsfl√∂den till l√§sbara metodanrop

> üí° **Proftips**: Anv√§nd ramverk n√§r du byter mellan olika AI-modeller eller bygger komplexa funktioner som agenter, minne eller verktygsanrop. H√•ll dig till direkta API:er n√§r du l√§r dig grunderna eller bygger enkla, fokuserade applikationer.

**Slutsatsen**: Som att v√§lja mellan en hantverkares specialverktyg och en komplett verkstad handlar det om att matcha verktyget med uppgiften. Ramverk √§r b√§st f√∂r komplexa, funktionsrika applikationer, medan direkta API:er fungerar bra f√∂r enkla anv√§ndningsfall.

## üó∫Ô∏è Din l√§randeresa genom AI-ramverksm√§sterskap

```mermaid
journey
    title Fr√•n r√•a API:er till produktions-AI-applikationer
    section Ramverksgrunder
      F√∂rst√• abstraktionsf√∂rdelar: 4: You
      Bem√§stra LangChain-grunder: 6: You
      J√§mf√∂r metoder: 7: You
    section Konversationssystem
      Bygg chattgr√§nssnitt: 5: You
      Implementera minnesm√∂nster: 7: You
      Hantera str√∂mmande svar: 8: You
    section Avancerade funktioner
      Skapa anpassade verktyg: 6: You
      Bem√§stra strukturerad output: 8: You
      Bygg dokumentsystem: 8: You
    section Produktionsapplikationer
      Kombinera alla funktioner: 7: You
      Hantera fell√§gen: 8: You
      Distribuera kompletta system: 9: You
```
**Din resas m√•l**: I slutet av denna lektion kommer du att ha beh√§rskat AI-ramverksutveckling och kunna bygga sofistikerade, produktionsklara AI-applikationer som kan m√§ta sig med kommersiella AI-assistenter.

## Introduktion

I denna lektion ska vi l√§ra oss att:

- Anv√§nda ett vanligt AI-ramverk.
- Hantera vanliga problem som chattkonversationer, verktygsanv√§ndning, minne och kontext.
- Utnyttja detta f√∂r att bygga AI-appar.

## üß† AI-ramverksutvecklings-ekosystem

```mermaid
mindmap
  root((AI Frameworks))
    Abstraktionsf√∂rdelar
      Kodf√∂renkling
        Enhetliga API:er
        Inbyggd felhantering
        Konsekventa m√∂nster
        Minskat mallkod
      St√∂d f√∂r flera modeller
        Leverant√∂rsagnostisk
        Enkel omkoppling
        Reservalternativ
        Kostnadsoptimering
    K√§rnkomponenter
      Konversationshantering
        Meddelandetyper
        Minnessystem
        Kontextsp√•rning
        Historikensvarighet
      Verktygsintegration
        Funktionsanrop
        API-anslutningar
        Anpassade verktyg
        Arbetsfl√∂desautomatisering
    Avancerade funktioner
      Strukturerat utdata
        Pydantic-modeller
        JSON-scheman
        Typs√§kerhet
        Valideringsregler
      Dokumentbearbetning
        Inb√§ddningar
        Vektordatabaser
        Likhetss√∂kning
        RAG-system
    Produktionsm√∂nster
      Applikationsarkitektur
        Modul√§r design
        Felgr√§nser
        Asynkrona operationer
        Tillst√•ndshantering
      Drifts√§ttningsstrategier
        Skalbarhet
        √ñvervakning
        Prestanda
        S√§kerhet
```
**K√§rnprincip**: AI-ramverk abstraherar komplexitet samtidigt som de tillhandah√•ller kraftfulla abstraktioner f√∂r konversationshantering, verktygsintegration och dokumentbearbetning, vilket g√∂r det m√∂jligt f√∂r utvecklare att bygga sofistikerade AI-applikationer med ren, underh√•llbar kod.

## Din f√∂rsta AI-prompt

L√•t oss b√∂rja med grunderna genom att skapa din f√∂rsta AI-applikation som skickar en fr√•ga och f√•r ett svar tillbaka. Som Archimedes som uppt√§ckte principen om f√∂rskjutning i sitt badkar, leder ibland de enklaste observationerna till de mest kraftfulla insikterna - och ramverk g√∂r dessa insikter tillg√§ngliga.

### St√§lla in LangChain med GitHub Models

Vi ska anv√§nda LangChain f√∂r att koppla till GitHub Models, vilket √§r ganska bra eftersom det ger dig gratis tillg√•ng till olika AI-modeller. Det b√§sta? Du beh√∂ver bara n√•gra enkla konfigurationsparametrar f√∂r att komma ig√•ng:

```python
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

# Skicka en enkel uppmaning
response = llm.invoke("What's the capital of France?")
print(response.content)
```

**L√•t oss bryta ner vad som h√§nder h√§r:**
- **Skapar** en LangChain-klient med `ChatOpenAI`-klassen - detta √§r din port till AI!
- **Konfigurerar** anslutningen till GitHub Models med din autentiseringstoken
- **Specificerar** vilken AI-modell som ska anv√§ndas (`gpt-4o-mini`) - t√§nk p√• detta som att v√§lja din AI-assistent
- **Skickar** din fr√•ga med `invoke()`-metoden - h√§r h√§nder magin
- **Extraherar** och visar svaret - och voil√†, du chattar med AI!

> üîß **Installationsnotering**: Om du anv√§nder GitHub Codespaces √§r du lyckligt lottad - `GITHUB_TOKEN` √§r redan konfigurerad √•t dig! Jobbar du lokalt? Ingen fara, du beh√∂ver bara skapa en personlig √•tkomsttoken med r√§tt beh√∂righeter.

**F√∂rv√§ntad utdata:**
```text
The capital of France is Paris.
```

```mermaid
sequenceDiagram
    participant App as Din Python-app
    participant LC as LangChain
    participant GM as GitHub-modeller
    participant AI as GPT-4o-mini
    
    App->>LC: llm.invoke("Vad √§r huvudstaden i Frankrike?")
    LC->>GM: HTTP-beg√§ran med prompt
    GM->>AI: Bearbeta prompt
    AI->>GM: Genererat svar
    GM->>LC: Returnera svar
    LC->>App: response.content
```
## Bygga konversationell AI

Det f√∂rsta exemplet visar grunderna, men det √§r bara ett enda utbyte - du st√§ller en fr√•ga, f√•r ett svar, och det √§r allt. I riktiga applikationer vill du att din AI ska minnas vad ni har diskuterat, som hur Watson och Holmes byggde sina utredande samtal √∂ver tid.

H√§r blir LangChain s√§rskilt anv√§ndbart. Det tillhandah√•ller olika meddelandetyper som hj√§lper till att strukturera konversationer och l√•ter dig ge din AI en personlighet. Du kommer att bygga chattupplevelser som beh√•ller kontext och karakt√§r.

### F√∂rst√• meddelandetyper

T√§nk p√• dessa meddelandetyper som olika "hattar" som deltagare b√§r i en konversation. LangChain anv√§nder olika meddelandeklasser f√∂r att h√•lla reda p√• vem som s√§ger vad:

| Meddelandetyp | Syfte | Exempel p√• anv√§ndning |
|--------------|---------|----------------------|
| `SystemMessage` | Definierar AI:s personlighet och beteende | "Du √§r en hj√§lpsam kodningsassistent" |
| `HumanMessage` | Representerar anv√§ndarens input | "F√∂rklara hur funktioner fungerar" |
| `AIMessage` | Sparar AI:s svar | Tidigare AI-svar i konversationen |

### Skapa din f√∂rsta konversation

L√•t oss skapa en konversation d√§r v√•r AI antar en specifik roll. Vi l√•ter den gestalta kapten Picard - en karakt√§r k√§nd f√∂r sin diplomatiska visdom och ledarskap:

```python
messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]
```

**Bryt ner denna konversationsinst√§llning:**
- **Etablerar** AI:s roll och personlighet genom `SystemMessage`
- **Tillhandah√•ller** den initiala anv√§ndarfr√•gan via `HumanMessage`
- **Skapar** en grund f√∂r fleromg√•ngs-konversation

Den fullst√§ndiga koden f√∂r detta exempel ser ut s√• h√§r:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]


# fungerar
response  = llm.invoke(messages)
print(response.content)
```

Du b√∂r se ett resultat som liknar:

```text
I am Captain Jean-Luc Picard, the commanding officer of the USS Enterprise (NCC-1701-D), a starship in the United Federation of Planets. My primary mission is to explore new worlds, seek out new life and new civilizations, and boldly go where no one has gone before. 

I believe in the importance of diplomacy, reason, and the pursuit of knowledge. My crew is diverse and skilled, and we often face challenges that test our resolve, ethics, and ingenuity. Throughout my career, I have encountered numerous species, grappled with complex moral dilemmas, and have consistently sought peaceful solutions to conflicts.

I hold the ideals of the Federation close to my heart, believing in the importance of cooperation, understanding, and respect for all sentient beings. My experiences have shaped my leadership style, and I strive to be a thoughtful and just captain. How may I assist you further?
```

F√∂r att beh√•lla kontinuiteten i konversationen (ist√§llet f√∂r att √•terst√§lla kontext varje g√•ng) m√•ste du forts√§tta l√§gga till svar i din meddelandelista. Som de muntliga traditioner som bevarade ber√§ttelser √∂ver generationer bygger detta ett best√•ende minne:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]


# fungerar
response  = llm.invoke(messages)

print(response.content)

print("---- Next ----")

messages.append(response)
messages.append(HumanMessage(content="Now that I know about you, I'm Chris, can I be in your crew?"))

response  = llm.invoke(messages)

print(response.content)

```

R√§tt snyggt, eller hur? Det som h√§nder h√§r √§r att vi anropar LLM tv√• g√•nger - f√∂rst med bara v√•ra initiala tv√• meddelanden, men sedan igen med hela konversationshistoriken. Det √§r som om AI faktiskt f√∂ljer med i v√•r chatt!

N√§r du k√∂r denna kod f√•r du ett andra svar som l√•ter ungef√§r s√• h√§r:

```text
Welcome aboard, Chris! It's always a pleasure to meet those who share a passion for exploration and discovery. While I cannot formally offer you a position on the Enterprise right now, I encourage you to pursue your aspirations. We are always in need of talented individuals with diverse skills and backgrounds. 

If you are interested in space exploration, consider education and training in the sciences, engineering, or diplomacy. The values of curiosity, resilience, and teamwork are crucial in Starfleet. Should you ever find yourself on a starship, remember to uphold the principles of the Federation: peace, understanding, and respect for all beings. Your journey can lead you to remarkable adventures, whether in the stars or on the ground. Engage!
```

```mermaid
sequenceDiagram
    participant User
    participant App
    participant LangChain
    participant AI
    
    User->>App: "Ber√§tta om dig sj√§lv"
    App->>LangChain: [SystemMessage, HumanMessage]
    LangChain->>AI: Formaterad konversation
    AI->>LangChain: Captain Picard svar
    LangChain->>App: AIMessage objekt
    App->>User: Visa svar
    
    Note over App: L√§gg till AIMessage i konversationen
    
    User->>App: "Kan jag g√• med i din bes√§ttning?"
    App->>LangChain: [SystemMessage, HumanMessage, AIMessage, HumanMessage]
    LangChain->>AI: Fullst√§ndig konversationskontext
    AI->>LangChain: Kontextuellt svar
    LangChain->>App: Ny AIMessage
    App->>User: Visa kontextuellt svar
```
Jag tolkar det som ett kanske ;)

## Str√∂mmande svar

Har du m√§rkt hur ChatGPT verkar "skriva" sina svar i realtid? Det √§r str√∂mning i aktion. Som att se en skicklig kalligraf arbeta - se tecknen dyka upp streck f√∂r streck ist√§llet f√∂r att materialisera direkt - g√∂r str√∂mning interaktionen mer naturlig och ger omedelbar √•terkoppling.

### Implementera str√∂mning med LangChain

```python
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
    streaming=True
)

# Str√∂mma svaret
for chunk in llm.stream("Write a short story about a robot learning to code"):
    print(chunk.content, end="", flush=True)
```

**Varf√∂r str√∂mning √§r fantastiskt:**
- **Visar** inneh√•llet medan det skapas - inget mer pinsamt v√§ntande!
- **F√•r** anv√§ndare att k√§nna att n√•got verkligen h√§nder
- **K√§nns** snabbare, √§ven n√§r det tekniskt inte √§r det
- **L√•ter** anv√§ndare b√∂rja l√§sa medan AI fortfarande "t√§nker"

> üí° **Anv√§ndartips**: Str√∂mning lyser verkligen n√§r du hanterar l√§ngre svar som kodf√∂rklaringar, kreativt skrivande eller detaljerade handledningar. Dina anv√§ndare kommer att √§lska att se framsteg ist√§llet f√∂r att stirra p√• en tom sk√§rm!

### üéØ Pedagogisk kontroll: Ramverksabstraktionsf√∂rdelar

**Pausa och reflektera**: Du har precis upplevt kraften i AI-ramverksabstraktioner. J√§mf√∂r vad du l√§rt dig med r√•a API-anrop fr√•n tidigare lektioner.

**Snabb sj√§lvutv√§rdering**:
- Kan du f√∂rklara hur LangChain f√∂renklar konversationshantering j√§mf√∂rt med manuell meddelandesp√•rning?
- Vad √§r skillnaden mellan `invoke()` och `stream()`-metoderna, och n√§r skulle du anv√§nda varje?
- Hur f√∂rb√§ttrar ramverkets meddelandetyp-system kodorganisationen?

**Verklighetskoppling**: De abstraktionsm√∂nster du l√§rt dig (meddelandetyper, str√∂mningsgr√§nssnitt, konversationsminne) anv√§nds i varje st√∂rre AI-applikation - fr√•n ChatGPT:s gr√§nssnitt till GitHub Copilots kodassistans. Du bem√§strar samma arkitekturprinciper som professionella AI-utvecklingsteam anv√§nder.

**Utmaningsfr√•ga**: Hur skulle du designa en ramverksabstraktion f√∂r att hantera olika AI-modellleverant√∂rer (OpenAI, Anthropic, Google) med ett enda gr√§nssnitt? √ñverv√§g f√∂rdelarna och nackdelarna.

## Promptmallar

Promptmallar fungerar som de retoriska strukturer som anv√§nds i klassisk retorik - t√§nk p√• hur Cicero anpassade sina talm√∂nster f√∂r olika publiker samtidigt som den √∂vertygande ramen beh√∂lls. De l√•ter dig skapa √•teranv√§ndbara prompts d√§r du kan byta ut olika informationsdelar utan att skriva om allt fr√•n b√∂rjan. N√§r du har st√§llt in mallen fyller du bara i variablerna med de v√§rden du beh√∂ver.

### Skapa √•teranv√§ndbara prompts

```python
from langchain_core.prompts import ChatPromptTemplate

# Definiera en mall f√∂r kodf√∂rklaringar
template = ChatPromptTemplate.from_messages([
    ("system", "You are an expert programming instructor. Explain concepts clearly with examples."),
    ("human", "Explain {concept} in {language} with a practical example for {skill_level} developers")
])

# Anv√§nd mallen med olika v√§rden
questions = [
    {"concept": "functions", "language": "JavaScript", "skill_level": "beginner"},
    {"concept": "classes", "language": "Python", "skill_level": "intermediate"},
    {"concept": "async/await", "language": "JavaScript", "skill_level": "advanced"}
]

for question in questions:
    prompt = template.format_messages(**question)
    response = llm.invoke(prompt)
    print(f"Topic: {question['concept']}\n{response.content}\n---\n")
```

**Varf√∂r du kommer att √§lska att anv√§nda mallar:**
- **H√•ller** dina prompts konsekventa √∂ver hela din app
- **Inget mer** r√∂rigt str√§ngsammanfogande - bara rena, enkla variabler
- **Din AI** beter sig f√∂ruts√§gbart eftersom strukturen f√∂rblir densamma
- **Uppdateringar** √§r en enkel match - √§ndra mallen en g√•ng, s√• √§r det fixat √∂verallt

## Strukturerad output

Har du n√•gonsin blivit frustrerad n√§r du f√∂rs√∂kt tolka AI-svar som kommer tillbaka som ostrukturerad text? Strukturerad output √§r som att l√§ra din AI att f√∂lja det systematiska tillv√§gag√•ngss√§tt som Linn√© anv√§nde f√∂r biologisk klassificering - organiserat, f√∂ruts√§gbart och l√§tt att arbeta med. Du kan beg√§ra JSON, specifika datastrukturer eller vilket format du beh√∂ver.

### Definiera outputscheman

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel, Field

class CodeReview(BaseModel):
    score: int = Field(description="Code quality score from 1-10")
    strengths: list[str] = Field(description="List of code strengths")
    improvements: list[str] = Field(description="List of suggested improvements")
    overall_feedback: str = Field(description="Summary feedback")

# St√§ll in parsern
parser = JsonOutputParser(pydantic_object=CodeReview)

# Skapa prompt med formatinstruktioner
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a code reviewer. {format_instructions}"),
    ("human", "Review this code: {code}")
])

# Formatera prompten med instruktioner
chain = prompt | llm | parser

# H√§mta strukturerat svar
code_sample = """
def calculate_average(numbers):
    return sum(numbers) / len(numbers)
"""

result = chain.invoke({
    "code": code_sample,
    "format_instructions": parser.get_format_instructions()
})

print(f"Score: {result['score']}")
print(f"Strengths: {', '.join(result['strengths'])}")
```

**Varf√∂r strukturerad output √§r en spelv√§xlare:**
- **Inget mer** gissande om vilket format du f√•r tillbaka - det √§r konsekvent varje g√•ng
- **Kan** direkt kopplas in i dina databaser och API:er utan extra arbete
- **F√•ngar** konstiga AI-svar innan de f√∂rst√∂r din app
- **G√∂r** din kod renare eftersom du vet exakt vad du arbetar med

## Verktygsanrop

Nu n√•r vi en av de mest kraftfulla funktionerna: verktyg. S√• h√§r ger du din AI praktiska m√∂jligheter bortom konversation. Precis som medeltida skr√•n utvecklade specialiserade verktyg f√∂r specifika hantverk, kan du utrusta din AI med fokuserade instrument. Du beskriver vilka verktyg som √§r tillg√§ngliga, och n√§r n√•gon beg√§r n√•got som matchar, kan din AI agera.

### Anv√§nda Python

L√•t oss l√§gga till n√•gra verktyg s√• h√§r:

```python
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Anm√§rkningar m√•ste ha typen och kan valfritt inkludera ett standardv√§rde och en beskrivning (i den ordningen).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

tools = [add]

functions = {
    "add": lambda a, b: a + b
}
```

S√• vad h√§nder h√§r? Vi skapar en mall f√∂r ett verktyg som heter `add`. Genom att √§rva fr√•n `TypedDict` och anv√§nda de d√§r fina `Annotated`-typerna f√∂r `a` och `b` ger vi LLM en tydlig bild av vad detta verktyg g√∂r och vad det beh√∂ver. Ordboken `functions` √§r som v√•r verktygsl√•da - den ber√§ttar f√∂r v√•r kod exakt vad som ska g√∂ras n√§r AI best√§mmer sig f√∂r att anv√§nda ett specifikt verktyg.

L√•t oss se hur vi anropar LLM med detta verktyg n√§sta:

```python
llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)
```

H√§r anropar vi `bind_tools` med v√•r `tools`-array och d√§rmed har LLM `llm_with_tools` nu kunskap om detta verktyg.

F√∂r att anv√§nda denna nya LLM kan vi skriva f√∂ljande kod:

```python
query = "What is 3 + 12?"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

Nu n√§r vi anropar `invoke` p√• denna nya llm, som har verktyg, f√•r vi kanske egenskapen `tool_calls` ifylld. Om s√• √§r fallet har alla identifierade verktyg en `name` och `args`-egenskap som anger vilket verktyg som ska anropas och med vilka argument. Den fullst√§ndiga koden ser ut s√• h√§r:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Anm√§rkningar m√•ste ha typ och kan valfritt inkludera ett standardv√§rde och beskrivning (i den ordningen).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

tools = [add]

functions = {
    "add": lambda a, b: a + b
}

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)

query = "What is 3 + 12?"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

N√§r du k√∂r denna kod b√∂r du se output som liknar:

```text
TOOL CALL:  15
CONTENT: 
```

AI:n unders√∂kte "What is 3 + 12" och k√§nde igen detta som en uppgift f√∂r verktyget `add`. Som en skicklig bibliotekarie som vet vilken referens som ska konsulteras baserat p√• typen av fr√•ga, gjorde den denna bed√∂mning utifr√•n verktygets namn, beskrivning och f√§ltspecifikationer. Resultatet 15 kommer fr√•n v√•r ordbok `functions` som utf√∂r verktyget:

```python
print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
```

### Ett mer intressant verktyg som anropar ett web-API
Att l√§gga till siffror demonstrerar konceptet, men verkliga verktyg utf√∂r vanligtvis mer komplexa operationer, som att anropa web API:er. L√•t oss ut√∂ka v√•rt exempel till att l√•ta AI h√§mta inneh√•ll fr√•n internet - liknande hur telegrafoperat√∂rer en g√•ng kopplade samman avl√§gsna platser:

```python
class joke(TypedDict):
    """Tell a joke."""

    # Anm√§rkningar m√•ste ha typen och kan valfritt inkludera ett standardv√§rde och beskrivning (i den ordningen).
    category: Annotated[str, ..., "The joke category"]

def get_joke(category: str) -> str:
    response = requests.get(f"https://api.chucknorris.io/jokes/random?category={category}", headers={"Accept": "application/json"})
    if response.status_code == 200:
        return response.json().get("value", f"Here's a {category} joke!")
    return f"Here's a {category} joke!"

functions = {
    "add": lambda a, b: a + b,
    "joke": lambda category: get_joke(category)
}

query = "Tell me a joke about animals"

# resten av koden √§r samma
```

Nu, om du k√∂r denna kod, kommer du att f√• ett svar som s√§ger n√•got i stil med:

```text
TOOL CALL:  Chuck Norris once rode a nine foot grizzly bear through an automatic car wash, instead of taking a shower.
CONTENT:  
```

```mermaid
flowchart TD
    A[Anv√§ndarfr√•ga: "Ber√§tta ett sk√§mt om djur"] --> B[LangChain-analys]
    B --> C{Verktyg tillg√§ngligt?}
    C -->|Ja| D[V√§lj sk√§mtverktyg]
    C -->|Nej| E[Generera direkt svar]
    
    D --> F[Extrahera parametrar]
    F --> G[Ropa sk√§mt(kategori="djur")]
    G --> H[API-f√∂rfr√•gan till chucknorris.io]
    H --> I[Returnera sk√§mtinneh√•ll]
    I --> J[Visa f√∂r anv√§ndare]
    
    E --> K[AI-genererat svar]
    K --> J
    
    subgraph "Verktygsdefinitionslager"
        L[TypedDict-schema]
        M[Funktionsimplementation]
        N[Parameterkontroll]
    end
    
    D --> L
    F --> N
    G --> M
```
H√§r √§r koden i sin helhet:

```python
from langchain_openai import ChatOpenAI
import requests
import os
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Anm√§rkningar m√•ste ha typen och kan valfritt inkludera ett standardv√§rde och beskrivning (i den ordningen).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

class joke(TypedDict):
    """Tell a joke."""

    # Anm√§rkningar m√•ste ha typen och kan valfritt inkludera ett standardv√§rde och beskrivning (i den ordningen).
    category: Annotated[str, ..., "The joke category"]

tools = [add, joke]

def get_joke(category: str) -> str:
    response = requests.get(f"https://api.chucknorris.io/jokes/random?category={category}", headers={"Accept": "application/json"})
    if response.status_code == 200:
        return response.json().get("value", f"Here's a {category} joke!")
    return f"Here's a {category} joke!"

functions = {
    "add": lambda a, b: a + b,
    "joke": lambda category: get_joke(category)
}

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)

query = "Tell me a joke about animals"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        # print("VERKTYGSANROP: ", tool)
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

## Embeddings och dokumentbearbetning

Embeddings representerar en av de mest eleganta l√∂sningarna inom modern AI. F√∂rest√§ll dig att du kan ta vilken textbit som helst och omvandla den till numeriska koordinater som f√•ngar dess betydelse. Det √§r precis vad embeddings g√∂r - de omvandlar text till punkter i ett flerdimensionellt rum d√§r liknande koncept klustras tillsammans. Det √§r som att ha ett koordinatsystem f√∂r id√©er, p√•minnande om hur Mendeleev organiserade det periodiska systemet efter atom√§ra egenskaper.

### Skapa och anv√§nda embeddings

```python
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter

# Initiera inb√§ddningar
embeddings = OpenAIEmbeddings(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="text-embedding-3-small"
)

# Ladda och dela upp dokument
loader = TextLoader("documentation.txt")
documents = loader.load()

text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(documents)

# Skapa vektorlagring
vectorstore = FAISS.from_documents(texts, embeddings)

# Utf√∂r likhetss√∂kning
query = "How do I handle user authentication?"
similar_docs = vectorstore.similarity_search(query, k=3)

for doc in similar_docs:
    print(f"Relevant content: {doc.page_content[:200]}...")
```

### Dokumentladdare f√∂r olika format

```python
from langchain_community.document_loaders import (
    PyPDFLoader,
    CSVLoader,
    JSONLoader,
    WebBaseLoader
)

# Ladda olika dokumenttyper
pdf_loader = PyPDFLoader("manual.pdf")
csv_loader = CSVLoader("data.csv")
json_loader = JSONLoader("config.json")
web_loader = WebBaseLoader("https://example.com/docs")

# Bearbeta alla dokument
all_documents = []
for loader in [pdf_loader, csv_loader, json_loader, web_loader]:
    docs = loader.load()
    all_documents.extend(docs)
```

**Vad du kan g√∂ra med embeddings:**
- **Bygga** s√∂kningar som verkligen f√∂rst√•r vad du menar, inte bara nyckelordsmatchning
- **Skapa** AI som kan svara p√• fr√•gor om dina dokument
- **G√∂ra** rekommendationssystem som f√∂resl√•r verkligt relevant inneh√•ll
- **Automatiskt** organisera och kategorisera ditt inneh√•ll

```mermaid
flowchart LR
    A[Dokument] --> B[Textdelare]
    B --> C[Skapa Embeddings]
    C --> D[Vektorbutik]
    
    E[Anv√§ndarfr√•ga] --> F[Fr√•geembedding]
    F --> G[Likhetss√∂kning]
    G --> D
    D --> H[Relevanta Dokument]
    H --> I[AI-svar]
    
    subgraph "Vektorutrymme"
        J[Dokument A: [0.1, 0.8, 0.3...]]
        K[Dokument B: [0.2, 0.7, 0.4...]]
        L[Fr√•ga: [0.15, 0.75, 0.35...]]
    end
    
    C --> J
    C --> K
    F --> L
    G --> J
    G --> K
```
## Bygga en komplett AI-applikation

Nu ska vi integrera allt du l√§rt dig till en omfattande applikation - en kodningsassistent som kan svara p√• fr√•gor, anv√§nda verktyg och beh√•lla samtalsminne. Precis som boktryckarkonsten kombinerade befintliga teknologier (r√∂rlig typ, bl√§ck, papper och tryck) till n√•got transformerande, kommer vi kombinera v√•ra AI-komponenter till n√•got praktiskt och anv√§ndbart.

### Komplett applikationsexempel

```python
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_community.vectorstores import FAISS
from typing_extensions import Annotated, TypedDict
import os
import requests

class CodingAssistant:
    def __init__(self):
        self.llm = ChatOpenAI(
            api_key=os.environ["GITHUB_TOKEN"],
            base_url="https://models.github.ai/inference",
            model="openai/gpt-4o-mini"
        )
        
        self.conversation_history = [
            SystemMessage(content="""You are an expert coding assistant. 
            Help users learn programming concepts, debug code, and write better software.
            Use tools when needed and maintain a helpful, encouraging tone.""")
        ]
        
        # Definiera verktyg
        self.setup_tools()
    
    def setup_tools(self):
        class web_search(TypedDict):
            """Search for programming documentation or examples."""
            query: Annotated[str, "Search query for programming help"]
        
        class code_formatter(TypedDict):
            """Format and validate code snippets."""
            code: Annotated[str, "Code to format"]
            language: Annotated[str, "Programming language"]
        
        self.tools = [web_search, code_formatter]
        self.llm_with_tools = self.llm.bind_tools(self.tools)
    
    def chat(self, user_input: str):
        # L√§gg till anv√§ndarmeddelande i konversationen
        self.conversation_history.append(HumanMessage(content=user_input))
        
        # H√§mta AI-svar
        response = self.llm_with_tools.invoke(self.conversation_history)
        
        # Hantera verktygsanrop om n√•gra finns
        if response.tool_calls:
            for tool_call in response.tool_calls:
                tool_result = self.execute_tool(tool_call)
                print(f"üîß Tool used: {tool_call['name']}")
                print(f"üìä Result: {tool_result}")
        
        # L√§gg till AI-svar i konversationen
        self.conversation_history.append(response)
        
        return response.content
    
    def execute_tool(self, tool_call):
        tool_name = tool_call['name']
        args = tool_call['args']
        
        if tool_name == 'web_search':
            return f"Found documentation for: {args['query']}"
        elif tool_name == 'code_formatter':
            return f"Formatted {args['language']} code: {args['code'][:50]}..."
        
        return "Tool execution completed"

# Anv√§ndningsexempel
assistant = CodingAssistant()

print("ü§ñ Coding Assistant Ready! Type 'quit' to exit.\n")

while True:
    user_input = input("You: ")
    if user_input.lower() == 'quit':
        break
    
    response = assistant.chat(user_input)
    print(f"ü§ñ Assistant: {response}\n")
```

**Applikationsarkitektur:**

```mermaid
graph TD
    A[Anv√§ndarinmatning] --> B[Kodassistent]
    B --> C[Samtalsminne]
    B --> D[Verktygsigenk√§nning]
    B --> E[LLM-bearbetning]
    
    D --> F[Webbs√∂kningsverktyg]
    D --> G[Kodformateringsverktyg]
    
    E --> H[Svarsgenerering]
    F --> H
    G --> H
    
    H --> I[Anv√§ndargr√§nssnitt]
    H --> C
```
**Nyckelfunktioner vi implementerat:**
- **Kommer ih√•g** hela din konversation f√∂r kontinuitet i kontexten
- **Utf√∂r √•tg√§rder** genom att anropa verktyg, inte bara konversation
- **F√∂ljer** f√∂ruts√§gbara interaktionsm√∂nster
- **Hanterar** fel och komplexa arbetsfl√∂den automatiskt

### üéØ Pedagogisk avst√§mning: Produktions-AI-arkitektur

**F√∂rst√•else av arkitektur**: Du har byggt en komplett AI-applikation som kombinerar konversationshantering, verktygsanrop och strukturerade arbetsfl√∂den. Detta representerar utveckling av AI-applikationer p√• produktionsniv√•.

**Centrala koncept beh√§rskade**:
- **Klassbaserad arkitektur**: Organiserad och underh√•llbar AI-applikationsstruktur
- **Verktygsintegration**: Anpassad funktionalitet ut√∂ver konversation
- **Minneshantering**: Best√•ende kontext f√∂r konversation
- **Felhantering**: Robust applikationsbeteende

**Branschkoppling**: De arkitekturm√∂nster du implementerat (konversationsklasser, verktygssystem, minneshantering) √§r samma som anv√§nds i f√∂retags-AI-applikationer som Slack's AI-assistent, GitHub Copilot och Microsoft Copilot. Du bygger med professionellt arkitekturt√§nk.

**Reflektionsfr√•ga**: Hur skulle du ut√∂ka denna applikation f√∂r att hantera flera anv√§ndare, best√§ndig lagring eller integration med externa databaser? T√§nk p√• skalbarhet och tillst√•ndshantering.

## Uppgift: Bygg din egen AI-drivna studierassistent

**M√•l**: Skapa en AI-applikation som hj√§lper studenter att l√§ra sig programmeringskoncept genom att erbjuda f√∂rklaringar, kodexempel och interaktiva quiz.

### Krav

**K√§rnfunktioner (Obligatoriska):**
1. **Konversationsgr√§nssnitt**: Implementera ett chatt-system som beh√•ller kontext √∂ver flera fr√•gor
2. **Utbildningsverktyg**: Skapa minst tv√• verktyg som hj√§lper med l√§randet:
   - Verktyg f√∂r kodf√∂rklaring
   - Quizgenerator f√∂r konceptfr√•gor
3. **Personanpassat l√§rande**: Anv√§nd systemmeddelanden f√∂r att anpassa svar efter olika kunskapsniv√•er
4. **Svarformatering**: Implementera strukturerad utdata f√∂r quizfr√•gor

### Implementeringssteg

**Steg 1: St√§ll in din milj√∂**
```bash
pip install langchain langchain-openai
```

**Steg 2: Grundl√§ggande chattfunktionalitet**
- Skapa en `StudyAssistant`-klass
- Implementera samtalsminne
- L√§gg till personlighet f√∂r pedagogiskt st√∂d

**Steg 3: L√§gg till utbildningsverktyg**
- **Kodf√∂rklarare**: Bryter ner kod i begripliga delar
- **Quizgenerator**: Skapar fr√•gor om programmeringskoncept
- **Framstegsregistrerare**: H√•ller koll p√• t√§ckta √§mnen

**Steg 4: Avancerade funktioner (valfritt)**
- Implementera str√∂mmade svar f√∂r b√§ttre anv√§ndarupplevelse
- L√§gg till dokumentladdning f√∂r att inkludera kursmaterial
- Skapa embeddings f√∂r likhetsbaserad inneh√•llsh√§mtning

### Utv√§rderingskriterier

| Funktion | Utm√§rkt (4) | Bra (3) | Tillfredsst√§llande (2) | Beh√∂ver f√∂rb√§ttras (1) |
|---------|--------------|---------|------------------------|------------------------|
| **Konversationsfl√∂de** | Naturliga, kontextmedvetna svar | Bra kontextbeh√•llning | Grundl√§ggande konversation | Inget minne mellan meddelanden |
| **Verktygsintegration** | Flera anv√§ndbara verktyg fungerar s√∂ml√∂st | 2+ verktyg implementerade korrekt | 1-2 grundl√§ggande verktyg | Verktyg fungerar inte |
| **Kodkvalitet** | Ren, v√§l dokumenterad, felhantering | Bra struktur, viss dokumentation | Grundl√§ggande funktionalitet fungerar | D√•lig struktur, ingen felhantering |
| **Pedagogiskt v√§rde** | Verkligen hj√§lpsam f√∂r l√§rande, adaptiv | Bra st√∂d f√∂r l√§rande | Grundl√§ggande f√∂rklaringar | Begr√§nsat pedagogiskt v√§rde |

### Exempel p√• kodstruktur

```python
class StudyAssistant:
    def __init__(self, skill_level="beginner"):
        # Initialisera LLM, verktyg och samtalsminne
        pass
    
    def explain_code(self, code, language):
        # Verktyg: F√∂rklara hur koden fungerar
        pass
    
    def generate_quiz(self, topic, difficulty):
        # Verktyg: Skapa √∂vningsfr√•gor
        pass
    
    def chat(self, user_input):
        # Huvudgr√§nssnitt f√∂r konversation
        pass

# Exempel p√• anv√§ndning
assistant = StudyAssistant(skill_level="intermediate")
response = assistant.chat("Explain how Python functions work")
```

**Bonusutmaningar:**
- L√§gg till r√∂stinmatning/-utmatning
- Implementera ett webbgr√§nssnitt med Streamlit eller Flask
- Skapa en kunskapsbas fr√•n kursmaterial med embeddings
- L√§gg till framstegsuppf√∂ljning och personliga l√§rv√§gar

## üìà Din tidslinje f√∂r m√§sterskap i AI-ramverksutveckling

```mermaid
timeline
    title Produktions AI-ramverksutvecklingsresa
    
    section Ramverksgrunder
        F√∂rst√• abstraktioner
            : Master ramverk vs API-beslut
            : L√§ra sig LangChain k√§rnkoncept
            : Implementera meddelandetyp-system
        
        Grundl√§ggande integration
            : Anslut till AI-leverant√∂rer
            : Hantera autentisering
            : Hantera konfiguration
    
    section Konversationssystem
        Minneshantering
            : Bygg konversationshistorik
            : Implementera kontextsp√•rning
            : Hantera sessionspersistens
        
        Avancerade interaktioner
            : Bem√§stra str√∂mmande svar
            : Skapa promptmallar
            : Implementera strukturerad output
    
    section Verktygsintegration
        Anpassad verktygsutveckling
            : Designa verktygsscheman
            : Implementera funktionsanrop
            : Hantera externa API:er
        
        Arbetsfl√∂desautomatisering
            : K√§tt ihop flera verktyg
            : Skapa beslutsgranar
            : Bygg agentbeteenden
    
    section Produktionsapplikationer
        Komplett systemarkitektur
            : Kombinera alla ramverksfunktioner
            : Implementera felgr√§nser
            : Skapa underh√•llbar kod
        
        F√∂retagsberedskap
            : Hantera skalbarhetsfr√•gor
            : Implementera √∂vervakning
            : Bygg distributionsstrategier
```
**üéì Examensmilstolpe**: Du har framg√•ngsrikt beh√§rskat AI-ramverksutveckling med samma verktyg och m√∂nster som driver moderna AI-applikationer. Dessa f√§rdigheter representerar framkanten inom AI-applikationsutveckling och f√∂rbereder dig f√∂r att bygga intelligenta system i f√∂retagsklass.

**üîÑ N√§sta niv√•-funktioner**:
- Redo att utforska avancerade AI-arkitekturer (agenter, multi-agent system)
- F√∂rberedd f√∂r att bygga RAG-system med vektordatabaser
- Utrustad f√∂r att skapa multimodala AI-applikationer
- Grundlagd f√∂r skalning och optimering av AI-applikationer

## Sammanfattning

üéâ Du har nu beh√§rskat grunderna i AI-ramverksutveckling och l√§rt dig hur man bygger sofistikerade AI-applikationer med LangChain. Som att genomf√∂ra en omfattande l√§rlingsutbildning har du samlat en betydande verktygsl√•da av f√§rdigheter. L√•t oss g√• igenom vad du har √•stadkommit.

### Vad du har l√§rt dig

**K√§rnkoncept f√∂r ramverk:**
- **Ramverksf√∂rdelar**: F√∂rst√• n√§r man ska v√§lja ramverk √∂ver direkta API-anrop
- **LangChains grunder**: St√§lla in och konfigurera AI-modellsanslutningar
- **Meddelandetyper**: Anv√§nda `SystemMessage`, `HumanMessage` och `AIMessage` f√∂r strukturerade konversationer

**Avancerade funktioner:**
- **Verktygsanrop**: Skapa och integrera anpassade verktyg f√∂r f√∂rb√§ttrade AI-m√∂jligheter
- **Samtalsminne**: Beh√•lla kontext √∂ver flera samtalsturer
- **Str√∂mmande svar**: Implementera realtidsleverans av svar
- **Promptmallar**: Bygga √•teranv√§ndbara, dynamiska promptingar
- **Strukturerad utdata**: S√§kerst√§lla konsekventa, parsbara AI-svar
- **Embeddings**: Skapa semantisk s√∂kning och dokumenthantering

**Praktiska till√§mpningar:**
- **Bygga kompletta appar**: Kombinera flera funktioner till produktionsklara applikationer
- **Felhantering**: Implementera robust felhantering och validering
- **Verktygsintegration**: Skapa anpassade verktyg som ut√∂kar AI-funktionalitet

### Viktiga insikter

> üéØ **Kom ih√•g**: AI-ramverk som LangChain √§r i princip dina komplexitetssmusslande, funktionsfyllda b√§sta v√§nner. De √§r perfekta n√§r du beh√∂ver samtalsminne, verktygsanrop eller vill arbeta med flera AI-modeller utan att tappa f√∂rst√•ndet.

**Beslutsram f√∂r AI-integration:**

```mermaid
flowchart TD
    A[Behov av AI-integration] --> B{Enkel enkel fr√•gest√§llning?}
    B -->|Ja| C[Direkta API-anrop]
    B -->|Nej| D{Beh√∂vs samtalsminne?}
    D -->|Nej| E[SDK-integration]
    D -->|Ja| F{Beh√∂vs verktyg eller avancerade funktioner?}
    F -->|Nej| G[Ramverk med grundl√§ggande upps√§ttning]
    F -->|Ja| H[Fullst√§ndig ramverksimplementering]
    
    C --> I[HTTP-f√∂rfr√•gningar, minimala beroenden]
    E --> J[Provider SDK, modell-specifik]
    G --> K[LangChain grundl√§ggande chatt]
    H --> L[LangChain med verktyg, minne, agenter]
```
### Vad g√∂r du h√§rn√§st?

**B√∂rja bygga direkt:**
- Ta dessa koncept och bygg n√•got som EXCITERAR DIG!
- Lek med olika AI-modeller via LangChain ‚Äì det √§r som en lekplats f√∂r AI-modeller
- Skapa verktyg som l√∂ser riktiga problem du m√∂ter i arbete eller projekt

**Redo f√∂r n√§sta niv√•?**
- **AI-agenter**: Bygg AI-system som faktiskt kan planera och utf√∂ra komplexa uppgifter sj√§lvst√§ndigt
- **RAG (Retrieval-Augmented Generation)**: Kombinera AI med egna kunskapsbaser f√∂r superkraftfulla applikationer
- **Multimodal AI**: Arbeta med text, bilder och ljud tillsammans ‚Äì m√∂jligheterna √§r o√§ndliga!
- **Produktionss√§ttning**: L√§r dig hur du skalar dina AI-appar och √∂vervakar dem i verkliga v√§rlden

**G√• med i communityn:**
- LangChain-communityn √§r fantastisk f√∂r att h√•lla sig uppdaterad och l√§ra sig b√§sta praxis
- GitHub Models ger dig tillg√•ng till toppmoderna AI-funktioner ‚Äì perfekt f√∂r experiment
- Forts√§tt √∂va med olika anv√§ndningsfall ‚Äì varje projekt l√§r dig n√•got nytt

Du har nu kunskapen att bygga intelligenta, konverserande applikationer som kan hj√§lpa m√§nniskor att l√∂sa verkliga problem. Precis som ren√§ssanshantverkare som kombinerade konstn√§rlig vision med teknisk skicklighet, kan du nu f√∂rena AI-funktioner med praktisk till√§mpning. Fr√•gan √§r: vad kommer du skapa? üöÄ

## GitHub Copilot Agent-utmaningen üöÄ

Anv√§nd Agent-l√§get f√∂r att slutf√∂ra f√∂ljande utmaning:

**Beskrivning:** Bygg en avancerad AI-driven kodgranskningsassistent som kombinerar flera LangChain-funktioner inklusive verktygsanrop, strukturerad utdata och samtalsminne f√∂r att ge omfattande feedback p√• kodins√§ndningar.

**Prompt:** Skapa en CodeReviewAssistant-klass som implementerar:
1. Ett verktyg f√∂r att analysera kodkomplexitet och f√∂resl√• f√∂rb√§ttringar
2. Ett verktyg f√∂r att kontrollera kod mot b√§sta praxis
3. Strukturerad utdata med Pydantic-modeller f√∂r konsekvent granskningsformat
4. Samtalsminne f√∂r att sp√•ra granskningssessioner
5. Ett huvudchattgr√§nssnitt som kan hantera kodins√§ndningar och ge detaljerad, handlingsbar feedback

Assistenten ska kunna granska kod i flera programmeringsspr√•k, beh√•lla kontext √∂ver flera kodins√§ndningar i en session och ge b√•de sammanfattande betyg och detaljerade f√∂rb√§ttringsf√∂rslag.

L√§s mer om [agent-l√§get](https://code.visualstudio.com/blogs/2025/02/24/introducing-copilot-agent-mode) h√§r.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Ansvarsfriskrivning**:
Detta dokument har √∂versatts med hj√§lp av AI-√∂vers√§ttningstj√§nsten [Co-op Translator](https://github.com/Azure/co-op-translator). √Ñven om vi str√§var efter noggrannhet, var v√§nlig uppm√§rksam p√• att automatiska √∂vers√§ttningar kan inneh√•lla fel eller brister. Det ursprungliga dokumentet p√• dess modersm√•l b√∂r betraktas som den auktoritativa k√§llan. F√∂r viktig information rekommenderas professionell m√§nsklig √∂vers√§ttning. Vi ansvarar inte f√∂r n√•gra missf√∂rst√•nd eller feltolkningar som uppst√•r fr√•n anv√§ndningen av denna √∂vers√§ttning.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->