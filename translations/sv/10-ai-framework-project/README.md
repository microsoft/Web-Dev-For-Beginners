<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2c4ae5688e34b4b8b09d52aec56c79e",
  "translation_date": "2025-10-23T21:34:05+00:00",
  "source_file": "10-ai-framework-project/README.md",
  "language_code": "sv"
}
-->
# AI-ramverk

Har du n친gonsin k칛nt dig 칬verv칛ldigad n칛r du f칬rs칬ker bygga AI-applikationer fr친n grunden? Du 칛r inte ensam! AI-ramverk 칛r som en schweizisk arm칠kniv f칬r AI-utveckling - kraftfulla verktyg som kan spara dig tid och huvudv칛rk n칛r du bygger intelligenta applikationer. T칛nk p친 ett AI-ramverk som ett v칛lorganiserat bibliotek: det erbjuder f칛rdigbyggda komponenter, standardiserade API:er och smarta abstraktioner s친 att du kan fokusera p친 att l칬sa problem ist칛llet f칬r att brottas med implementeringsdetaljer.

I den h칛r lektionen kommer vi att utforska hur ramverk som LangChain kan f칬rvandla tidigare komplexa AI-integreringsuppgifter till ren och l칛sbar kod. Du kommer att uppt칛cka hur du kan hantera verkliga utmaningar som att h친lla koll p친 konversationer, implementera verktygsanrop och jonglera olika AI-modeller genom ett enhetligt gr칛nssnitt.

N칛r vi 칛r klara kommer du att veta n칛r du ska anv칛nda ramverk ist칛llet f칬r r친a API-anrop, hur du anv칛nder deras abstraktioner effektivt och hur du bygger AI-applikationer som 칛r redo f칬r verklig anv칛ndning. L친t oss utforska vad AI-ramverk kan g칬ra f칬r dina projekt.

## Varf칬r v칛lja ett ramverk?

S친 du 칛r redo att bygga en AI-app - fantastiskt! Men h칛r 칛r grejen: du har flera olika v칛gar att ta, och varje har sina egna f칬r- och nackdelar. Det 칛r lite som att v칛lja mellan att g친, cykla eller k칬ra bil f칬r att komma n친gonstans - alla tar dig dit, men upplevelsen (och anstr칛ngningen) kommer att vara helt olika.

L친t oss bryta ner de tre huvudsakliga s칛tten du kan integrera AI i dina projekt:

| Tillv칛gag친ngss칛tt | F칬rdelar | B칛st f칬r | 칐verv칛ganden |
|-------------------|----------|----------|--------------|
| **Direkta HTTP-anrop** | Full kontroll, inga beroenden | Enkla fr친gor, l칛ra sig grunderna | Mer detaljerad kod, manuell felhantering |
| **SDK-integration** | Mindre boilerplate, modell-specifik optimering | Applikationer med en modell | Begr칛nsad till specifika leverant칬rer |
| **AI-ramverk** | Enhetligt API, inbyggda abstraktioner | Appar med flera modeller, komplexa arbetsfl칬den | Inl칛rningskurva, potentiell 칬ver-abstraktion |

### F칬rdelar med ramverk i praktiken

```mermaid
graph TD
    A[Your Application] --> B[AI Framework]
    B --> C[OpenAI GPT]
    B --> D[Anthropic Claude]
    B --> E[GitHub Models]
    B --> F[Local Models]
    
    B --> G[Built-in Tools]
    G --> H[Memory Management]
    G --> I[Conversation History]
    G --> J[Function Calling]
    G --> K[Error Handling]
```

**Varf칬r ramverk 칛r viktiga:**
- **Enhetligg칬r** flera AI-leverant칬rer under ett gr칛nssnitt
- **Hantera** konversationsminne automatiskt
- **Tillhandah친ller** f칛rdiga verktyg f칬r vanliga uppgifter som embeddings och funktionsanrop
- **Sk칬ter** felhantering och 친terf칬rs칬kslogik
- **F칬rvandlar** komplexa arbetsfl칬den till l칛sbara metodanrop

> 游눠 **Proffstips**: Anv칛nd ramverk n칛r du v칛xlar mellan olika AI-modeller eller bygger komplexa funktioner som agenter, minne eller verktygsanrop. H친ll dig till direkta API:er n칛r du l칛r dig grunderna eller bygger enkla, fokuserade applikationer.

**Slutsats**: Precis som att v칛lja mellan en hantverkares specialverktyg och en komplett verkstad handlar det om att matcha verktyget med uppgiften. Ramverk 칛r utm칛rkta f칬r komplexa, funktionsrika applikationer, medan direkta API:er fungerar bra f칬r enkla anv칛ndningsfall.

## Introduktion

I den h칛r lektionen kommer vi att l칛ra oss att:

- Anv칛nda ett vanligt AI-ramverk.
- Hantera vanliga problem som chattkonversationer, verktygsanv칛ndning, minne och kontext.
- Utnyttja detta f칬r att bygga AI-appar.

## Din f칬rsta AI-prompt

L친t oss b칬rja med grunderna genom att skapa din f칬rsta AI-applikation som skickar en fr친ga och f친r ett svar tillbaka. Precis som Archimedes uppt칛ckte principen om f칬rskjutning i sitt badkar kan ibland de enklaste observationerna leda till de mest kraftfulla insikterna - och ramverk g칬r dessa insikter tillg칛ngliga.

### St칛lla in LangChain med GitHub-modeller

Vi ska anv칛nda LangChain f칬r att ansluta till GitHub-modeller, vilket 칛r riktigt bra eftersom det ger dig gratis tillg친ng till olika AI-modeller. Det b칛sta? Du beh칬ver bara n친gra enkla konfigurationsparametrar f칬r att komma ig친ng:

```python
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

# Send a simple prompt
response = llm.invoke("What's the capital of France?")
print(response.content)
```

**L친t oss bryta ner vad som h칛nder h칛r:**
- **Skapar** en LangChain-klient med klassen `ChatOpenAI` - detta 칛r din port till AI!
- **Konfigurerar** anslutningen till GitHub-modeller med din autentiseringstoken
- **Anger** vilken AI-modell som ska anv칛ndas (`gpt-4o-mini`) - t칛nk p친 detta som att v칛lja din AI-assistent
- **Skickar** din fr친ga med metoden `invoke()` - h칛r sker magin
- **Extraherar** och visar svaret - och voil, du chattar med AI!

> 游댢 **Inst칛llningsnotering**: Om du anv칛nder GitHub Codespaces har du tur - `GITHUB_TOKEN` 칛r redan inst칛llt f칬r dig! Arbetar du lokalt? Ingen fara, du beh칬ver bara skapa en personlig 친tkomsttoken med r칛tt beh칬righeter.

**F칬rv칛ntat resultat:**
```text
The capital of France is Paris.
```

```mermaid
sequenceDiagram
    participant App as Your Python App
    participant LC as LangChain
    participant GM as GitHub Models
    participant AI as GPT-4o-mini
    
    App->>LC: llm.invoke("What's the capital of France?")
    LC->>GM: HTTP request with prompt
    GM->>AI: Process prompt
    AI->>GM: Generated response
    GM->>LC: Return response
    LC->>App: response.content
```

## Bygga konverserande AI

Det f칬rsta exemplet visar grunderna, men det 칛r bara ett enda utbyte - du st칛ller en fr친ga, f친r ett svar och det 칛r allt. I verkliga applikationer vill du att din AI ska komma ih친g vad ni har diskuterat, ungef칛r som hur Watson och Holmes byggde sina unders칬kande samtal 칬ver tid.

Det 칛r h칛r LangChain blir s칛rskilt anv칛ndbart. Det tillhandah친ller olika meddelandetyper som hj칛lper till att strukturera konversationer och l친ter dig ge din AI en personlighet. Du kommer att bygga chattupplevelser som bibeh친ller kontext och karakt칛r.

### F칬rst친 meddelandetyper

T칛nk p친 dessa meddelandetyper som olika "roller" som deltagarna har i en konversation. LangChain anv칛nder olika meddelandeklasser f칬r att h친lla reda p친 vem som s칛ger vad:

| Meddelandetyp | Syfte | Exempel p친 anv칛ndning |
|---------------|-------|-----------------------|
| `SystemMessage` | Definierar AI:s personlighet och beteende | "Du 칛r en hj칛lpsam kodningsassistent" |
| `HumanMessage` | Representerar anv칛ndarinmatning | "F칬rklara hur funktioner fungerar" |
| `AIMessage` | Lagrar AI-svar | Tidigare AI-svar i konversationen |

### Skapa din f칬rsta konversation

L친t oss skapa en konversation d칛r v친r AI antar en specifik roll. Vi l친ter den gestalta kapten Picard - en karakt칛r k칛nd f칬r sin diplomatiska visdom och ledarskap:

```python
messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]
```

**Bryta ner denna konversationsinst칛llning:**
- **Fastst칛ller** AI:s roll och personlighet genom `SystemMessage`
- **Tillhandah친ller** den initiala anv칛ndarfr친gan via `HumanMessage`
- **Skapar** en grund f칬r flerv칛gs-konversation

Den fullst칛ndiga koden f칬r detta exempel ser ut s친 h칛r:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]


# works
response  = llm.invoke(messages)
print(response.content)
```

Du b칬r se ett resultat som liknar:

```text
I am Captain Jean-Luc Picard, the commanding officer of the USS Enterprise (NCC-1701-D), a starship in the United Federation of Planets. My primary mission is to explore new worlds, seek out new life and new civilizations, and boldly go where no one has gone before. 

I believe in the importance of diplomacy, reason, and the pursuit of knowledge. My crew is diverse and skilled, and we often face challenges that test our resolve, ethics, and ingenuity. Throughout my career, I have encountered numerous species, grappled with complex moral dilemmas, and have consistently sought peaceful solutions to conflicts.

I hold the ideals of the Federation close to my heart, believing in the importance of cooperation, understanding, and respect for all sentient beings. My experiences have shaped my leadership style, and I strive to be a thoughtful and just captain. How may I assist you further?
```

F칬r att bibeh친lla konversationskontinuitet (ist칛llet f칬r att 친terst칛lla kontext varje g친ng) m친ste du forts칛tta l칛gga till svar i din meddelandelista. Precis som muntliga traditioner bevarade ber칛ttelser 칬ver generationer bygger detta en varaktig minnesbank:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]


# works
response  = llm.invoke(messages)

print(response.content)

print("---- Next ----")

messages.append(response)
messages.append(HumanMessage(content="Now that I know about you, I'm Chris, can I be in your crew?"))

response  = llm.invoke(messages)

print(response.content)

```

Ganska h칛ftigt, eller hur? Vad som h칛nder h칛r 칛r att vi anropar LLM tv친 g친nger - f칬rst med bara v친ra initiala tv친 meddelanden, men sedan igen med hela konversationshistoriken. Det 칛r som om AI faktiskt f칬ljer med i v친r chatt!

N칛r du k칬r denna kod f친r du ett andra svar som l친ter ungef칛r s친 h칛r:

```text
Welcome aboard, Chris! It's always a pleasure to meet those who share a passion for exploration and discovery. While I cannot formally offer you a position on the Enterprise right now, I encourage you to pursue your aspirations. We are always in need of talented individuals with diverse skills and backgrounds. 

If you are interested in space exploration, consider education and training in the sciences, engineering, or diplomacy. The values of curiosity, resilience, and teamwork are crucial in Starfleet. Should you ever find yourself on a starship, remember to uphold the principles of the Federation: peace, understanding, and respect for all beings. Your journey can lead you to remarkable adventures, whether in the stars or on the ground. Engage!
```

Jag tar det som ett kanske ;)

## Str칬mmande svar

Har du n친gonsin m칛rkt hur ChatGPT verkar "skriva" sina svar i realtid? Det 칛r str칬mning i aktion. Precis som att se en skicklig kalligraf arbeta - att se tecken dyka upp streck f칬r streck ist칛llet f칬r att materialiseras direkt - g칬r str칬mning interaktionen mer naturlig och ger omedelbar feedback.

### Implementera str칬mning med LangChain

```python
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
    streaming=True
)

# Stream the response
for chunk in llm.stream("Write a short story about a robot learning to code"):
    print(chunk.content, end="", flush=True)
```

**Varf칬r str칬mning 칛r fantastiskt:**
- **Visar** inneh친ll medan det skapas - ingen mer pinsam v칛ntan!
- **F친r** anv칛ndare att k칛nna att n친got faktiskt h칛nder
- **K칛nns** snabbare, 칛ven n칛r det tekniskt sett inte 칛r det
- **L친ter** anv칛ndare b칬rja l칛sa medan AI fortfarande "t칛nker"

> 游눠 **Anv칛ndarupplevelsetips**: Str칬mning 칛r verkligen anv칛ndbart n칛r du hanterar l칛ngre svar som kodf칬rklaringar, kreativt skrivande eller detaljerade handledningar. Dina anv칛ndare kommer att 칛lska att se framsteg ist칛llet f칬r att stirra p친 en tom sk칛rm!

## Promptmallar

Promptmallar fungerar som de retoriska strukturer som anv칛ndes i klassisk retorik - t칛nk p친 hur Cicero skulle anpassa sina talm칬nster f칬r olika publiker samtidigt som han beh칬ll samma 칬vertygande ramverk. De l친ter dig skapa 친teranv칛ndbara prompts d칛r du kan byta ut olika informationsdelar utan att beh칬va skriva om allt fr친n b칬rjan. N칛r du har st칛llt in mallen fyller du bara i variablerna med de v칛rden du beh칬ver.

### Skapa 친teranv칛ndbara prompts

```python
from langchain_core.prompts import ChatPromptTemplate

# Define a template for code explanations
template = ChatPromptTemplate.from_messages([
    ("system", "You are an expert programming instructor. Explain concepts clearly with examples."),
    ("human", "Explain {concept} in {language} with a practical example for {skill_level} developers")
])

# Use the template with different values
questions = [
    {"concept": "functions", "language": "JavaScript", "skill_level": "beginner"},
    {"concept": "classes", "language": "Python", "skill_level": "intermediate"},
    {"concept": "async/await", "language": "JavaScript", "skill_level": "advanced"}
]

for question in questions:
    prompt = template.format_messages(**question)
    response = llm.invoke(prompt)
    print(f"Topic: {question['concept']}\n{response.content}\n---\n")
```

**Varf칬r du kommer att 칛lska att anv칛nda mallar:**
- **H친ller** dina prompts konsekventa 칬ver hela din app
- **Ingen mer** r칬rig str칛ngkonkatenering - bara rena, enkla variabler
- **Din AI** beter sig f칬ruts칛gbart eftersom strukturen f칬rblir densamma
- **Uppdateringar** 칛r enkla - 칛ndra mallen en g친ng, och det 칛r fixat 칬verallt

## Strukturerad output

Har du n친gonsin blivit frustrerad 칬ver att f칬rs칬ka tolka AI-svar som kommer tillbaka som ostrukturerad text? Strukturerad output 칛r som att l칛ra din AI att f칬lja det systematiska tillv칛gag친ngss칛tt som Linn칠 anv칛nde f칬r biologisk klassificering - organiserat, f칬ruts칛gbart och l칛tt att arbeta med. Du kan beg칛ra JSON, specifika datastrukturer eller vilket format du beh칬ver.

### Definiera output-scheman

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel, Field

class CodeReview(BaseModel):
    score: int = Field(description="Code quality score from 1-10")
    strengths: list[str] = Field(description="List of code strengths")
    improvements: list[str] = Field(description="List of suggested improvements")
    overall_feedback: str = Field(description="Summary feedback")

# Set up the parser
parser = JsonOutputParser(pydantic_object=CodeReview)

# Create prompt with format instructions
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a code reviewer. {format_instructions}"),
    ("human", "Review this code: {code}")
])

# Format the prompt with instructions
chain = prompt | llm | parser

# Get structured response
code_sample = """
def calculate_average(numbers):
    return sum(numbers) / len(numbers)
"""

result = chain.invoke({
    "code": code_sample,
    "format_instructions": parser.get_format_instructions()
})

print(f"Score: {result['score']}")
print(f"Strengths: {', '.join(result['strengths'])}")
```

**Varf칬r strukturerad output 칛r en game-changer:**
- **Ingen mer** gissning om vilket format du f친r tillbaka - det 칛r konsekvent varje g친ng
- **Pluggar** direkt in i dina databaser och API:er utan extra arbete
- **F친ngar** konstiga AI-svar innan de f칬rst칬r din app
- **G칬r** din kod renare eftersom du vet exakt vad du arbetar med

## Verktygsanrop

Nu n친r vi en av de mest kraftfulla funktionerna: verktyg. Det 칛r s친 du ger din AI praktiska f칬rm친gor ut칬ver konversation. Precis som hur medeltida skr친n utvecklade specialverktyg f칬r specifika hantverk kan du utrusta din AI med fokuserade instrument. Du beskriver vilka verktyg som 칛r tillg칛ngliga, och n칛r n친gon beg칛r n친got som matchar kan din AI agera.

### Anv칛nda Python

L친t oss l칛gga till n친gra verktyg s친 h칛r:

```python
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

tools = [add]

functions = {
    "add": lambda a, b: a + b
}
```

S친 vad h칛nder h칛r? Vi skapar en ritning f칬r ett verktyg som heter `add`. Genom att 칛rva fr친n `TypedDict` och anv칛nda de snygga `Annotated`-typerna f칬r `a` och `b` ger vi LLM en tydlig bild av vad detta verktyg g칬r och vad det beh칬ver. Ordboken `functions` 칛r som v친r verktygsl친da - den ber칛ttar f칬r v친r kod exakt vad den ska g칬ra n칛r AI best칛mmer sig f칬r att anv칛nda ett specifikt verktyg.

L친t oss se hur vi anropar LLM med detta verktyg n칛sta:

```python
llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)
```

H칛r anropar vi `bind_tools` med v친r array `tools` och d칛rmed har LLM `llm_with_tools` nu kunskap om detta verktyg.

F칬r att anv칛nda denna nya LLM kan vi skriva f칬ljande kod:

```python
query = "What is 3 + 12?"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

Nu n칛r vi anropar `invoke` p친 denna nya LLM, som har verktyg, kanske egenskapen `tool_calls` fylls i. Om s친 칛r fallet har alla identifierade verktyg en egenskap `name` och `args` som identifierar vilket verktyg som ska anropas och med vilka argument. Den fullst칛ndiga koden ser ut s친 h칛r:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

tools = [add]

functions = {
    "add": lambda a, b: a + b
}

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)

query = "What is 3 + 12?"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

N칛r du k칬r denna kod b칬r du se ett resultat som liknar:

```text
TOOL CALL:  15
CONTENT: 
```

AI unders칬kte "Vad 칛r 3 + 12" och ins친g att detta var en uppgift f칬r verktyget `add`. Precis som hur en skicklig bibliotekarie vet vilken referens som ska konsulteras baserat p친 typen av fr친ga, gjorde den denna bed칬mning utifr친n verktygets namn, beskrivning och f칛ltspecifikationer. Resultatet 15 kommer fr친n v친r ordbok `functions` som utf칬r verktyget:

```python
print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
```

### Ett mer intressant verktyg som anropar ett webb-API

Att l칛gga till siffror demonstrerar konceptet, men riktiga verktyg utf칬r vanligtvis mer komplexa operationer, som att anropa webb-API:er. L친t oss ut칬ka v친rt exempel f칬r att l친ta AI h칛mta inneh친ll fr친n internet - liknande hur telegrafoperat칬rer en g친ng kopplade avl칛gsna platser:

```python
class joke(TypedDict):
    """Tell a joke."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    category: Annotated[str, ..., "The joke category"]

def get_joke(category: str) -> str:
    response = requests.get(f"https://api.chucknorris.io/jokes/random?category={category}", headers={"Accept": "application/json"})
    if response.status_code == 200:
        return response.json().get("value", f"Here's a {category} joke!")
    return f"Here's a {category} joke!"

functions = {
    "add": lambda a, b: a + b,
    "joke": lambda category: get_joke(category)
}

query = "Tell me a joke about animals"

# the rest of the code is the same
```

Nu om du k칬r denna kod f친r du ett svar som s칛ger n친got i stil med:

```text
TOOL CALL:  Chuck Norris once rode a nine foot grizzly bear through an automatic car wash, instead of taking a shower.
CONTENT:  
```

H칛r 칛r koden i sin helhet:

```python
from langchain_openai import ChatOpenAI
import requests
import os
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

class joke(TypedDict):
    """Tell a joke."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    category: Annotated[str, ..., "The joke category"]

tools = [add, joke]

def get_joke(category: str) -> str:
    response = requests.get(f"https://api.chucknorris.io/jokes/random?category={category}", headers={"Accept": "application/json"})
    if response.status_code == 200:
        return response.json().get("value", f"Here's a {category} joke!")
    return f"Here's a {category} joke!"

functions = {
    "add": lambda a, b: a + b,
    "joke": lambda category: get_joke(category)
}

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)

query = "Tell me a joke about animals"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        # print("TOOL CALL: ", tool)
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

## Embeddings och dokumentbearbetning

Embeddings representerar en av de mest eleganta l칬sningarna inom modern AI. T칛nk dig att du kan ta vilken text som helst och konvertera den till numeriska koordinater som f친ngar dess betydelse. Det 칛r precis vad embeddings g칬r - de omvandlar text till punkter i ett multidimensionellt rum d칛r liknande koncept klustrar sig tillsammans. Det 칛r som att ha ett koordinatsystem f칬r id칠er, p친minnande om hur Mendelejev organiserade det periodiska systemet efter atom칛ra egenskaper.

### Skapa och anv칛nda embeddings

```python
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter

# Initialize embeddings
embeddings = OpenAIEmbeddings(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="text-embedding-3-small"
)

# Load and split documents
loader = TextLoader("documentation.txt")
documents = loader.load()

text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(documents)

# Create vector store
vectorstore = FAISS.from_documents(texts, embeddings)

# Perform similarity search
query = "How do I handle user authentication?"
similar_docs = vectorstore.similarity_search(query, k=3)

for doc in similar_docs:
    print(f"Relevant content: {doc.page_content[:200]}...")
```

### Dokumentladdare f칬r olika format

```python
from langchain_community.document_loaders import (
    PyPDFLoader,
    CSVLoader,
    JSONLoader,
    WebBaseLoader
)

# Load different document types
pdf_loader = PyPDFLoader("manual.pdf")
csv_loader = CSVLoader("data.csv")
json_loader = JSONLoader("config.json")
web_loader = WebBaseLoader("https://example.com/docs")

# Process all documents
all_documents = []
for loader in [pdf_loader, csv_loader, json_loader, web_loader]:
    docs = loader.load()
    all_documents.extend(docs)
```

**Vad du kan g칬ra med embeddings:**
- **Bygg** s칬kfunktioner som faktiskt f칬rst친r vad du menar, inte bara nyckelordsmatchning
- **Skapa** AI som kan svara p친 fr친gor om dina dokument
- **G칬r** rekommendationssystem som f칬resl친r verkligen relevant inneh친ll
- **Organisera** och kategorisera ditt inneh친ll automatiskt

## Bygga en komplett AI-applikation

Nu ska vi integrera allt du har l칛rt dig i en omfattande applikation - en kodningsassistent som kan svara p친 fr친gor, anv칛nda verktyg och bibeh친lla konversationsminne. Precis som hur tryckpressen kombinerade befintliga teknologier (r칬rliga typer, bl칛ck, papper och tryck) till n친got transformativt, kommer vi att kombinera v친ra AI-komponenter till n친got praktiskt och anv칛ndbart.

### Komplett applikationsexempel

```python
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_community.vectorstores import FAISS
from typing_extensions import Annotated, TypedDict
import os
import requests

class CodingAssistant:
    def __init__(self):
        self.llm = ChatOpenAI(
            api_key=os.environ["GITHUB_TOKEN"],
            base_url="https://models.github.ai/inference",
            model="openai/gpt-4o-mini"
        )
        
        self.conversation_history = [
            SystemMessage(content="""You are an expert coding assistant. 
            Help users learn programming concepts, debug code, and write better software.
            Use tools when needed and maintain a helpful, encouraging tone.""")
        ]
        
        # Define tools
        self.setup_tools()
    
    def setup_tools(self):
        class web_search(TypedDict):
            """Search for programming documentation or examples."""
            query: Annotated[str, "Search query for programming help"]
        
        class code_formatter(TypedDict):
            """Format and validate code snippets."""
            code: Annotated[str, "Code to format"]
            language: Annotated[str, "Programming language"]
        
        self.tools = [web_search, code_formatter]
        self.llm_with_tools = self.llm.bind_tools(self.tools)
    
    def chat(self, user_input: str):
        # Add user message to conversation
        self.conversation_history.append(HumanMessage(content=user_input))
        
        # Get AI response
        response = self.llm_with_tools.invoke(self.conversation_history)
        
        # Handle tool calls if any
        if response.tool_calls:
            for tool_call in response.tool_calls:
                tool_result = self.execute_tool(tool_call)
                print(f"游댢 Tool used: {tool_call['name']}")
                print(f"游늵 Result: {tool_result}")
        
        # Add AI response to conversation
        self.conversation_history.append(response)
        
        return response.content
    
    def execute_tool(self, tool_call):
        tool_name = tool_call['name']
        args = tool_call['args']
        
        if tool_name == 'web_search':
            return f"Found documentation for: {args['query']}"
        elif tool_name == 'code_formatter':
            return f"Formatted {args['language']} code: {args['code'][:50]}..."
        
        return "Tool execution completed"

# Usage example
assistant = CodingAssistant()

print("游뱄 Coding Assistant Ready! Type 'quit' to exit.\n")

while True:
    user_input = input("You: ")
    if user_input.lower() == 'quit':
        break
    
    response = assistant.chat(user_input)
    print(f"游뱄 Assistant: {response}\n")
```

**Applikationsarkitektur:**

```mermaid
graph TD
    A[User Input] --> B[Coding Assistant]
    B --> C[Conversation Memory]
    B --> D[Tool Detection]
    B --> E[LLM Processing]
    
    D --> F[Web Search Tool]
    D --> G[Code Formatter Tool]
    
    E --> H[Response Generation]
    F --> H
    G --> H
    
    H --> I[User Interface]
    H --> C
```

**Nyckelfunktioner vi har implementerat:**
- **Kommer ih친g** hela din konversation f칬r kontextkontinuitet
- **Utf칬r 친tg칛rder** genom verktygsanrop, inte bara konversation
- **F칬ljer** f칬ruts칛gbara interaktionsm칬nster
- **Hantera** felhantering och komplexa arbetsfl칬den automatiskt

## Uppgift: Bygg din egen AI-drivna studieassistent

**M친l**: Skapa en AI-applikation som hj칛lper studenter att l칛ra sig programmeringskoncept genom att tillhandah친lla f칬rklaringar, kodexempel och interaktiva fr친gesporter.

### Krav

**K칛rnfunktioner (Obligatoriska):**
1. **Konversationsgr칛nssnitt**: Implementera ett chattsystem som bibeh친ller kontext 칬ver flera fr친gor
2. **Utbildningsverktyg**: Skapa minst tv친 verktyg som hj칛lper till med l칛rande:
   - Verktyg f칬r kodf칬rklaringar
   - Generator f칬r konceptfr친gesporter
3. **Personanpassat l칛rande**: Anv칛nd systemmeddelanden f칬r att anpassa svar till olika kunskapsniv친er  
4. **Svarformat**: Implementera strukturerad output f칬r quizfr친gor  

### Implementeringssteg  

**Steg 1: St칛ll in din milj칬**  
```bash
pip install langchain langchain-openai
```
  
**Steg 2: Grundl칛ggande chattfunktionalitet**  
- Skapa en `StudyAssistant`-klass  
- Implementera konversationsminne  
- L칛gg till personlighetskonfiguration f칬r pedagogiskt st칬d  

**Steg 3: L칛gg till utbildningsverktyg**  
- **Kodf칬rklarare**: Bryter ner kod i f칬rst친eliga delar  
- **Quizgenerator**: Skapar fr친gor om programmeringskoncept  
- **Framstegssp친rare**: H친ller koll p친 t칛ckta 칛mnen  

**Steg 4: F칬rb칛ttrade funktioner (valfritt)**  
- Implementera str칬mmande svar f칬r b칛ttre anv칛ndarupplevelse  
- L칛gg till dokumentladdning f칬r att integrera kursmaterial  
- Skapa embeddings f칬r inneh친llsbaserad likhets친tervinning  

### Utv칛rderingskriterier  

| Funktion | Utm칛rkt (4) | Bra (3) | Tillfredsst칛llande (2) | Beh칬ver f칬rb칛ttras (1) |  
|----------|-------------|---------|------------------------|------------------------|  
| **Konversationsfl칬de** | Naturliga, kontextmedvetna svar | Bra kontextbevarande | Grundl칛ggande konversation | Ingen minnesfunktion mellan utbyten |  
| **Verktygsintegration** | Flera anv칛ndbara verktyg som fungerar s칬ml칬st | 2+ verktyg implementerade korrekt | 1-2 grundl칛ggande verktyg | Verktyg fungerar inte |  
| **Kodkvalitet** | Ren, v칛l dokumenterad, felhantering | Bra struktur, viss dokumentation | Grundl칛ggande funktionalitet fungerar | D친lig struktur, ingen felhantering |  
| **Pedagogiskt v칛rde** | Verkligt hj칛lpsam f칬r l칛rande, anpassningsbar | Bra st칬d f칬r l칛rande | Grundl칛ggande f칬rklaringar | Begr칛nsad pedagogisk nytta |  

### Exempel p친 kodstruktur  

```python
class StudyAssistant:
    def __init__(self, skill_level="beginner"):
        # Initialize LLM, tools, and conversation memory
        pass
    
    def explain_code(self, code, language):
        # Tool: Explain how code works
        pass
    
    def generate_quiz(self, topic, difficulty):
        # Tool: Create practice questions
        pass
    
    def chat(self, user_input):
        # Main conversation interface
        pass

# Example usage
assistant = StudyAssistant(skill_level="intermediate")
response = assistant.chat("Explain how Python functions work")
```
  
**Bonusutmaningar:**  
- L칛gg till r칬stinmatning/utmatning  
- Implementera ett webbgr칛nssnitt med Streamlit eller Flask  
- Skapa en kunskapsbas fr친n kursmaterial med hj칛lp av embeddings  
- L칛gg till framstegssp친rning och personanpassade l칛rv칛gar  

## Sammanfattning  

游꿀 Du har nu bem칛strat grunderna i AI-ramverksutveckling och l칛rt dig hur man bygger sofistikerade AI-applikationer med LangChain. Som att avsluta en omfattande l칛rlingsutbildning har du skaffat dig en gedigen verktygsl친da med f칛rdigheter. L친t oss sammanfatta vad du har 친stadkommit.  

### Vad du har l칛rt dig  

**Grundl칛ggande ramverkskoncept:**  
- **F칬rdelar med ramverk**: F칬rst친 n칛r det 칛r b칛st att v칛lja ramverk framf칬r direkta API-anrop  
- **Grunderna i LangChain**: St칛lla in och konfigurera AI-modellanslutningar  
- **Meddelandetyper**: Anv칛nda `SystemMessage`, `HumanMessage` och `AIMessage` f칬r strukturerade konversationer  

**Avancerade funktioner:**  
- **Verktygsanrop**: Skapa och integrera anpassade verktyg f칬r f칬rb칛ttrade AI-funktioner  
- **Konversationsminne**: Bibeh친lla kontext 칬ver flera konversationsv칛ndningar  
- **Str칬mmande svar**: Implementera realtidsleverans av svar  
- **Promptmallar**: Bygga 친teranv칛ndbara, dynamiska prompts  
- **Strukturerad output**: S칛kerst칛lla konsekventa, parsbara AI-svar  
- **Embeddings**: Skapa semantisk s칬kning och dokumentbearbetningsm칬jligheter  

**Praktiska till칛mpningar:**  
- **Bygga kompletta appar**: Kombinera flera funktioner till produktionsklara applikationer  
- **Felhantering**: Implementera robust felhantering och validering  
- **Verktygsintegration**: Skapa anpassade verktyg som ut칬kar AI-funktioner  

### Viktiga insikter  

> 游꿢 **Kom ih친g**: AI-ramverk som LangChain 칛r i princip dina komplexitetsskyddande, funktionspackade b칛sta v칛nner. De 칛r perfekta n칛r du beh칬ver konversationsminne, verktygsanrop eller vill arbeta med flera AI-modeller utan att bli galen.  

**Beslutsramverk f칬r AI-integration:**  

```mermaid
flowchart TD
    A[AI Integration Need] --> B{Simple single query?}
    B -->|Yes| C[Direct API calls]
    B -->|No| D{Need conversation memory?}
    D -->|No| E[SDK Integration]
    D -->|Yes| F{Need tools or complex features?}
    F -->|No| G[Framework with basic setup]
    F -->|Yes| H[Full framework implementation]
    
    C --> I[HTTP requests, minimal dependencies]
    E --> J[Provider SDK, model-specific]
    G --> K[LangChain basic chat]
    H --> L[LangChain with tools, memory, agents]
```
  
### Vad g칬r du h칛rn칛st?  

**B칬rja bygga direkt:**  
- Ta dessa koncept och bygg n친got som inspirerar DIG!  
- Experimentera med olika AI-modeller via LangChain - det 칛r som en lekplats f칬r AI-modeller  
- Skapa verktyg som l칬ser verkliga problem du st칬ter p친 i ditt arbete eller dina projekt  

**Redo f칬r n칛sta niv친?**  
- **AI-agenter**: Bygg AI-system som faktiskt kan planera och utf칬ra komplexa uppgifter p친 egen hand  
- **RAG (Retrieval-Augmented Generation)**: Kombinera AI med dina egna kunskapsbaser f칬r superkraftiga applikationer  
- **Multimodal AI**: Arbeta med text, bilder och ljud tillsammans - m칬jligheterna 칛r o칛ndliga!  
- **Produktionsimplementering**: L칛r dig hur du skalar dina AI-appar och 칬vervakar dem i verkligheten  

**G친 med i gemenskapen:**  
- LangChain-gemenskapen 칛r fantastisk f칬r att h친lla sig uppdaterad och l칛ra sig b칛sta praxis  
- GitHub Models ger dig tillg친ng till den senaste AI-kapaciteten - perfekt f칬r experimentering  
- Forts칛tt att 칬va med olika anv칛ndningsomr친den - varje projekt l칛r dig n친got nytt  

Du har nu kunskapen att bygga intelligenta, konversationsapplikationer som kan hj칛lpa m칛nniskor att l칬sa verkliga problem. Precis som ren칛ssansens hantverkare som kombinerade konstn칛rlig vision med teknisk skicklighet, kan du nu f칬rena AI-funktioner med praktisk till칛mpning. Fr친gan 칛r: vad kommer du att skapa? 游  

## GitHub Copilot Agent-utmaning 游  

Anv칛nd Agent-l칛get f칬r att slutf칬ra f칬ljande utmaning:  

**Beskrivning:** Bygg en avancerad AI-driven kodgranskningsassistent som kombinerar flera LangChain-funktioner inklusive verktygsanrop, strukturerad output och konversationsminne f칬r att ge omfattande feedback p친 kodinl칛mningar.  

**Prompt:** Skapa en CodeReviewAssistant-klass som implementerar:  
1. Ett verktyg f칬r att analysera kodens komplexitet och f칬resl친 f칬rb칛ttringar  
2. Ett verktyg f칬r att kontrollera kod mot b칛sta praxis  
3. Strukturerad output med Pydantic-modeller f칬r konsekvent granskningsformat  
4. Konversationsminne f칬r att sp친ra granskningssessioner  
5. Ett huvudchattgr칛nssnitt som kan hantera kodinl칛mningar och ge detaljerad, handlingsbar feedback  

Assistenten ska kunna granska kod i flera programmeringsspr친k, bibeh친lla kontext 칬ver flera kodinl칛mningar i en session och ge b친de sammanfattande po칛ng och detaljerade f칬rb칛ttringsf칬rslag.  

L칛s mer om [agent mode](https://code.visualstudio.com/blogs/2025/02/24/introducing-copilot-agent-mode) h칛r.  

---

**Ansvarsfriskrivning**:  
Detta dokument har 칬versatts med hj칛lp av AI-칬vers칛ttningstj칛nsten [Co-op Translator](https://github.com/Azure/co-op-translator). 츿ven om vi str칛var efter noggrannhet, b칬r det noteras att automatiserade 칬vers칛ttningar kan inneh친lla fel eller felaktigheter. Det ursprungliga dokumentet p친 dess ursprungliga spr친k b칬r betraktas som den auktoritativa k칛llan. F칬r kritisk information rekommenderas professionell m칛nsklig 칬vers칛ttning. Vi ansvarar inte f칬r eventuella missf칬rst친nd eller feltolkningar som uppst친r vid anv칛ndning av denna 칬vers칛ttning.