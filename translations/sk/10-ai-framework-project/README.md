<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2c4ae5688e34b4b8b09d52aec56c79e",
  "translation_date": "2025-10-24T21:30:05+00:00",
  "source_file": "10-ai-framework-project/README.md",
  "language_code": "sk"
}
-->
# AI Framework

U ste sa niekedy c칤tili zahlten칤 pri pokuse vytvori콘 AI aplik치cie od nuly? Nie ste sami! AI frameworky s칰 ako 코vaj캜iarsky no쮂셞 pre v칳voj AI - s칰 to v칳konn칠 n치stroje, ktor칠 v치m m칪쬿 u코etri콘 캜as a starosti pri budovan칤 inteligentn칳ch aplik치ci칤. Predstavte si AI framework ako dobre organizovan칰 kni쬹icu: poskytuje predpripraven칠 komponenty, 코tandardizovan칠 API a inteligentn칠 abstrakcie, aby ste sa mohli s칰stredi콘 na rie코enie probl칠mov namiesto boja s implementa캜n칳mi detailmi.

V tejto lekcii presk칰mame, ako frameworky ako LangChain m칪쬿 premeni콘 kedysi zlo쬴t칠 칰lohy integr치cie AI na 캜ist칳, preh쬬dn칳 k칩d. Objav칤te, ako sa vysporiada콘 s re치lnymi v칳zvami, ako je sledovanie konverz치ci칤, implement치cia volania n치strojov a manipul치cia s r칪znymi AI modelmi prostredn칤ctvom jedn칠ho zjednoten칠ho rozhrania.

Ke캞 skon캜칤me, budete vedie콘, kedy siahnu콘 po frameworkoch namiesto surov칳ch API volan칤, ako efekt칤vne pou쮂셨a콘 ich abstrakcie a ako vytv치ra콘 AI aplik치cie pripraven칠 na re치lne pou쬴tie. Po캞me presk칰ma콘, 캜o m칪쬿 AI frameworky urobi콘 pre va코e projekty.

## Pre캜o si vybra콘 framework?

Tak쬰 ste pripraven칤 vytvori콘 AI aplik치ciu - skvel칠! Ale tu je vec: m치te nieko쬶o r칪znych ciest, ktor칳mi sa m칪쬰te vyda콘, a ka쬯치 z nich m치 svoje v칳hody a nev칳hody. Je to trochu ako rozhodovanie medzi ch칪dzou, bicyklovan칤m alebo jazdou autom, aby ste sa niekam dostali - v코etky v치s tam dostan칰, ale z치쬴tok (a 칰silie) bude 칰plne odli코n칠.

Rozde쬸e si tri hlavn칠 sp칪soby, ako m칪쬰te integrova콘 AI do svojich projektov:

| Pr칤stup | V칳hody | Najlep코ie pre | Zv치쬰nia |
|---------|--------|--------------|----------|
| **Priame HTTP po쬴adavky** | Pln치 kontrola, 쬴adne z치vislosti | Jednoduch칠 dotazy, u캜enie z치kladov | Viac rozvl치캜ny k칩d, manu치lne spracovanie ch칳b |
| **Integr치cia SDK** | Menej boilerplate k칩du, optimaliz치cia pre konkr칠tny model | Aplik치cie s jedn칳m modelom | Obmedzen칠 na konkr칠tnych poskytovate쬺v |
| **AI Frameworky** | Zjednoten칠 API, zabudovan칠 abstrakcie | Aplik치cie s viacer칳mi modelmi, zlo쬴t칠 pracovn칠 postupy | Krivka u캜enia, potenci치lne nadmern치 abstrakcia |

### V칳hody frameworkov v praxi

```mermaid
graph TD
    A[Your Application] --> B[AI Framework]
    B --> C[OpenAI GPT]
    B --> D[Anthropic Claude]
    B --> E[GitHub Models]
    B --> F[Local Models]
    
    B --> G[Built-in Tools]
    G --> H[Memory Management]
    G --> I[Conversation History]
    G --> J[Function Calling]
    G --> K[Error Handling]
```

**Pre캜o s칰 frameworky d칪le쬴t칠:**
- **Zjednocuj칰** viacer칳ch poskytovate쬺v AI pod jedno rozhranie
- **Automaticky spracov치vaj칰** pam칛콘 konverz치ci칤
- **Poskytuj칰** hotov칠 n치stroje na be쬹칠 칰lohy, ako s칰 embeddings a volanie funkci칤
- **Spravuj칰** spracovanie ch칳b a logiku opakovania
- **Premie켿aj칰** zlo쬴t칠 pracovn칠 postupy na preh쬬dn칠 volania met칩d

> 游눠 **Tip**: Pou쮂셨ajte frameworky pri prep칤nan칤 medzi r칪znymi AI modelmi alebo pri budovan칤 zlo쬴t칳ch funkci칤, ako s칰 agenti, pam칛콘 alebo volanie n치strojov. Pri u캜en칤 z치kladov alebo vytv치ran칤 jednoduch칳ch, zameran칳ch aplik치ci칤 sa dr쬾e priamych API.

**Zhrnutie**: Je to ako v칳ber medzi 코pecializovan칳mi n치strojmi remeseln칤ka a kompletnou diel켿ou - ide o prisp칪sobenie n치stroja 칰lohe. Frameworky vynikaj칰 pri zlo쬴t칳ch, funk캜ne bohat칳ch aplik치ci치ch, zatia 캜o priame API funguj칰 dobre pre jednoduch칠 pr칤pady pou쬴tia.

## 칔vod

V tejto lekcii sa nau캜칤me:

- Pou쮂셨a콘 be쬹칳 AI framework.
- Rie코i콘 be쬹칠 probl칠my, ako s칰 chatov칠 konverz치cie, pou쮂셨anie n치strojov, pam칛콘 a kontext.
- Vyu쬴콘 to na vytvorenie AI aplik치ci칤.

## V치코 prv칳 AI prompt

Za캜nime z치kladmi a vytvorme va코u prv칰 AI aplik치ciu, ktor치 po코le ot치zku a dostane odpove캞 sp칛콘. Ako Archimedes objavil princ칤p vztlaku vo svojej vani, niekedy najjednoduch코ie pozorovania ved칰 k najv칳znamnej코칤m poznatkom - a frameworky robia tieto poznatky pr칤stupn칳mi.

### Nastavenie LangChain s GitHub modelmi

Pou쬴jeme LangChain na pripojenie k GitHub modelom, 캜o je skvel칠, preto쬰 v치m poskytuje bezplatn칳 pr칤stup k r칪znym AI modelom. Najlep코ia 캜as콘? Na za캜iatok potrebujete len nieko쬶o jednoduch칳ch konfigura캜n칳ch parametrov:

```python
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

# Send a simple prompt
response = llm.invoke("What's the capital of France?")
print(response.content)
```

**Rozdelenie toho, 캜o sa tu deje:**
- **Vytvor칤** klienta LangChain pomocou triedy `ChatOpenAI` - toto je va코a br치na k AI!
- **Konfiguruje** pripojenie k GitHub modelom pomocou v치코ho autentifika캜n칠ho tokenu
- **Ur캜uje**, ktor칳 AI model pou쬴콘 (`gpt-4o-mini`) - predstavte si to ako v칳ber v치코ho AI asistenta
- **Odosiela** va코u ot치zku pomocou met칩dy `invoke()` - tu sa deje m치gia
- **Extrahuje** a zobrazuje odpove캞 - a voil, rozpr치vate sa s AI!

> 游댢 **Pozn치mka k nastaveniu**: Ak pou쮂셨ate GitHub Codespaces, m치te 코콘astie - `GITHUB_TOKEN` je u nastaven칳! Pracujete lok치lne? 콯iadny probl칠m, sta캜칤 si vytvori콘 osobn칳 pr칤stupov칳 token s potrebn칳mi opr치vneniami.

**O캜ak치van칳 v칳stup:**
```text
The capital of France is Paris.
```

```mermaid
sequenceDiagram
    participant App as Your Python App
    participant LC as LangChain
    participant GM as GitHub Models
    participant AI as GPT-4o-mini
    
    App->>LC: llm.invoke("What's the capital of France?")
    LC->>GM: HTTP request with prompt
    GM->>AI: Process prompt
    AI->>GM: Generated response
    GM->>LC: Return response
    LC->>App: response.content
```

## Budovanie konverza캜n칠ho AI

Tento prv칳 pr칤klad demon코truje z치klady, ale je to len jednorazov치 v칳mena - polo쮂셦e ot치zku, dostanete odpove캞 a to je v코etko. V re치lnych aplik치ci치ch chcete, aby si AI pam칛talo, o 캜om ste diskutovali, podobne ako Watson a Holmes budovali svoje investigat칤vne rozhovory v priebehu 캜asu.

Tu sa LangChain st치va obzvl치코콘 u쬴to캜n칳m. Poskytuje r칪zne typy spr치v, ktor칠 pom치haj칰 코trukt칰rova콘 konverz치cie a umo쮄갓j칰 v치m da콘 AI osobnos콘. Budete vytv치ra콘 chatovacie z치쬴tky, ktor칠 si udr쬿j칰 kontext a charakter.

### Pochopenie typov spr치v

Predstavte si tieto typy spr치v ako r칪zne "klob칰ky", ktor칠 칰캜astn칤ci nosia v konverz치cii. LangChain pou쮂셨a r칪zne triedy spr치v na sledovanie toho, kto 캜o hovor칤:

| Typ spr치vy | 칔캜el | Pr칤klad pou쬴tia |
|------------|------|------------------|
| `SystemMessage` | Definuje osobnos콘 a spr치vanie AI | "Ste u쬴to캜n칳 asistent pre programovanie" |
| `HumanMessage` | Reprezentuje vstup pou쮂셨ate쬬 | "Vysvetlite, ako funguj칰 funkcie" |
| `AIMessage` | Uklad치 odpovede AI | Predch치dzaj칰ce odpovede AI v konverz치cii |

### Vytvorenie va코ej prvej konverz치cie

Vytvorme konverz치ciu, kde na코e AI prevezme konkr칠tnu 칰lohu. Nech치me ho stelesni콘 kapit치na Picarda - postavu zn치mu svojou diplomatickou m칰dros콘ou a vodcovstvom:

```python
messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]
```

**Rozdelenie nastavenia tejto konverz치cie:**
- **Stanovuje** 칰lohu a osobnos콘 AI prostredn칤ctvom `SystemMessage`
- **Poskytuje** po캜iato캜n칳 dotaz pou쮂셨ate쬬 cez `HumanMessage`
- **Vytv치ra** z치klad pre viacn치sobn칰 konverz치ciu

Cel칳 k칩d pre tento pr칤klad vyzer치 takto:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]


# works
response  = llm.invoke(messages)
print(response.content)
```

Mali by ste vidie콘 v칳sledok podobn칳:

```text
I am Captain Jean-Luc Picard, the commanding officer of the USS Enterprise (NCC-1701-D), a starship in the United Federation of Planets. My primary mission is to explore new worlds, seek out new life and new civilizations, and boldly go where no one has gone before. 

I believe in the importance of diplomacy, reason, and the pursuit of knowledge. My crew is diverse and skilled, and we often face challenges that test our resolve, ethics, and ingenuity. Throughout my career, I have encountered numerous species, grappled with complex moral dilemmas, and have consistently sought peaceful solutions to conflicts.

I hold the ideals of the Federation close to my heart, believing in the importance of cooperation, understanding, and respect for all sentient beings. My experiences have shaped my leadership style, and I strive to be a thoughtful and just captain. How may I assist you further?
```

Na udr쬬nie kontinuity konverz치cie (namiesto resetovania kontextu pri ka쬯om volan칤) mus칤te neust치le prid치va콘 odpovede do zoznamu spr치v. Podobne ako 칰stne trad칤cie, ktor칠 uchov치vali pr칤behy cez gener치cie, tento pr칤stup buduje trval칰 pam칛콘:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]


# works
response  = llm.invoke(messages)

print(response.content)

print("---- Next ----")

messages.append(response)
messages.append(HumanMessage(content="Now that I know about you, I'm Chris, can I be in your crew?"))

response  = llm.invoke(messages)

print(response.content)

```

Celkom zauj칤mav칠, v코ak? 캛o sa tu deje, je to, 쬰 vol치me LLM dvakr치t - najprv len s na코imi po캜iato캜n칳mi dvoma spr치vami, ale potom znova s celou hist칩riou konverz치cie. Je to, akoby AI skuto캜ne sledovalo na코u diskusiu!

Ke캞 spust칤te tento k칩d, dostanete druh칰 odpove캞, ktor치 znie nie캜o ako:

```text
Welcome aboard, Chris! It's always a pleasure to meet those who share a passion for exploration and discovery. While I cannot formally offer you a position on the Enterprise right now, I encourage you to pursue your aspirations. We are always in need of talented individuals with diverse skills and backgrounds. 

If you are interested in space exploration, consider education and training in the sciences, engineering, or diplomacy. The values of curiosity, resilience, and teamwork are crucial in Starfleet. Should you ever find yourself on a starship, remember to uphold the principles of the Federation: peace, understanding, and respect for all beings. Your journey can lead you to remarkable adventures, whether in the stars or on the ground. Engage!
```

To beriem ako mo쬹o ;)

## Streamovanie odpoved칤

U ste si niekedy v코imli, ako ChatGPT "p칤코e" svoje odpovede v re치lnom 캜ase? To je streamovanie v akcii. Podobne ako sledovanie zru캜n칠ho kaligrafa pri pr치ci - vidie콘, ako sa znaky objavuj칰 콘ah za 콘ahom namiesto toho, aby sa objavili naraz - streamovanie rob칤 interakciu prirodzenej코ou a poskytuje okam쬴t칰 sp칛tn칰 v칛zbu.

### Implement치cia streamovania s LangChain

```python
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
    streaming=True
)

# Stream the response
for chunk in llm.stream("Write a short story about a robot learning to code"):
    print(chunk.content, end="", flush=True)
```

**Pre캜o je streamovanie skvel칠:**
- **Zobrazuje** obsah, ako sa vytv치ra - u 쬴adne tr치pne 캜akanie!
- **D치va** pou쮂셨ate쬺m pocit, 쬰 sa nie캜o skuto캜ne deje
- **P칪sob칤** r칳chlej코ie, aj ke캞 technicky nie je
- **Umo쮄갓je** pou쮂셨ate쬺m za캜a콘 캜칤ta콘, zatia 캜o AI st치le "prem칳코쬬"

> 游눠 **Tip pre pou쮂셨ate쬽k칰 sk칰senos콘**: Streamovanie naozaj vynik치, ke캞 pracujete s dlh코칤mi odpove캞ami, ako s칰 vysvetlenia k칩du, kreat칤vne p칤sanie alebo podrobn칠 tutori치ly. Va코i pou쮂셨atelia bud칰 milova콘 sledovanie pokroku namiesto pozerania na pr치zdnu obrazovku!

## 마bl칩ny promptov

마bl칩ny promptov funguj칰 ako r칠torick칠 코trukt칰ry pou쮂셨an칠 v klasickej r칠torike - predstavte si, ako by Cicero prisp칪sobil svoje vzorce re캜i pre r칪zne publikum, pri캜om by si zachoval rovnak칳 presved캜iv칳 r치mec. Umo쮄갓j칰 v치m vytv치ra콘 opakovane pou쬴te쬹칠 prompty, kde m칪쬰te vymeni콘 r칪zne 캜asti inform치ci칤 bez toho, aby ste museli v코etko prepisova콘 od za캜iatku. Ke캞 nastav칤te 코abl칩nu, sta캜칤 len vyplni콘 premenn칠 potrebn칳mi hodnotami.

### Vytvorenie opakovane pou쬴te쬹칳ch promptov

```python
from langchain_core.prompts import ChatPromptTemplate

# Define a template for code explanations
template = ChatPromptTemplate.from_messages([
    ("system", "You are an expert programming instructor. Explain concepts clearly with examples."),
    ("human", "Explain {concept} in {language} with a practical example for {skill_level} developers")
])

# Use the template with different values
questions = [
    {"concept": "functions", "language": "JavaScript", "skill_level": "beginner"},
    {"concept": "classes", "language": "Python", "skill_level": "intermediate"},
    {"concept": "async/await", "language": "JavaScript", "skill_level": "advanced"}
]

for question in questions:
    prompt = template.format_messages(**question)
    response = llm.invoke(prompt)
    print(f"Topic: {question['concept']}\n{response.content}\n---\n")
```

**Pre캜o si zamilujete pou쮂셨anie 코abl칩n:**
- **Udr쬿je** va코e prompty konzistentn칠 v celej aplik치cii
- **콯iadne viac** chaotick칠 sp치janie re콘azcov - len 캜ist칠, jednoduch칠 premenn칠
- **Va코e AI** sa spr치va predv칤date쬹e, preto쬰 코trukt칰ra zost치va rovnak치
- **Aktualiz치cie** s칰 jednoduch칠 - zme켿te 코abl칩nu raz a je opraven치 v코ade

## 맚rukt칰rovan칳 v칳stup

U ste niekedy boli frustrovan칤 pri pokuse analyzova콘 AI odpovede, ktor칠 sa vracaj칰 ako ne코trukt칰rovan칳 text? 맚rukt칰rovan칳 v칳stup je ako nau캜i콘 va코e AI dodr쬴ava콘 systematick칳 pr칤stup, ktor칳 pou쮂셨al Linnaeus na biologick칰 klasifik치ciu - organizovan칳, predv칤date쬹칳 a 쬬hko pou쬴te쬹칳. M칪쬰te po쬴ada콘 o JSON, konkr칠tne d치tov칠 코trukt칰ry alebo ak칳ko쭀ek form치t, ktor칳 potrebujete.

### Definovanie sch칠m v칳stupu

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel, Field

class CodeReview(BaseModel):
    score: int = Field(description="Code quality score from 1-10")
    strengths: list[str] = Field(description="List of code strengths")
    improvements: list[str] = Field(description="List of suggested improvements")
    overall_feedback: str = Field(description="Summary feedback")

# Set up the parser
parser = JsonOutputParser(pydantic_object=CodeReview)

# Create prompt with format instructions
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a code reviewer. {format_instructions}"),
    ("human", "Review this code: {code}")
])

# Format the prompt with instructions
chain = prompt | llm | parser

# Get structured response
code_sample = """
def calculate_average(numbers):
    return sum(numbers) / len(numbers)
"""

result = chain.invoke({
    "code": code_sample,
    "format_instructions": parser.get_format_instructions()
})

print(f"Score: {result['score']}")
print(f"Strengths: {', '.join(result['strengths'])}")
```

**Pre캜o je 코trukt칰rovan칳 v칳stup prelomov칳:**
- **콯iadne viac** h치danie, ak칳 form치t dostanete sp칛콘 - je konzistentn칳 v쬯y
- **Pripoj칤 sa** priamo do va코ich datab치z a API bez 캞al코ej pr치ce
- **Zachyt칤** divn칠 AI odpovede sk칪r, ne rozbij칰 va코u aplik치ciu
- **Rob칤** v치코 k칩d 캜istej코칤m, preto쬰 presne viete, s 캜칤m pracujete

## Volanie n치strojov

Teraz sa dost치vame k jednej z najv칳konnej코칤ch funkci칤: n치stroje. Takto d치vate svojmu AI praktick칠 schopnosti nad r치mec konverz치cie. Podobne ako stredovek칠 cechy vyv칤jali 코pecializovan칠 n치stroje pre konkr칠tne remesl치, m칪쬰te vybavi콘 svoje AI zameran칳mi n치strojmi. Pop칤코ete, ak칠 n치stroje s칰 k dispoz칤cii, a ke캞 niekto po쬴ada o nie캜o, 캜o zodpoved치, va코e AI m칪쬰 kona콘.

### Pou쬴tie Pythonu

Pridajme nieko쬶o n치strojov takto:

```python
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

tools = [add]

functions = {
    "add": lambda a, b: a + b
}
```

캛o sa tu deje? Vytv치rame pl치n pre n치stroj nazvan칳 `add`. T칳m, 쬰 ded칤me z `TypedDict` a pou쮂셨ame tie 코ikovn칠 typy `Annotated` pre `a` a `b`, d치vame LLM jasn칳 obraz o tom, 캜o tento n치stroj rob칤 a 캜o potrebuje. Slovn칤k `functions` je ako na코a sada n치strojov - hovor칤 n치코mu k칩du presne, 캜o m치 robi콘, ke캞 sa AI rozhodne pou쬴콘 konkr칠tny n치stroj.

Pozrime sa, ako zavol치me LLM s t칳mto n치strojom:

```python
llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)
```

Tu vol치me `bind_tools` s na코칤m po쬺m `tools`, a t칳m p치dom m치 LLM `llm_with_tools` teraz vedomosti o tomto n치stroji.

Na pou쬴tie tohto nov칠ho LLM m칪쬰me nap칤sa콘 nasleduj칰ci k칩d:

```python
query = "What is 3 + 12?"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

Teraz, ke캞 zavol치me `invoke` na tomto novom LLM, ktor칠 m치 n치stroje, m칪쬰 by콘 vlastnos콘 `tool_calls` naplnen치. Ak 치no, ak칳ko쭀ek identifikovan칳 n치stroj m치 vlastnosti `name` a `args`, ktor칠 identifikuj칰, ak칳 n치stroj by mal by콘 pou쬴t칳 a s ak칳mi argumentmi. Cel칳 k칩d vyzer치 takto:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

tools = [add]

functions = {
    "add": lambda a, b: a + b
}

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)

query = "What is 3 + 12?"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

Po spusten칤 tohto k칩du by ste mali vidie콘 v칳stup podobn칳:

```text
TOOL CALL:  15
CONTENT: 
```

AI presk칰malo "캛o je 3 + 12" a rozpoznalo to ako 칰lohu pre n치stroj `add`. Podobne ako zru캜n칳 knihovn칤k vie, na ktor칳 odkaz sa obr치ti콘 na z치klade typu ot치zky, urobilo toto rozhodnutie na z치klade n치zvu n치stroja, popisu a 코pecifik치ci칤 pol칤. V칳sledok 15 poch치dza z n치코ho slovn칤ka `functions`, ktor칳 vykon치va n치stroj:

```python
print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
```

### Zauj칤mavej코칤 n치stroj, ktor칳 vol치 webov칠 API

S캜칤tanie 캜칤sel demon코truje koncept, ale skuto캜n칠 n치stroje zvy캜ajne vykon치vaj칰 zlo쬴tej코ie oper치cie, ako je volanie webov칳ch API. Roz코칤rme n치코 pr칤klad, aby AI z칤skalo obsah z internetu - podobne ako telegrafn칤 oper치tori kedysi sp치jali vzdialen칠 lokality:

```python
class joke(TypedDict):
    """Tell a joke."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    category: Annotated[str, ..., "The joke category"]

def get_joke(category: str) -> str:
    response = requests.get(f"https://api.chucknorris.io/jokes/random?category={category}", headers={"Accept": "application/json"})
    if response.status_code == 200:
        return response.json().get("value", f"Here's a {category} joke!")
    return f"Here's a {category} joke!"

functions = {
    "add": lambda a, b: a + b,
    "joke": lambda category: get_joke(category)
}

query = "Tell me a joke about animals"

# the rest of the code is the same
```

Teraz, ak spust칤te tento k칩d, dostanete odpove캞, ktor치 znie nie캜o ako:

```text
TOOL CALL:  Chuck Norris once rode a nine foot grizzly bear through an automatic car wash, instead of taking a shower.
CONTENT:  
```

Tu je cel칳 k칩d:

```python
from langchain_openai import ChatOpenAI
import requests
import os
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

class joke(TypedDict):
    """Tell a joke."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    category: Annotated[str, ..., "The joke category"]

tools = [add, joke]

def get_joke(category: str) -> str:
    response = requests.get(f"https://api.chucknorris.io/jokes/random?category={category}", headers={"Accept": "application/json"})
    if response.status_code == 200:
        return response.json().get("value", f"Here's a {category} joke!")
    return f"Here's a {category} joke!"

functions = {
    "add": lambda a, b: a + b,
    "joke": lambda category: get_joke(category)
}

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)

query = "Tell me a joke about animals"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        # print("TOOL CALL: ", tool)
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

## Embeddings a spracovanie dokumentov

Embeddings predstavuj칰 jedno z najelegantnej코칤ch rie코en칤 v modernej AI. Predstavte si, 쬰 by ste mohli vzia콘 ak칳ko쭀ek text a previes콘 ho na 캜칤seln칠 s칰radnice, ktor칠 zachyt치vaj칰 jeho v칳znam. Presne to embeddings robia - transformuj칰 text na body v multidimenzion치lnom priestore, kde podobn칠 koncepty tvoria zhluky. Je to ako ma콘 s칰radnicov칳 syst칠m pre my코lienky, pripom칤naj칰ci, ako Mendelejev usporiadal periodick칰 tabu쬶u pod쬬 vlastnost칤 at칩mov.

### Vytv치ranie a pou쮂셨anie embeddings

```python
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter

# Initialize embeddings
embeddings = OpenAIEmbeddings(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="text-embedding-3-small"
)

# Load and split documents
loader = TextLoader("documentation.txt")
documents = loader.load()

text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(documents)

# Create vector store
vectorstore = FAISS.from_documents(texts, embeddings)

# Perform similarity search
query = "How do I handle user authentication?"
similar_docs = vectorstore.similarity_search(query, k=3)

for doc in similar_docs:
    print(f"Relevant content: {doc.page_content[:200]}...")
```

### Na캜칤tava캜e dokumentov pre r칪zne form치ty

```python
from langchain_community.document_loaders import (
    PyPDFLoader,
    CSVLoader,
    JSONLoader,
    WebBaseLoader
)

# Load different document types
pdf_loader = PyPDFLoader("manual.pdf")
csv_loader = CSVLoader("data.csv")
json_loader = JSONLoader("config.json")
web_loader = WebBaseLoader("https://example.com/docs")

# Process all documents
all_documents = []
for loader in [pdf_loader, csv_loader, json_loader, web_loader]:
    docs = loader.load()
    all_documents.extend(docs)
```

**캛o m칪쬰te robi콘 s embeddings:**
- **Vytv치ra콘** vyh쬬d치vanie, ktor칠 skuto캜ne rozumie tomu, 캜o mysl칤te, nielen
3. **Personalizovan칠 u캜enie**: Pou쮂셨ajte syst칠mov칠 spr치vy na prisp칪sobenie odpoved칤 r칪znym 칰rovniam zru캜nost칤  
4. **Form치tovanie odpoved칤**: Implementujte 코trukt칰rovan칳 v칳stup pre kv칤zov칠 ot치zky  

### Kroky implement치cie  

**Krok 1: Nastavte svoje prostredie**  
```bash
pip install langchain langchain-openai
```
  
**Krok 2: Z치kladn치 funkcia chatu**  
- Vytvorte triedu `StudyAssistant`  
- Implementujte pam칛콘 konverz치cie  
- Pridajte konfigur치ciu osobnosti na podporu vzdel치vania  

**Krok 3: Pridajte vzdel치vacie n치stroje**  
- **Vysvet쬺va캜 k칩du**: Rozklad치 k칩d na zrozumite쬹칠 캜asti  
- **Gener치tor kv칤zov**: Vytv치ra ot치zky o programovac칤ch konceptoch  
- **Sledova캜 pokroku**: Sleduje pokryt칠 t칠my  

**Krok 4: Roz코칤ren칠 funkcie (volite쬹칠)**  
- Implementujte streamovanie odpoved칤 pre lep코칤 pou쮂셨ate쬽k칳 z치쬴tok  
- Pridajte na캜칤tanie dokumentov na za캜lenenie u캜ebn칳ch materi치lov  
- Vytvorte embeddings na vyh쬬d치vanie obsahu na z치klade podobnosti  

### Krit칠ri치 hodnotenia  

| Funkcia | V칳born칠 (4) | Dobr칠 (3) | Uspokojiv칠 (2) | Potrebuje zlep코enie (1) |  
|---------|-------------|-----------|----------------|--------------------------|  
| **Tok konverz치cie** | Prirodzen칠, kontextovo uvedomel칠 odpovede | Dobr칠 udr쬬nie kontextu | Z치kladn치 konverz치cia | 콯iadna pam칛콘 medzi v칳menami |  
| **Integr치cia n치strojov** | Viacero u쬴to캜n칳ch n치strojov funguje bez probl칠mov | 2+ n치stroje implementovan칠 spr치vne | 1-2 z치kladn칠 n치stroje | N치stroje nefunk캜n칠 |  
| **Kvalita k칩du** | 캛ist칳, dobre dokumentovan칳, spracovanie ch칳b | Dobr치 코trukt칰ra, nejak치 dokument치cia | Z치kladn치 funk캜nos콘 funguje | Zl치 코trukt칰ra, 쬴adne spracovanie ch칳b |  
| **Vzdel치vacia hodnota** | Skuto캜ne u쬴to캜n칠 pre u캜enie, adapt칤vne | Dobr치 podpora u캜enia | Z치kladn칠 vysvetlenia | Obmedzen칳 vzdel치vac칤 pr칤nos |  

### Uk치쬶ov치 코trukt칰ra k칩du  

```python
class StudyAssistant:
    def __init__(self, skill_level="beginner"):
        # Initialize LLM, tools, and conversation memory
        pass
    
    def explain_code(self, code, language):
        # Tool: Explain how code works
        pass
    
    def generate_quiz(self, topic, difficulty):
        # Tool: Create practice questions
        pass
    
    def chat(self, user_input):
        # Main conversation interface
        pass

# Example usage
assistant = StudyAssistant(skill_level="intermediate")
response = assistant.chat("Explain how Python functions work")
```
  
**Bonusov칠 v칳zvy:**  
- Pridajte schopnosti hlasov칠ho vstupu/v칳stupu  
- Implementujte webov칠 rozhranie pomocou Streamlit alebo Flask  
- Vytvorte datab치zu znalost칤 z u캜ebn칳ch materi치lov pomocou embeddings  
- Pridajte sledovanie pokroku a personalizovan칠 u캜ebn칠 cesty  

## Zhrnutie  

游꿀 Teraz ste zvl치dli z치klady v칳voja AI frameworkov a nau캜ili sa, ako vytv치ra콘 sofistikovan칠 AI aplik치cie pomocou LangChain. Ako pri dokon캜en칤 komplexn칠ho u캜켿ovsk칠ho programu, z칤skali ste rozsiahlu sadu zru캜nost칤. Po캞me si zhrn칰콘, 캜o ste dosiahli.  

### 캛o ste sa nau캜ili  

**Z치kladn칠 koncepty frameworku:**  
- **V칳hody frameworkov**: Pochopenie, kedy si vybra콘 frameworky namiesto priamych API volan칤  
- **Z치klady LangChain**: Nastavenie a konfigur치cia pripojen칤 AI modelov  
- **Typy spr치v**: Pou쮂셨anie `SystemMessage`, `HumanMessage` a `AIMessage` na 코trukt칰rovan칠 konverz치cie  

**Pokro캜il칠 funkcie:**  
- **Volanie n치strojov**: Vytv치ranie a integr치cia vlastn칳ch n치strojov na roz코칤ren칠 schopnosti AI  
- **Pam칛콘 konverz치cie**: Udr쬴avanie kontextu naprie캜 viacer칳mi v칳menami v konverz치cii  
- **Streamovanie odpoved칤**: Implement치cia doru캜ovania odpoved칤 v re치lnom 캜ase  
- **마bl칩ny promptov**: Vytv치ranie opakovane pou쬴te쬹칳ch, dynamick칳ch promptov  
- **맚rukt칰rovan칳 v칳stup**: Zabezpe캜enie konzistentn칳ch, analyzovate쬹칳ch odpoved칤 AI  
- **Embeddings**: Vytv치ranie semantick칠ho vyh쬬d치vania a spracovania dokumentov  

**Praktick칠 aplik치cie:**  
- **Vytv치ranie kompletn칳ch aplik치ci칤**: Kombinovanie viacer칳ch funkci칤 do aplik치ci칤 pripraven칳ch na produkciu  
- **Spracovanie ch칳b**: Implement치cia robustn칠ho spracovania ch칳b a valid치cie  
- **Integr치cia n치strojov**: Vytv치ranie vlastn칳ch n치strojov, ktor칠 roz코iruj칰 schopnosti AI  

### K쮂줷꼂v칠 poznatky  

> 游꿢 **Pam칛tajte**: AI frameworky ako LangChain s칰 v podstate va코i pomocn칤ci, ktor칤 skr칳vaj칰 zlo쬴tos콘 a pon칰kaj칰 mno쬽tvo funkci칤. S칰 ide치lne, ke캞 potrebujete pam칛콘 konverz치cie, volanie n치strojov alebo chcete pracova콘 s viacer칳mi AI modelmi bez straty rozumu.  

**Rozhodovac칤 r치mec pre integr치ciu AI:**  

```mermaid
flowchart TD
    A[AI Integration Need] --> B{Simple single query?}
    B -->|Yes| C[Direct API calls]
    B -->|No| D{Need conversation memory?}
    D -->|No| E[SDK Integration]
    D -->|Yes| F{Need tools or complex features?}
    F -->|No| G[Framework with basic setup]
    F -->|Yes| H[Full framework implementation]
    
    C --> I[HTTP requests, minimal dependencies]
    E --> J[Provider SDK, model-specific]
    G --> K[LangChain basic chat]
    H --> L[LangChain with tools, memory, agents]
```
  
### Kam 캞alej?  

**Za캜nite budova콘 hne캞 teraz:**  
- Vezmite tieto koncepty a vytvorte nie캜o, 캜o v치s nadchne!  
- Experimentujte s r칪znymi AI modelmi cez LangChain - je to ako ma콘 ihrisko pln칠 AI modelov  
- Vytv치rajte n치stroje, ktor칠 rie코ia skuto캜n칠 probl칠my vo va코ej pr치ci alebo projektoch  

**Pripraven칤 na 캞al코iu 칰rove켿?**  
- **AI agenti**: Vytv치rajte AI syst칠my, ktor칠 dok치쬿 samostatne pl치nova콘 a vykon치va콘 zlo쬴t칠 칰lohy  
- **RAG (Retrieval-Augmented Generation)**: Kombinujte AI s vlastn칳mi datab치zami znalost칤 pre aplik치cie s roz코칤ren칳mi schopnos콘ami  
- **Multimod치lne AI**: Pracujte s textom, obr치zkami a zvukom naraz - mo쬹osti s칰 nekone캜n칠!  
- **Nasadenie do produkcie**: Nau캜te sa, ako 코k치lova콘 svoje AI aplik치cie a monitorova콘 ich v re치lnom svete  

**Pripojte sa ku komunite:**  
- Komunita LangChain je skvel치 na to, aby ste zostali informovan칤 a nau캜ili sa osved캜en칠 postupy  
- GitHub Models v치m poskytuje pr칤stup k najnov코칤m schopnostiam AI - ide치lne na experimentovanie  
- Pokra캜ujte v praxi s r칪znymi pr칤padmi pou쬴tia - ka쬯칳 projekt v치s nau캜칤 nie캜o nov칠  

Teraz m치te vedomosti na vytv치ranie inteligentn칳ch, konverza캜n칳ch aplik치ci칤, ktor칠 m칪쬿 pom칪c콘 쬿캞om rie코i콘 skuto캜n칠 probl칠my. Rovnako ako renesan캜n칤 remeseln칤ci, ktor칤 spojili umeleck칰 v칤ziu s technick칳mi zru캜nos콘ami, m칪쬰te teraz spoji콘 schopnosti AI s praktick칳m vyu쬴t칤m. Ot치zka znie: 캜o vytvor칤te? 游  

## V칳zva GitHub Copilot Agent 游  

Pou쬴te re쬴m Agent na splnenie nasleduj칰cej v칳zvy:  

**Popis:** Vytvorte pokro캜il칠ho AI asistenta na kontrolu k칩du, ktor칳 kombinuje viacero funkci칤 LangChain vr치tane volania n치strojov, 코trukt칰rovan칠ho v칳stupu a pam칛te konverz치cie na poskytovanie komplexnej sp칛tnej v칛zby k odoslan칳m k칩dom.  

**Prompt:** Vytvorte triedu CodeReviewAssistant, ktor치 implementuje:  
1. N치stroj na anal칳zu zlo쬴tosti k칩du a navrhovanie zlep코en칤  
2. N치stroj na kontrolu k칩du pod쬬 najlep코칤ch prakt칤k  
3. 맚rukt칰rovan칳 v칳stup pomocou Pydantic modelov na konzistentn칳 form치t recenzi칤  
4. Pam칛콘 konverz치cie na sledovanie rel치ci칤 recenzi칤  
5. Hlavn칠 rozhranie chatu, ktor칠 dok치쬰 spracova콘 odoslan칠 k칩dy a poskytova콘 podrobn칠, ak캜n칠 odpor칰캜ania  

Asistent by mal by콘 schopn칳 kontrolova콘 k칩d v viacer칳ch programovac칤ch jazykoch, udr쬴ava콘 kontext naprie캜 viacer칳mi odoslan칳mi k칩dmi v jednej rel치cii a poskytova콘 s칰hrnn칠 sk칩re aj podrobn칠 n치vrhy na zlep코enie.  

Viac inform치ci칤 o [re쬴me agent](https://code.visualstudio.com/blogs/2025/02/24/introducing-copilot-agent-mode) n치jdete tu.  

---

**Zrieknutie sa zodpovednosti**:  
Tento dokument bol prelo쬰n칳 pomocou slu쬭y AI prekladu [Co-op Translator](https://github.com/Azure/co-op-translator). Aj ke캞 sa sna쮂셠e o presnos콘, pros칤m, berte na vedomie, 쬰 automatizovan칠 preklady m칪쬿 obsahova콘 chyby alebo nepresnosti. P칪vodn칳 dokument v jeho rodnom jazyku by mal by콘 pova쬺van칳 za autoritat칤vny zdroj. Pre kritick칠 inform치cie sa odpor칰캜a profesion치lny 쬿dsk칳 preklad. Nenesieme zodpovednos콘 za ak칠ko쭀ek nedorozumenia alebo nespr치vne interpret치cie vypl칳vaj칰ce z pou쬴tia tohto prekladu.