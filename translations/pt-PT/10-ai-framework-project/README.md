# Framework de IA

Alguma vez se sentiu sobrecarregado a tentar construir aplica√ß√µes de IA do zero? N√£o est√° sozinho! Os frameworks de IA s√£o como ter um canivete su√≠√ßo para o desenvolvimento de IA ‚Äì s√£o ferramentas poderosas que podem poupar-lhe tempo e dores de cabe√ßa ao construir aplica√ß√µes inteligentes. Pense num framework de IA como numa biblioteca bem organizada: fornece componentes pr√©-constru√≠dos, APIs padronizadas e abstra√ß√µes inteligentes para que possa focar-se em resolver problemas em vez de lutar com os detalhes da implementa√ß√£o.

Nesta li√ß√£o, vamos explorar como frameworks como o LangChain podem transformar tarefas complexas de integra√ß√£o de IA em c√≥digo limpo e leg√≠vel. Vai descobrir como enfrentar desafios do mundo real como acompanhar conversas, implementar chamadas a ferramentas e gerir diferentes modelos de IA atrav√©s de uma interface unificada.

Quando terminarmos, vai saber quando recorrer a frameworks em vez de chamadas diretas √† API, como usar as suas abstra√ß√µes de forma eficaz e como construir aplica√ß√µes de IA prontas para uso no mundo real. Vamos explorar o que os frameworks de IA podem fazer pelos seus projetos.

## ‚ö° O Que Pode Fazer nos Pr√≥ximos 5 Minutos

**Caminho de Arranque R√°pido para Programadores Ocupados**

```mermaid
flowchart LR
    A[‚ö° 5 minutos] --> B[Instalar LangChain]
    B --> C[Criar cliente ChatOpenAI]
    C --> D[Enviar primeiro prompt]
    D --> E[Ver o poder do framework]
```
- **Minuto 1**: Instale LangChain: `pip install langchain langchain-openai`
- **Minuto 2**: Configure o seu token do GitHub e importe o cliente ChatOpenAI
- **Minuto 3**: Crie uma conversa simples com mensagens do sistema e do utilizador
- **Minuto 4**: Adicione uma ferramenta b√°sica (como uma fun√ß√£o soma) e veja a chamada da ferramenta pela IA
- **Minuto 5**: Experimente a diferen√ßa entre chamadas diretas √† API e abstra√ß√£o do framework

**C√≥digo para Teste R√°pido**:
```python
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini"
)

response = llm.invoke([
    SystemMessage(content="You are a helpful coding assistant"),
    HumanMessage(content="Explain Python functions briefly")
])
print(response.content)
```

**Porqu√™ isto ter import√¢ncia**: Em 5 minutos, vai experimentar como os frameworks de IA transformam uma integra√ß√£o complexa de IA em chamadas simples de m√©todo. Esta √© a base que alimenta aplica√ß√µes de IA em produ√ß√£o.

## Porque escolher um framework?

Ent√£o est√° pronto para construir uma aplica√ß√£o de IA ‚Äì √≥timo! Mas aqui est√° o ponto: tem v√°rios caminhos diferentes que pode seguir, e cada um tem os seus pr√≥s e contras. √â como escolher entre andar a p√©, andar de bicicleta ou conduzir para chegar a algum lado ‚Äì todos o levam l√°, mas a experi√™ncia (e o esfor√ßo) ser√° totalmente diferente.

Vamos analisar as tr√™s formas principais de integrar IA nos seus projetos:

| Abordagem | Vantagens | Melhor Para | Considera√ß√µes |
|----------|------------|----------|--------------|
| **Chamadas Diretas HTTP** | Controlo total, sem depend√™ncias | Consultas simples, aprendizagem dos fundamentos | C√≥digo mais verboso, gest√£o manual de erros |
| **Integra√ß√£o SDK** | Menos c√≥digo redundante, otimiza√ß√£o espec√≠fica do modelo | Aplica√ß√µes de modelo √∫nico | Limitado a fornecedores espec√≠ficos |
| **Frameworks de IA** | API unificada, abstra√ß√µes integradas | Aplica√ß√µes multi-modelo, fluxos de trabalho complexos | Curva de aprendizagem, poss√≠vel abstra√ß√£o excessiva |

### Benef√≠cios do Framework na Pr√°tica

```mermaid
graph TD
    A[A Sua Aplica√ß√£o] --> B[Framework de IA]
    B --> C[OpenAI GPT]
    B --> D[Anthropic Claude]
    B --> E[Modelos GitHub]
    B --> F[Modelos Locais]
    
    B --> G[Ferramentas Integradas]
    G --> H[Gest√£o de Mem√≥ria]
    G --> I[Hist√≥rico de Conversa]
    G --> J[Chamada de Fun√ß√£o]
    G --> K[Gest√£o de Erros]
```
**Porque os frameworks importam:**
- **Unifica** m√∫ltiplos fornecedores de IA numa √∫nica interface
- **Gere** a mem√≥ria das conversas automaticamente
- **Fornece** ferramentas prontas para tarefas comuns como embeddings e chamadas de fun√ß√µes
- **Gerencia** tratamento de erros e l√≥gica de re-tentativa
- **Transforma** fluxos de trabalho complexos em chamadas de m√©todo leg√≠veis

> üí° **Dica Profissional**: Use frameworks quando mudar entre diferentes modelos de IA ou construir funcionalidades complexas como agentes, mem√≥ria ou chamadas a ferramentas. Use APIs diretas quando estiver a aprender os fundamentos ou a construir aplica√ß√µes simples e focadas.

**Conclus√£o**: Tal como escolher entre ferramentas especializadas de um artes√£o e uma oficina completa, o importante √© adequar a ferramenta √† tarefa. Os frameworks destacam-se para aplica√ß√µes complexas e ricas em funcionalidades, enquanto as APIs diretas funcionam bem para casos de uso simples.

## üó∫Ô∏è O Seu Percurso de Aprendizagem na Maestria de Frameworks de IA

```mermaid
journey
    title De APIs Brutas a Aplica√ß√µes de IA em Produ√ß√£o
    section Fundamentos do Framework
      Entender benef√≠cios da abstra√ß√£o: 4: You
      Dominar o b√°sico do LangChain: 6: You
      Comparar abordagens: 7: You
    section Sistemas de Conversa√ß√£o
      Construir interfaces de chat: 5: You
      Implementar padr√µes de mem√≥ria: 7: You
      Gerir respostas em streaming: 8: You
    section Funcionalidades Avan√ßadas
      Criar ferramentas personalizadas: 6: You
      Dominar sa√≠da estruturada: 8: You
      Construir sistemas de documentos: 8: You
    section Aplica√ß√µes em Produ√ß√£o
      Combinar todas as funcionalidades: 7: You
      Gerir cen√°rios de erro: 8: You
      Implementar sistemas completos: 9: You
```
**Destino da Sua Jornada**: No final desta li√ß√£o, ter√° dominado o desenvolvimento com frameworks de IA e ser√° capaz de construir aplica√ß√µes de IA sofisticadas e prontas para produ√ß√£o que rivalizam com assistentes comerciais de IA.

## Introdu√ß√£o

Nesta li√ß√£o, vamos aprender a:

- Usar um framework comum de IA.
- Resolver problemas comuns como conversas de chat, uso de ferramentas, mem√≥ria e contexto.
- Aproveitar isso para construir aplica√ß√µes de IA.

## üß† Ecossistema de Desenvolvimento de Frameworks de IA

```mermaid
mindmap
  root((Frameworks de IA))
    Abstraction Benefits
      Code Simplification
        Unified APIs
        Built-in Error Handling
        Consistent Patterns
        Reduced Boilerplate
      Multi-Model Support
        Provider Agnostic
        Easy Switching
        Fallback Options
        Cost Optimization
    Core Components
      Conversation Management
        Message Types
        Memory Systems
        Context Tracking
        History Persistence
      Tool Integration
        Function Calling
        API Connections
        Custom Tools
        Workflow Automation
    Advanced Features
      Structured Output
        Pydantic Models
        JSON Schemas
        Type Safety
        Validation Rules
      Document Processing
        Embeddings
        Vector Stores
        Similarity Search
        RAG Systems
    Production Patterns
      Application Architecture
        Modular Design
        Error Boundaries
        Async Operations
        State Management
      Deployment Strategies
        Scalability
        Monitoring
        Performance
        Security
```
**Princ√≠pio Fundamental**: Frameworks de IA abstraem a complexidade enquanto fornecem poderosas abstra√ß√µes para gest√£o de conversas, integra√ß√£o de ferramentas e processamento de documentos, permitindo aos programadores construir aplica√ß√µes de IA sofisticadas com c√≥digo limpo e f√°cil de manter.

## O seu primeiro prompt de IA

Vamos come√ßar pelo b√°sico criando a sua primeira aplica√ß√£o de IA que envia uma pergunta e obt√©m uma resposta. Tal como Arquimedes descobriu o princ√≠pio do deslocamento na sua banheira, √†s vezes as observa√ß√µes mais simples conduzem aos insights mais poderosos ‚Äì e os frameworks tornam estes insights acess√≠veis.

### Configurar LangChain com os Modelos do GitHub

Vamos usar LangChain para ligar aos Modelos do GitHub, que √© bastante fixe porque lhe d√° acesso gratuito a v√°rios modelos de IA. A melhor parte? S√≥ precisa de alguns par√¢metros simples de configura√ß√£o para come√ßar:

```python
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

# Enviar um prompt simples
response = llm.invoke("What's the capital of France?")
print(response.content)
```

**Vamos decompor o que aqui est√° a acontecer:**
- **Cria** um cliente LangChain usando a classe `ChatOpenAI` ‚Äì esta √© a sua porta de entrada para a IA!
- **Configura** a liga√ß√£o aos Modelos GitHub com o seu token de autentica√ß√£o
- **Especifica** qual modelo de IA usar (`gpt-4o-mini`) ‚Äì pense nisso como escolher o seu assistente de IA
- **Envia** a sua pergunta usando o m√©todo `invoke()` ‚Äì onde a magia acontece
- **Extrai** e mostra a resposta ‚Äì e voil√†, est√° a conversar com a IA!

> üîß **Nota de Configura√ß√£o**: Se estiver a usar GitHub Codespaces, tem sorte ‚Äì o `GITHUB_TOKEN` j√° est√° configurado para si! A trabalhar localmente? Sem problema, s√≥ precisa criar um token de acesso pessoal com as permiss√µes certas.

**Sa√≠da esperada:**
```text
The capital of France is Paris.
```

```mermaid
sequenceDiagram
    participant App as A Sua App Python
    participant LC as LangChain
    participant GM as Modelos GitHub
    participant AI as GPT-4o-mini
    
    App->>LC: llm.invoke("Qual √© a capital de Fran√ßa?")
    LC->>GM: Pedido HTTP com prompt
    GM->>AI: Processar prompt
    AI->>GM: Resposta gerada
    GM->>LC: Devolver resposta
    LC->>App: response.content
```
## Construindo IA conversacional

Esse primeiro exemplo demonstra o b√°sico, mas √© apenas uma troca √∫nica ‚Äì faz uma pergunta, obt√©m uma resposta, e pronto. Em aplica√ß√µes reais, quer que a sua IA se lembre do que foi discutido, como Watson e Holmes constru√≠am as suas conversas de investiga√ß√£o ao longo do tempo.

√â aqui que o LangChain se torna particularmente √∫til. Fornece diferentes tipos de mensagens que ajudam a estruturar conversas e permitem dar √† sua IA uma personalidade. Vai construir experi√™ncias de chat que mant√™m contexto e car√°cter.

### Entendendo os tipos de mensagem

Pense nestes tipos de mensagem como diferentes "chap√©us" que os participantes usam numa conversa. O LangChain usa diferentes classes de mensagem para acompanhar quem diz o qu√™:

| Tipo de Mensagem | Prop√≥sito | Caso de Uso Exemplo |
|--------------|---------|------------------|
| `SystemMessage` | Define a personalidade e comportamento da IA | "√âs um assistente de programa√ß√£o √∫til" |
| `HumanMessage` | Representa a entrada do utilizador | "Explica como funcionam as fun√ß√µes" |
| `AIMessage` | Guarda respostas da IA | Respostas anteriores da IA na conversa |

### Criando a sua primeira conversa

Vamos criar uma conversa onde a nossa IA assume um papel espec√≠fico. Vamos faz√™-la encarnar o Capit√£o Picard ‚Äì uma personagem conhecida pela sua sabedoria diplom√°tica e lideran√ßa:

```python
messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]
```

**Decompondo esta configura√ß√£o da conversa:**
- **Estabelece** o papel e personalidade da IA atrav√©s do `SystemMessage`
- **Fornece** a pergunta inicial do utilizador via `HumanMessage`
- **Cria** a base para uma conversa multi-turnos

O c√≥digo completo para este exemplo √© assim:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]


# funciona
response  = llm.invoke(messages)
print(response.content)
```

Dever√° ver um resultado semelhante a:

```text
I am Captain Jean-Luc Picard, the commanding officer of the USS Enterprise (NCC-1701-D), a starship in the United Federation of Planets. My primary mission is to explore new worlds, seek out new life and new civilizations, and boldly go where no one has gone before. 

I believe in the importance of diplomacy, reason, and the pursuit of knowledge. My crew is diverse and skilled, and we often face challenges that test our resolve, ethics, and ingenuity. Throughout my career, I have encountered numerous species, grappled with complex moral dilemmas, and have consistently sought peaceful solutions to conflicts.

I hold the ideals of the Federation close to my heart, believing in the importance of cooperation, understanding, and respect for all sentient beings. My experiences have shaped my leadership style, and I strive to be a thoughtful and just captain. How may I assist you further?
```

Para manter a continuidade da conversa (em vez de reiniciar o contexto sempre), precisa de continuar a adicionar respostas √† sua lista de mensagens. Tal como as tradi√ß√µes orais que preservaram hist√≥rias ao longo das gera√ß√µes, esta abordagem constr√≥i mem√≥ria duradoura:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]


# funciona
response  = llm.invoke(messages)

print(response.content)

print("---- Next ----")

messages.append(response)
messages.append(HumanMessage(content="Now that I know about you, I'm Chris, can I be in your crew?"))

response  = llm.invoke(messages)

print(response.content)

```

Bem giro, certo? O que aqui acontece √© que estamos a chamar o LLM duas vezes ‚Äì primeiro s√≥ com as duas mensagens iniciais, mas depois de novo com todo o hist√≥rico de conversa. √â como se a IA realmente estivesse a acompanhar a nossa conversa!

Quando executar este c√≥digo, obter√° uma segunda resposta que soa algo como:

```text
Welcome aboard, Chris! It's always a pleasure to meet those who share a passion for exploration and discovery. While I cannot formally offer you a position on the Enterprise right now, I encourage you to pursue your aspirations. We are always in need of talented individuals with diverse skills and backgrounds. 

If you are interested in space exploration, consider education and training in the sciences, engineering, or diplomacy. The values of curiosity, resilience, and teamwork are crucial in Starfleet. Should you ever find yourself on a starship, remember to uphold the principles of the Federation: peace, understanding, and respect for all beings. Your journey can lead you to remarkable adventures, whether in the stars or on the ground. Engage!
```

```mermaid
sequenceDiagram
    participant User
    participant App
    participant LangChain
    participant AI
    
    User->>App: "Fala-me sobre ti"
    App->>LangChain: [SystemMessage, HumanMessage]
    LangChain->>AI: Conversa formatada
    AI->>LangChain: Resposta do Capit√£o Picard
    LangChain->>App: Objeto AIMessage
    App->>User: Mostrar resposta
    
    Note over App: Adicionar AIMessage √† conversa
    
    User->>App: "Posso juntar-me √† tua tripula√ß√£o?"
    App->>LangChain: [SystemMessage, HumanMessage, AIMessage, HumanMessage]
    LangChain->>AI: Contexto completo da conversa
    AI->>LangChain: Resposta contextual
    LangChain->>App: Novo AIMessage
    App->>User: Mostrar resposta contextual
```
Vou considerar isso um talvez ;)

## Respostas em streaming

J√° reparou como o ChatGPT parece "escrever" as respostas em tempo real? Isso √© o streaming em a√ß√£o. Tal como ver um cal√≠grafo habilidoso a trabalhar ‚Äì vendo os caracteres aparecerem tra√ßo a tra√ßo em vez de se materializarem instantaneamente ‚Äì o streaming torna a intera√ß√£o mais natural e oferece feedback imediato.

### Implementar streaming com LangChain

```python
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
    streaming=True
)

# Transmitir a resposta
for chunk in llm.stream("Write a short story about a robot learning to code"):
    print(chunk.content, end="", flush=True)
```

**Porque o streaming √© fant√°stico:**
- **Mostra** o conte√∫do √† medida que √© criado ‚Äì sem esperas desconfort√°veis!
- **Faz** os utilizadores sentirem que algo est√° realmente a acontecer
- **Parece** mais r√°pido, mesmo que tecnicamente n√£o seja
- **Permite** aos utilizadores come√ßar a ler enquanto a IA ainda est√° a "pensar"

> üí° **Dica de Experi√™ncia do Utilizador**: O streaming brilha mesmo com respostas mais longas, como explica√ß√µes de c√≥digo, escrita criativa ou tutoriais detalhados. Os seus utilizadores v√£o adorar ver o progresso em vez de ficarem a olhar para um ecr√£ vazio!

### üéØ Verifica√ß√£o Pedag√≥gica: Benef√≠cios da Abstra√ß√£o do Framework

**Pausa para Reflex√£o**: Acabou de experienciar o poder das abstra√ß√µes dos frameworks de IA. Compare o que aprendeu com as chamadas diretas √† API das li√ß√µes anteriores.

**Autoavalia√ß√£o R√°pida**:
- Consegue explicar como o LangChain simplifica a gest√£o de conversas comparado com o acompanhamento manual de mensagens?
- Qual a diferen√ßa entre os m√©todos `invoke()` e `stream()`, e quando usaria cada um?
- Como √© que o sistema de tipos de mensagens do framework melhora a organiza√ß√£o do c√≥digo?

**Liga√ß√£o ao Mundo Real**: Os padr√µes de abstra√ß√£o que aprendeu (tipos de mensagens, interfaces de streaming, mem√≥ria da conversa) s√£o usados em todas as grandes aplica√ß√µes de IA ‚Äì desde a interface do ChatGPT at√© √† assist√™ncia de c√≥digo do GitHub Copilot. Est√° a dominar os mesmos padr√µes arquitet√≥nicos usados pelas equipas profissionais de desenvolvimento de IA.

**Pergunta Desafio**: Como desenharia uma abstra√ß√£o de framework para lidar com diferentes fornecedores de modelos de IA (OpenAI, Anthropic, Google) usando uma √∫nica interface? Considere os benef√≠cios e compensa√ß√µes.

## Modelos de prompt

Os modelos de prompt funcionam como as estruturas ret√≥ricas usadas na orat√≥ria cl√°ssica ‚Äì pense em como C√≠cero adaptava os seus padr√µes de discurso para diferentes audi√™ncias mantendo o mesmo framework persuasivo. Permitem criar prompts reutiliz√°veis onde pode trocar diferentes peda√ßos de informa√ß√£o sem reescrever tudo do zero. Depois de configurar o modelo, s√≥ precisa de preencher as vari√°veis com os valores que necessita.

### Criar prompts reutiliz√°veis

```python
from langchain_core.prompts import ChatPromptTemplate

# Definir um modelo para explica√ß√µes de c√≥digo
template = ChatPromptTemplate.from_messages([
    ("system", "You are an expert programming instructor. Explain concepts clearly with examples."),
    ("human", "Explain {concept} in {language} with a practical example for {skill_level} developers")
])

# Usar o modelo com diferentes valores
questions = [
    {"concept": "functions", "language": "JavaScript", "skill_level": "beginner"},
    {"concept": "classes", "language": "Python", "skill_level": "intermediate"},
    {"concept": "async/await", "language": "JavaScript", "skill_level": "advanced"}
]

for question in questions:
    prompt = template.format_messages(**question)
    response = llm.invoke(prompt)
    print(f"Topic: {question['concept']}\n{response.content}\n---\n")
```

**Porque vai adorar usar modelos:**
- **Mant√©m** os seus prompts consistentes em toda a aplica√ß√£o
- **Chega de** concatena√ß√µes complexas de strings ‚Äì s√≥ vari√°veis simples e limpas
- **A sua IA** comporta-se de forma previs√≠vel porque a estrutura mant√©m-se igual
- **As atualiza√ß√µes** s√£o f√°ceis ‚Äì muda o modelo uma vez e fica corrigido em todo o lado

## Sa√≠da estruturada

Alguma vez se sentiu frustrado a tentar interpretar respostas de IA que surgem como texto n√£o estruturado? A sa√≠da estruturada √© como ensinar a sua IA a seguir o m√©todo sistem√°tico que Linnaeus usou para a classifica√ß√£o biol√≥gica ‚Äì organizada, previs√≠vel e f√°cil de trabalhar. Pode pedir JSON, estruturas de dados espec√≠ficas ou qualquer formato que necessite.

### Defini√ß√£o de esquemas de sa√≠da

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel, Field

class CodeReview(BaseModel):
    score: int = Field(description="Code quality score from 1-10")
    strengths: list[str] = Field(description="List of code strengths")
    improvements: list[str] = Field(description="List of suggested improvements")
    overall_feedback: str = Field(description="Summary feedback")

# Configurar o parser
parser = JsonOutputParser(pydantic_object=CodeReview)

# Criar prompt com instru√ß√µes de formato
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a code reviewer. {format_instructions}"),
    ("human", "Review this code: {code}")
])

# Formatar o prompt com instru√ß√µes
chain = prompt | llm | parser

# Obter resposta estruturada
code_sample = """
def calculate_average(numbers):
    return sum(numbers) / len(numbers)
"""

result = chain.invoke({
    "code": code_sample,
    "format_instructions": parser.get_format_instructions()
})

print(f"Score: {result['score']}")
print(f"Strengths: {', '.join(result['strengths'])}")
```

**Porque a sa√≠da estruturada √© revolucion√°ria:**
- **Chega de** adivinhar que formato vai receber ‚Äì √© consistente todas as vezes
- **Liga-se** diretamente √†s suas bases de dados e APIs sem trabalho extra
- **Detecta** respostas estranhas da IA antes que quebrem a sua aplica√ß√£o
- **Torna** o seu c√≥digo mais limpo porque sabe exatamente com o que est√° a lidar

## Chamada a ferramentas

Agora chegamos a uma das funcionalidades mais poderosas: ferramentas. √â assim que d√° √† sua IA capacidades pr√°ticas al√©m da conversa. Tal como as guildas medievais desenvolveram ferramentas especializadas para artes espec√≠ficas, pode equipar a sua IA com instrumentos focados. Descreve que ferramentas est√£o dispon√≠veis e, quando algu√©m pede algo que corresponde, a sua IA pode agir.

### Usar Python

Vamos adicionar algumas ferramentas assim:

```python
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # As anota√ß√µes devem ter o tipo e podem opcionalmente incluir um valor predefinido e uma descri√ß√£o (nessa ordem).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

tools = [add]

functions = {
    "add": lambda a, b: a + b
}
```

Ent√£o, o que est√° a acontecer aqui? Estamos a criar um modelo para uma ferramenta chamada `add`. Herdando de `TypedDict` e usando aqueles tipos `Annotated` giros para `a` e `b`, estamos a dar ao LLM uma imagem clara do que esta ferramenta faz e do que precisa. O dicion√°rio `functions` √© como a nossa caixa de ferramentas ‚Äì diz ao nosso c√≥digo exatamente o que fazer quando a IA decidir usar uma ferramenta espec√≠fica.

Vamos ver como chamamos o LLM com esta ferramenta a seguir:

```python
llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)
```

Aqui chamamos `bind_tools` com o nosso array `tools` e assim o LLM `llm_with_tools` agora tem conhecimento desta ferramenta.

Para usar este novo LLM, podemos digitar o seguinte c√≥digo:

```python
query = "What is 3 + 12?"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

Agora que chamamos `invoke` neste novo llm, que tem ferramentas, talvez a propriedade `tool_calls` esteja preenchida. Se assim for, qualquer ferramenta identificada tem uma propriedade `name` e `args` que identifica que ferramenta deve ser chamada e com que argumentos. O c√≥digo completo √© assim:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # As anota√ß√µes devem ter o tipo e podem opcionalmente incluir um valor predefinido e uma descri√ß√£o (nessa ordem).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

tools = [add]

functions = {
    "add": lambda a, b: a + b
}

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)

query = "What is 3 + 12?"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

Ao executar este c√≥digo, dever√° ver uma sa√≠da semelhante a:

```text
TOOL CALL:  15
CONTENT: 
```

A IA examinou "Qual √© 3 + 12" e reconheceu isto como uma tarefa para a ferramenta `add`. Tal como um bibliotec√°rio experiente sabe que refer√™ncia consultar com base no tipo de pergunta feita, fez esta determina√ß√£o a partir do nome da ferramenta, descri√ß√£o e especifica√ß√µes dos campos. O resultado 15 vem do nosso dicion√°rio `functions` a executar a ferramenta:

```python
print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
```

### Uma ferramenta mais interessante que chama uma API web
Adicionar n√∫meros demonstra o conceito, mas as ferramentas reais normalmente executam opera√ß√µes mais complexas, como chamadas a APIs web. Vamos expandir o nosso exemplo para que a IA obtenha conte√∫do da internet - semelhante a como os operadores de tel√©grafo antigamente ligavam locais distantes:

```python
class joke(TypedDict):
    """Tell a joke."""

    # As anota√ß√µes devem ter o tipo e podem opcionalmente incluir um valor predefinido e uma descri√ß√£o (nessa ordem).
    category: Annotated[str, ..., "The joke category"]

def get_joke(category: str) -> str:
    response = requests.get(f"https://api.chucknorris.io/jokes/random?category={category}", headers={"Accept": "application/json"})
    if response.status_code == 200:
        return response.json().get("value", f"Here's a {category} joke!")
    return f"Here's a {category} joke!"

functions = {
    "add": lambda a, b: a + b,
    "joke": lambda category: get_joke(category)
}

query = "Tell me a joke about animals"

# o resto do c√≥digo √© o mesmo
```

Agora, se executar este c√≥digo, receber√° uma resposta dizendo algo como:

```text
TOOL CALL:  Chuck Norris once rode a nine foot grizzly bear through an automatic car wash, instead of taking a shower.
CONTENT:  
```

```mermaid
flowchart TD
    A[Consulta do Utilizador: "Conta-me uma piada sobre animais"] --> B[An√°lise LangChain]
    B --> C{Ferramenta Dispon√≠vel?}
    C -->|Sim| D[Selecionar ferramenta de piadas]
    C -->|N√£o| E[Gerar resposta direta]
    
    D --> F[Extrair Par√¢metros]
    F --> G[Chamar piada(categoria="animais")]
    G --> H[Pedido API para chucknorris.io]
    H --> I[Retornar conte√∫do da piada]
    I --> J[Exibir ao utilizador]
    
    E --> K[Resposta gerada pela IA]
    K --> J
    
    subgraph "Camada de Defini√ß√£o da Ferramenta"
        L[Esquema TypedDict]
        M[Implementa√ß√£o da Fun√ß√£o]
        N[Valida√ß√£o de Par√¢metros]
    end
    
    D --> L
    F --> N
    G --> M
```
Aqui est√° o c√≥digo na sua totalidade:

```python
from langchain_openai import ChatOpenAI
import requests
import os
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # As anota√ß√µes devem ter o tipo e podem opcionalmente incluir um valor predefinido e uma descri√ß√£o (nessa ordem).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

class joke(TypedDict):
    """Tell a joke."""

    # As anota√ß√µes devem ter o tipo e podem opcionalmente incluir um valor predefinido e uma descri√ß√£o (nessa ordem).
    category: Annotated[str, ..., "The joke category"]

tools = [add, joke]

def get_joke(category: str) -> str:
    response = requests.get(f"https://api.chucknorris.io/jokes/random?category={category}", headers={"Accept": "application/json"})
    if response.status_code == 200:
        return response.json().get("value", f"Here's a {category} joke!")
    return f"Here's a {category} joke!"

functions = {
    "add": lambda a, b: a + b,
    "joke": lambda category: get_joke(category)
}

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)

query = "Tell me a joke about animals"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        # print("CHAMADA DE FERRAMENTA: ", ferramenta)
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

## Embeddings e processamento de documentos

Embeddings representam uma das solu√ß√µes mais elegantes na IA moderna. Imagine se pudesse pegar qualquer peda√ßo de texto e convert√™-lo em coordenadas num√©ricas que capturam o seu significado. √â exatamente isto que os embeddings fazem - transformam texto em pontos num espa√ßo multidimensional onde conceitos semelhantes se agrupam. √â como ter um sistema de coordenadas para ideias, lembrando como Mendeleev organizou a tabela peri√≥dica por propriedades at√≥micas.

### Criar e usar embeddings

```python
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter

# Inicializar embeddings
embeddings = OpenAIEmbeddings(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="text-embedding-3-small"
)

# Carregar e dividir documentos
loader = TextLoader("documentation.txt")
documents = loader.load()

text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(documents)

# Criar armazenamento vetorial
vectorstore = FAISS.from_documents(texts, embeddings)

# Realizar pesquisa por similaridade
query = "How do I handle user authentication?"
similar_docs = vectorstore.similarity_search(query, k=3)

for doc in similar_docs:
    print(f"Relevant content: {doc.page_content[:200]}...")
```

### Carregadores de documentos para v√°rios formatos

```python
from langchain_community.document_loaders import (
    PyPDFLoader,
    CSVLoader,
    JSONLoader,
    WebBaseLoader
)

# Carregar diferentes tipos de documentos
pdf_loader = PyPDFLoader("manual.pdf")
csv_loader = CSVLoader("data.csv")
json_loader = JSONLoader("config.json")
web_loader = WebBaseLoader("https://example.com/docs")

# Processar todos os documentos
all_documents = []
for loader in [pdf_loader, csv_loader, json_loader, web_loader]:
    docs = loader.load()
    all_documents.extend(docs)
```

**O que pode fazer com embeddings:**
- **Construir** pesquisas que realmente compreendem o que quer dizer, e n√£o apenas associar palavras-chave
- **Criar** IA que pode responder a perguntas sobre os seus documentos
- **Fazer** sistemas de recomenda√ß√£o que sugerem conte√∫do verdadeiramente relevante
- **Organizar** e categorizar automaticamente o seu conte√∫do

```mermaid
flowchart LR
    A[Documentos] --> B[Divisor de Texto]
    B --> C[Criar Embeddings]
    C --> D[Armazenamento Vetorial]
    
    E[Consulta do Utilizador] --> F[Embedding da Consulta]
    F --> G[Pesquisa por Similaridade]
    G --> D
    D --> H[Documentos Relevantes]
    H --> I[Resposta da IA]
    
    subgraph "Espa√ßo Vetorial"
        J[Documento A: [0.1, 0.8, 0.3...]]
        K[Documento B: [0.2, 0.7, 0.4...]]
        L[Consulta: [0.15, 0.75, 0.35...]]
    end
    
    C --> J
    C --> K
    F --> L
    G --> J
    G --> K
```
## Construir uma aplica√ß√£o AI completa

Agora vamos integrar tudo o que aprendeu numa aplica√ß√£o abrangente - um assistente de programa√ß√£o que pode responder a perguntas, usar ferramentas e manter mem√≥ria da conversa. Tal como a imprensa combinou tecnologias existentes (tipografia m√≥vel, tinta, papel e press√£o) numa coisa transformadora, combinaremos os nossos componentes de IA numa solu√ß√£o pr√°tica e √∫til.

### Exemplo de aplica√ß√£o completa

```python
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_community.vectorstores import FAISS
from typing_extensions import Annotated, TypedDict
import os
import requests

class CodingAssistant:
    def __init__(self):
        self.llm = ChatOpenAI(
            api_key=os.environ["GITHUB_TOKEN"],
            base_url="https://models.github.ai/inference",
            model="openai/gpt-4o-mini"
        )
        
        self.conversation_history = [
            SystemMessage(content="""You are an expert coding assistant. 
            Help users learn programming concepts, debug code, and write better software.
            Use tools when needed and maintain a helpful, encouraging tone.""")
        ]
        
        # Definir ferramentas
        self.setup_tools()
    
    def setup_tools(self):
        class web_search(TypedDict):
            """Search for programming documentation or examples."""
            query: Annotated[str, "Search query for programming help"]
        
        class code_formatter(TypedDict):
            """Format and validate code snippets."""
            code: Annotated[str, "Code to format"]
            language: Annotated[str, "Programming language"]
        
        self.tools = [web_search, code_formatter]
        self.llm_with_tools = self.llm.bind_tools(self.tools)
    
    def chat(self, user_input: str):
        # Adicionar mensagem do utilizador √† conversa
        self.conversation_history.append(HumanMessage(content=user_input))
        
        # Obter resposta da IA
        response = self.llm_with_tools.invoke(self.conversation_history)
        
        # Lidar com chamadas de ferramentas, se houver
        if response.tool_calls:
            for tool_call in response.tool_calls:
                tool_result = self.execute_tool(tool_call)
                print(f"üîß Tool used: {tool_call['name']}")
                print(f"üìä Result: {tool_result}")
        
        # Adicionar resposta da IA √† conversa
        self.conversation_history.append(response)
        
        return response.content
    
    def execute_tool(self, tool_call):
        tool_name = tool_call['name']
        args = tool_call['args']
        
        if tool_name == 'web_search':
            return f"Found documentation for: {args['query']}"
        elif tool_name == 'code_formatter':
            return f"Formatted {args['language']} code: {args['code'][:50]}..."
        
        return "Tool execution completed"

# Exemplo de uso
assistant = CodingAssistant()

print("ü§ñ Coding Assistant Ready! Type 'quit' to exit.\n")

while True:
    user_input = input("You: ")
    if user_input.lower() == 'quit':
        break
    
    response = assistant.chat(user_input)
    print(f"ü§ñ Assistant: {response}\n")
```

**Arquitetura da aplica√ß√£o:**

```mermaid
graph TD
    A[Entrada do Utilizador] --> B[Assistente de Programa√ß√£o]
    B --> C[Mem√≥ria da Conversa]
    B --> D[Dete√ß√£o de Ferramentas]
    B --> E[Processamento LLM]
    
    D --> F[Ferramenta de Pesquisa Web]
    D --> G[Ferramenta de Formata√ß√£o de C√≥digo]
    
    E --> H[Gera√ß√£o de Resposta]
    F --> H
    G --> H
    
    H --> I[Interface do Utilizador]
    H --> C
```
**Funcionalidades principais que implement√°mos:**
- **Lembra-se** de toda a sua conversa para continuidade contextual
- **Executa a√ß√µes** via chamadas a ferramentas, n√£o apenas conversa
- **Segue** padr√µes previs√≠veis de intera√ß√£o
- **Gerencia** tratamento de erros e fluxos de trabalho complexos automaticamente

### üéØ Verifica√ß√£o Pedag√≥gica: Arquitetura AI para Produ√ß√£o

**Compreens√£o da Arquitetura**: Construiu uma aplica√ß√£o AI completa que combina gest√£o de conversa√ß√£o, chamada de ferramentas e fluxos estruturados. Isto representa desenvolvimento de aplica√ß√µes AI em n√≠vel de produ√ß√£o.

**Conceitos-chave dominados**:
- **Arquitetura baseada em classes**: Estrutura organizada e manuten√≠vel para aplica√ß√µes AI
- **Integra√ß√£o de ferramentas**: Funcionalidade personalizada para al√©m da conversa
- **Gest√£o de mem√≥ria**: Contexto persistente da conversa
- **Tratamento de erros**: Comportamento robusto da aplica√ß√£o

**Conex√£o com a ind√∫stria**: Os padr√µes de arquitetura que implementou (classes de conversa√ß√£o, sistemas de ferramentas, gest√£o de mem√≥ria) s√£o os mesmos usados em aplica√ß√µes AI empresariais como o assistente AI do Slack, GitHub Copilot e Microsoft Copilot. Est√° a construir com pensamento arquitet√≥nico profissional.

**Pergunta de reflex√£o**: Como estenderia esta aplica√ß√£o para suportar m√∫ltiplos utilizadores, armazenamento persistente ou integra√ß√£o com bases de dados externas? Considere desafios de escalabilidade e gest√£o de estado.

## Tarefa: Crie o seu pr√≥prio assistente de estudo com IA

**Objetivo**: Criar uma aplica√ß√£o AI que ajude estudantes a aprender conceitos de programa√ß√£o fornecendo explica√ß√µes, exemplos de c√≥digo e quizzes interativos.

### Requisitos

**Funcionalidades principais (Obrigat√≥rias):**
1. **Interface conversacional**: Implemente um sistema de chat que mantenha contexto em v√°rias perguntas
2. **Ferramentas educativas**: Crie pelo menos duas ferramentas que ajudem na aprendizagem:
   - Ferramenta de explica√ß√£o de c√≥digo
   - Gerador de quizzes de conceitos
3. **Aprendizagem personalizada**: Use mensagens de sistema para adaptar respostas a diferentes n√≠veis de habilidade
4. **Formata√ß√£o de respostas**: Implemente sa√≠da estruturada para perguntas de quizzes

### Passos para implementa√ß√£o

**Passo 1: Configurar o seu ambiente**
```bash
pip install langchain langchain-openai
```

**Passo 2: Funcionalidade b√°sica de chat**
- Crie uma classe `StudyAssistant`
- Implemente mem√≥ria de conversa√ß√£o
- Adicione configura√ß√£o de personalidade para suporte educativo

**Passo 3: Adicionar ferramentas educativas**
- **Explicador de C√≥digo**: Divide o c√≥digo em partes compreens√≠veis
- **Gerador de Quiz**: Cria perguntas sobre conceitos de programa√ß√£o
- **Rastreador de Progresso**: Acompanha os t√≥picos abordados

**Passo 4: Funcionalidades avan√ßadas (Opcional)**
- Implemente respostas em streaming para melhor experi√™ncia de utilizador
- Adicione carregamento de documentos para incorporar materiais do curso
- Crie embeddings para recupera√ß√£o de conte√∫do baseada em similaridade

### Crit√©rios de avalia√ß√£o

| Funcionalidade | Excelente (4) | Bom (3) | Satisfat√≥rio (2) | Precisa Melhorar (1) |
|----------------|---------------|---------|------------------|---------------------|
| **Fluxo de Conversa** | Respostas naturais, conscientes do contexto | Boa reten√ß√£o de contexto | Conversa b√°sica | Sem mem√≥ria entre trocas |
| **Integra√ß√£o de Ferramentas** | M√∫ltiplas ferramentas √∫teis a funcionar bem | 2+ ferramentas implementadas corretamente | 1-2 ferramentas b√°sicas | Ferramentas n√£o funcionais |
| **Qualidade do C√≥digo** | C√≥digo limpo, bem documentado, tratamento de erros | Boa estrutura, alguma documenta√ß√£o | Funcionalidade b√°sica | Estrutura pobre, sem tratamento de erros |
| **Valor Educativo** | Realmente √∫til para aprendizagem, adaptativo | Bom suporte educativo | Explica√ß√µes b√°sicas | Benef√≠cio educativo limitado |

### Estrutura de c√≥digo de exemplo

```python
class StudyAssistant:
    def __init__(self, skill_level="beginner"):
        # Inicializar LLM, ferramentas e mem√≥ria de conversa
        pass
    
    def explain_code(self, code, language):
        # Ferramenta: Explicar como o c√≥digo funciona
        pass
    
    def generate_quiz(self, topic, difficulty):
        # Ferramenta: Criar perguntas de pr√°tica
        pass
    
    def chat(self, user_input):
        # Interface principal de conversa
        pass

# Exemplo de utiliza√ß√£o
assistant = StudyAssistant(skill_level="intermediate")
response = assistant.chat("Explain how Python functions work")
```

**Desafios B√≥nus:**
- Adicionar capacidades de entrada/sa√≠da por voz
- Implementar uma interface web usando Streamlit ou Flask
- Criar uma base de conhecimento a partir dos materiais do curso usando embeddings
- Adicionar rastreamento de progresso e percursos de aprendizagem personalizados

## üìà Linha temporal da sua maestria no desenvolvimento de frameworks AI

```mermaid
timeline
    title Jornada de Desenvolvimento do Framework de IA de Produ√ß√£o
    
    section Fundamentos do Framework
        Compreens√£o das Abstra√ß√µes
            : Decis√µes entre framework mestre vs API
            : Aprender conceitos b√°sicos do LangChain
            : Implementar sistemas de tipos de mensagens
        
        Integra√ß√£o B√°sica
            : Conectar a provedores de IA
            : Gerir autentica√ß√£o
            : Gerir configura√ß√£o
    
    section Sistemas de Conversa√ß√£o
        Gest√£o de Mem√≥ria
            : Construir hist√≥rico de conversa√ß√£o
            : Implementar rastreamento de contexto
            : Gerir persist√™ncia de sess√£o
        
        Intera√ß√µes Avan√ßadas
            : Dominar respostas por streaming
            : Criar modelos de prompt
            : Implementar sa√≠da estruturada
    
    section Integra√ß√£o de Ferramentas
        Desenvolvimento de Ferramentas Personalizadas
            : Desenhar esquemas de ferramentas
            : Implementar chamadas de fun√ß√µes
            : Gerir APIs externas
        
        Automa√ß√£o de Fluxos de Trabalho
            : Encadear m√∫ltiplas ferramentas
            : Criar √°rvores de decis√£o
            : Construir comportamentos de agentes
    
    section Aplica√ß√µes de Produ√ß√£o
        Arquitetura Completa do Sistema
            : Combinar todas as funcionalidades do framework
            : Implementar limites de erro
            : Criar c√≥digo sustent√°vel
        
        Prepara√ß√£o para Empresas
            : Lidar com quest√µes de escalabilidade
            : Implementar monitoriza√ß√£o
            : Construir estrat√©gias de implanta√ß√£o
```
**üéì Marco de gradua√ß√£o**: Dominou com sucesso o desenvolvimento de frameworks AI usando as mesmas ferramentas e padr√µes que potenciam as aplica√ß√µes AI modernas. Estas compet√™ncias representam o estado da arte no desenvolvimento de aplica√ß√µes AI e preparam-no para construir sistemas inteligentes de n√≠vel empresarial.

**üîÑ Capacidades do pr√≥ximo n√≠vel**:
- Pronto para explorar arquiteturas AI avan√ßadas (agentes, sistemas multi-agente)
- Preparado para construir sistemas RAG com bases de dados vetoriais
- Equipado para criar aplica√ß√µes AI multimodais
- Base firmada para escalamento e otimiza√ß√£o de aplica√ß√µes AI

## Resumo

üéâ Agora dominou os fundamentos do desenvolvimento de frameworks AI e aprendeu a construir aplica√ß√µes AI sofisticadas usando LangChain. Tal como completar um aprendizado abrangente, adquiriu um conjunto substancial de compet√™ncias. Vamos rever o que alcan√ßou.

### O que aprendeu

**Conceitos fundamentais do framework:**
- **Benef√≠cios do framework**: Quando escolher frameworks em vez de chamadas diretas a API
- **No√ß√µes b√°sicas de LangChain**: Configurar e ligar modelos AI
- **Tipos de mensagens**: Uso de `SystemMessage`, `HumanMessage` e `AIMessage` para conversas estruturadas

**Funcionalidades avan√ßadas:**
- **Chamada de ferramentas**: Criar e integrar ferramentas personalizadas para capacidades AI melhoradas
- **Mem√≥ria de conversa√ß√£o**: Manter contexto ao longo da conversa
- **Respostas em streaming**: Implementar entrega de respostas em tempo real
- **Modelos de prompt**: Construir prompts reutiliz√°veis e din√¢micos
- **Sa√≠da estruturada**: Garantir respostas consistentes e pass√≠veis de an√°lise pela AI
- **Embeddings**: Criar capacidades de pesquisa sem√¢ntica e processamento documental

**Aplica√ß√µes pr√°ticas:**
- **Construir apps completas**: Combinar m√∫ltiplas funcionalidades em aplica√ß√µes prontas para produ√ß√£o
- **Tratamento de erros**: Implementar gest√£o robusta de erros e valida√ß√£o
- **Integra√ß√£o de ferramentas**: Criar ferramentas personalizadas que expandem capacidades AI

### Principais conclus√µes

> üéØ **Lembre-se**: Frameworks AI como LangChain s√£o basicamente os seus melhores amigos para esconder complexidade e com muitas funcionalidades. S√£o perfeitos quando precisa de mem√≥ria de conversa√ß√£o, chamada de ferramentas, ou quer trabalhar com m√∫ltiplos modelos AI sem perder a cabe√ßa.

**Framework de decis√£o para integra√ß√£o AI:**

```mermaid
flowchart TD
    A[Necessidade de Integra√ß√£o AI] --> B{Consulta simples e √∫nica?}
    B -->|Sim| C[Chamadas API diretas]
    B -->|N√£o| D{Necessita de mem√≥ria de conversa?}
    D -->|N√£o| E[Integra√ß√£o SDK]
    D -->|Sim| F{Necessita de ferramentas ou funcionalidades complexas?}
    F -->|N√£o| G[Framework com configura√ß√£o b√°sica]
    F -->|Sim| H[Implementa√ß√£o completa do framework]
    
    C --> I[Pedidos HTTP, depend√™ncias m√≠nimas]
    E --> J[SDK do fornecedor, espec√≠fico do modelo]
    G --> K[Chat b√°sico LangChain]
    H --> L[LangChain com ferramentas, mem√≥ria, agentes]
```
### Para onde seguir agora?

**Comece a construir agora mesmo:**
- Pegue nestes conceitos e construa algo que o entusiasme!
- Experimente diferentes modelos AI atrav√©s do LangChain ‚Äì √© como ter um parque de divers√µes dos modelos AI
- Crie ferramentas que resolvam problemas reais que enfrenta no seu trabalho ou projetos

**Pronto para o pr√≥ximo n√≠vel?**
- **Agentes AI**: Construa sistemas AI que possam planear e executar tarefas complexas por conta pr√≥pria
- **RAG (Gera√ß√£o Aumentada por Recupera√ß√£o)**: Combine AI com as suas pr√≥prias bases de conhecimento para aplica√ß√µes superpotentes
- **AI Multimodal**: Trabalhe com texto, imagens e √°udio em conjunto ‚Äì as possibilidades s√£o infinitas!
- **Desdobramento em produ√ß√£o**: Aprenda a escalar as suas apps AI e a monitoriz√°-las no mundo real

**Junte-se √† comunidade:**
- A comunidade LangChain √© fant√°stica para se manter atualizado e aprender as melhores pr√°ticas
- O GitHub Models oferece acesso a capacidades AI de ponta ‚Äì perfeito para experimentar
- Continue a praticar com diferentes casos de uso ‚Äì cada projeto ensina algo novo

Agora tem o conhecimento para criar aplica√ß√µes inteligentes, conversacionais, que ajudam as pessoas a resolver problemas reais. Tal como os artes√£os do Renascimento que combinaram vis√£o art√≠stica com habilidade t√©cnica, pode agora fundir capacidades AI com aplica√ß√£o pr√°tica. A pergunta √©: o que vai criar? üöÄ

## Desafio do Agente GitHub Copilot üöÄ

Use o modo Agente para completar o seguinte desafio:

**Descri√ß√£o:** Construa um assistente avan√ßado de revis√£o de c√≥digo alimentado por IA que combine m√∫ltiplas funcionalidades LangChain incluindo chamadas a ferramentas, sa√≠da estruturada e mem√≥ria de conversa√ß√£o para fornecer feedback abrangente sobre submiss√µes de c√≥digo.

**Prompt:** Crie uma classe CodeReviewAssistant que implemente:
1. Uma ferramenta para analisar a complexidade do c√≥digo e sugerir melhorias
2. Uma ferramenta para verificar c√≥digo segundo as melhores pr√°ticas
3. Sa√≠da estruturada usando modelos Pydantic para formato consistente de revis√£o
4. Mem√≥ria de conversa para acompanhar sess√µes de revis√£o
5. Uma interface de chat principal capaz de lidar com submiss√µes de c√≥digo e fornecer feedback detalhado e acion√°vel

O assistente deve ser capaz de rever c√≥digo em v√°rias linguagens de programa√ß√£o, manter contexto entre v√°rias submiss√µes de c√≥digo numa sess√£o, e fornecer tanto pontua√ß√µes sum√°rias como sugest√µes detalhadas de melhoria.

Saiba mais sobre [modo agente](https://code.visualstudio.com/blogs/2025/02/24/introducing-copilot-agent-mode) aqui.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos por garantir a precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original na sua l√≠ngua nativa deve ser considerado a fonte autorizada. Para informa√ß√µes cr√≠ticas, recomenda-se tradu√ß√£o profissional feita por um humano. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes erradas resultantes do uso desta tradu√ß√£o.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->