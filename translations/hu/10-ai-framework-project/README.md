<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2c4ae5688e34b4b8b09d52aec56c79e",
  "translation_date": "2025-10-24T20:07:20+00:00",
  "source_file": "10-ai-framework-project/README.md",
  "language_code": "hu"
}
-->
# AI Keretrendszer

Valaha is t√∫lterheltnek √©rezted magad, amikor null√°r√≥l pr√≥b√°lt√°l AI alkalmaz√°sokat √©p√≠teni? Nem vagy egyed√ºl! Az AI keretrendszerek olyanok, mint egy sv√°jci bicska az AI fejleszt√©shez - er≈ëteljes eszk√∂z√∂k, amelyek id≈ët √©s fejf√°j√°st takar√≠tanak meg, mik√∂zben intelligens alkalmaz√°sokat √©p√≠tesz. Gondolj egy AI keretrendszerre √∫gy, mint egy j√≥l szervezett k√∂nyvt√°rra: el≈ëre elk√©sz√≠tett komponenseket, szabv√°nyos√≠tott API-kat √©s okos absztrakci√≥kat biztos√≠t, hogy a probl√©m√°k megold√°s√°ra koncentr√°lhass, ahelyett hogy a megval√≥s√≠t√°s r√©szleteivel k√ºzden√©l.

Ebben a leck√©ben megvizsg√°ljuk, hogyan alak√≠thatj√°k √°t a keretrendszerek, mint p√©ld√°ul a LangChain, a kor√°bban bonyolult AI integr√°ci√≥s feladatokat tiszta, olvashat√≥ k√≥dd√°. Felfedezheted, hogyan kezelheted a val√≥s kih√≠v√°sokat, mint p√©ld√°ul a besz√©lget√©sek nyomon k√∂vet√©se, eszk√∂z√∂k h√≠v√°sa √©s k√ºl√∂nb√∂z≈ë AI modellek egyes√≠tett interf√©szen kereszt√ºli kezel√©se.

Mire v√©gezt√ºnk, tudni fogod, mikor √©rdemes keretrendszereket haszn√°lni a nyers API h√≠v√°sok helyett, hogyan haszn√°lhatod hat√©konyan az absztrakci√≥ikat, √©s hogyan √©p√≠thetsz val√≥s haszn√°latra k√©sz AI alkalmaz√°sokat. N√©zz√ºk meg, mit tehetnek az AI keretrendszerek a projektjeid√©rt.

## Mi√©rt v√°lassz keretrendszert?

Teh√°t k√©szen √°llsz egy AI alkalmaz√°s √©p√≠t√©s√©re - szuper! De itt van a dolog: t√∂bb k√ºl√∂nb√∂z≈ë √∫t √°ll el≈ëtted, √©s mindegyiknek megvannak a maga el≈ënyei √©s h√°tr√°nyai. Ez olyan, mint v√°lasztani, hogy gyalog, biciklivel vagy aut√≥val jutsz el valahov√° - mindegyik eljuttat a c√©lhoz, de az √©lm√©ny (√©s az er≈ëfesz√≠t√©s) teljesen m√°s lesz.

N√©zz√ºk meg az AI integr√°ci√≥ h√°rom f≈ë m√≥dj√°t a projektjeidben:

| Megk√∂zel√≠t√©s | El≈ëny√∂k | Legjobb felhaszn√°l√°s | Megfontol√°sok |
|--------------|---------|----------------------|---------------|
| **K√∂zvetlen HTTP k√©r√©sek** | Teljes kontroll, nincs f√ºgg≈ës√©g | Egyszer≈± lek√©rdez√©sek, alapok tanul√°sa | B≈ëbesz√©d≈± k√≥d, manu√°lis hibakezel√©s |
| **SDK integr√°ci√≥** | Kevesebb sablonk√≥d, modell-specifikus optimaliz√°ci√≥ | Egyetlen modell alkalmaz√°sok | Korl√°tozott specifikus szolg√°ltat√≥kra |
| **AI keretrendszerek** | Egys√©ges API, be√©p√≠tett absztrakci√≥k | T√∂bb modell alkalmaz√°sok, √∂sszetett munkafolyamatok | Tanul√°si g√∂rbe, esetleges t√∫lzott absztrakci√≥ |

### Keretrendszerek gyakorlati el≈ënyei

```mermaid
graph TD
    A[Your Application] --> B[AI Framework]
    B --> C[OpenAI GPT]
    B --> D[Anthropic Claude]
    B --> E[GitHub Models]
    B --> F[Local Models]
    
    B --> G[Built-in Tools]
    G --> H[Memory Management]
    G --> I[Conversation History]
    G --> J[Function Calling]
    G --> K[Error Handling]
```

**Mi√©rt fontosak a keretrendszerek:**
- **Egys√©ges√≠ti** t√∂bb AI szolg√°ltat√≥t egy interf√©szen kereszt√ºl
- **Automatikusan kezeli** a besz√©lget√©si mem√≥ri√°t
- **K√©sz eszk√∂z√∂ket biztos√≠t** gyakori feladatokhoz, mint p√©ld√°ul be√°gyaz√°sok √©s funkci√≥h√≠v√°sok
- **Kezeli** a hibakezel√©st √©s az √∫jrapr√≥b√°lkoz√°si logik√°t
- **√Åtalak√≠tja** az √∂sszetett munkafolyamatokat olvashat√≥ met√≥dush√≠v√°sokk√°

> üí° **Profi tipp**: Haszn√°lj keretrendszereket, amikor k√ºl√∂nb√∂z≈ë AI modellek k√∂z√∂tt v√°ltasz, vagy √∂sszetett funkci√≥kat, mint p√©ld√°ul √ºgyn√∂k√∂k, mem√≥ria vagy eszk√∂z√∂k h√≠v√°sa √©p√≠tesz. Maradj a k√∂zvetlen API-kn√°l, amikor az alapokat tanulod vagy egyszer≈±, f√≥kusz√°lt alkalmaz√°sokat √©p√≠tesz.

**L√©nyeg**: Mint v√°lasztani egy mesterember speci√°lis eszk√∂zei √©s egy teljes m≈±hely k√∂z√∂tt, ez arr√≥l sz√≥l, hogy az eszk√∂zt a feladathoz igaz√≠tsuk. A keretrendszerek kiv√°l√≥ak √∂sszetett, funkci√≥kban gazdag alkalmaz√°sokhoz, m√≠g a k√∂zvetlen API-k j√≥l m≈±k√∂dnek egyszer≈±bb esetekben.

## Bevezet√©s

Ebben a leck√©ben megtanuljuk:

- Egy k√∂z√∂s AI keretrendszer haszn√°lat√°t.
- Gyakori probl√©m√°k megold√°s√°t, mint p√©ld√°ul chat besz√©lget√©sek, eszk√∂zhaszn√°lat, mem√≥ria √©s kontextus.
- Hogyan haszn√°lhatjuk ezt AI alkalmaz√°sok √©p√≠t√©s√©re.

## Az els≈ë AI k√©rd√©sed

Kezdj√ºk az alapokkal, √©s hozzuk l√©tre az els≈ë AI alkalmaz√°sodat, amely k√©rd√©st k√ºld √©s v√°laszt kap. Mint ahogy Arkhim√©d√©sz felfedezte a v√≠zkiszor√≠t√°s elv√©t a f√ºrd≈ëj√©ben, n√©ha a legegyszer≈±bb megfigyel√©sek vezetnek a leger≈ëteljesebb felismer√©sekhez - √©s a keretrendszerek hozz√°f√©rhet≈ëv√© teszik ezeket a felismer√©seket.

### LangChain be√°ll√≠t√°sa GitHub Modellek haszn√°lat√°val

A LangChain-t fogjuk haszn√°lni, hogy csatlakozzunk a GitHub Modellekhez, ami el√©g szuper, mert ingyenes hozz√°f√©r√©st biztos√≠t k√ºl√∂nb√∂z≈ë AI modellekhez. A legjobb r√©sz? Csak n√©h√°ny egyszer≈± konfigur√°ci√≥s param√©terre van sz√ºks√©ged a kezd√©shez:

```python
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

# Send a simple prompt
response = llm.invoke("What's the capital of France?")
print(response.content)
```

**N√©zz√ºk meg, mi t√∂rt√©nik itt:**
- **L√©trehoz egy** LangChain klienst a `ChatOpenAI` oszt√°ly haszn√°lat√°val - ez az AI kapud!
- **Konfigur√°lja** a kapcsolatot a GitHub Modellekhez az autentik√°ci√≥s tokeneddel
- **Meghat√°rozza**, melyik AI modellt haszn√°lja (`gpt-4o-mini`) - gondolj erre √∫gy, mint az AI asszisztensed kiv√°laszt√°s√°ra
- **Elk√ºldi** a k√©rd√©sed az `invoke()` met√≥dus haszn√°lat√°val - itt t√∂rt√©nik a var√°zslat
- **Kinyeri** √©s megjelen√≠ti a v√°laszt - √©s voil√†, besz√©lgetsz az AI-val!

> üîß **Be√°ll√≠t√°si megjegyz√©s**: Ha GitHub Codespaces-t haszn√°lsz, szerencs√©d van - a `GITHUB_TOKEN` m√°r be van √°ll√≠tva! Helyben dolgozol? Ne agg√≥dj, csak l√©tre kell hoznod egy szem√©lyes hozz√°f√©r√©si tokent a megfelel≈ë jogosults√°gokkal.

**V√°rhat√≥ kimenet:**
```text
The capital of France is Paris.
```

```mermaid
sequenceDiagram
    participant App as Your Python App
    participant LC as LangChain
    participant GM as GitHub Models
    participant AI as GPT-4o-mini
    
    App->>LC: llm.invoke("What's the capital of France?")
    LC->>GM: HTTP request with prompt
    GM->>AI: Process prompt
    AI->>GM: Generated response
    GM->>LC: Return response
    LC->>App: response.content
```

## Besz√©lget≈ë AI √©p√≠t√©se

Az els≈ë p√©lda bemutatja az alapokat, de ez csak egyetlen csere - k√©rdezel valamit, kapsz egy v√°laszt, √©s ennyi. A val√≥s alkalmaz√°sokban azt szeretn√©d, hogy az AI eml√©kezzen arra, mir≈ël besz√©ltetek, mint ahogy Watson √©s Holmes √©p√≠tett√©k fel nyomoz√°si besz√©lget√©seiket az id≈ë m√∫l√°s√°val.

Itt v√°lik k√ºl√∂n√∂sen hasznoss√° a LangChain. K√ºl√∂nb√∂z≈ë √ºzenett√≠pusokat biztos√≠t, amelyek seg√≠tenek struktur√°lni a besz√©lget√©seket, √©s lehet≈ëv√© teszik, hogy szem√©lyis√©get adj az AI-nak. Olyan chat √©lm√©nyeket fogsz √©p√≠teni, amelyek meg≈ërzik a kontextust √©s a karaktert.

### √úzenett√≠pusok meg√©rt√©se

Gondolj ezekre az √ºzenett√≠pusokra √∫gy, mint k√ºl√∂nb√∂z≈ë "kalapokra", amelyeket a besz√©lget√©s r√©sztvev≈ëi viselnek. A LangChain k√ºl√∂nb√∂z≈ë √ºzenet oszt√°lyokat haszn√°l, hogy nyomon k√∂vesse, ki mit mond:

| √úzenett√≠pus | C√©l | P√©lda felhaszn√°l√°s |
|-------------|-----|--------------------|
| `SystemMessage` | Meghat√°rozza az AI szem√©lyis√©g√©t √©s viselked√©s√©t | "Te egy seg√≠t≈ëk√©sz k√≥dol√°si asszisztens vagy" |
| `HumanMessage` | A felhaszn√°l√≥i bemenetet k√©pviseli | "Magyar√°zd el, hogyan m≈±k√∂dnek a f√ºggv√©nyek" |
| `AIMessage` | Az AI v√°laszait t√°rolja | Kor√°bbi AI v√°laszok a besz√©lget√©sben |

### Az els≈ë besz√©lget√©s l√©trehoz√°sa

Hozzunk l√©tre egy besz√©lget√©st, ahol az AI egy konkr√©t szerepet v√°llal. Legyen p√©ld√°ul Jean-Luc Picard kapit√°ny - egy karakter, aki diplomatikus b√∂lcsess√©g√©r≈ël √©s vezet≈ëi k√©pess√©geir≈ël ismert:

```python
messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]
```

**A besz√©lget√©s be√°ll√≠t√°s√°nak r√©szletez√©se:**
- **Meghat√°rozza** az AI szerep√©t √©s szem√©lyis√©g√©t a `SystemMessage` seg√≠ts√©g√©vel
- **Biztos√≠tja** a kezdeti felhaszn√°l√≥i k√©rd√©st a `HumanMessage` seg√≠ts√©g√©vel
- **Alapot teremt** a t√∂bbfordul√≥s besz√©lget√©shez

A teljes k√≥d az al√°bbiak szerint n√©z ki:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]


# works
response  = llm.invoke(messages)
print(response.content)
```

Egy hasonl√≥ eredm√©nyt kell l√°tnod:

```text
I am Captain Jean-Luc Picard, the commanding officer of the USS Enterprise (NCC-1701-D), a starship in the United Federation of Planets. My primary mission is to explore new worlds, seek out new life and new civilizations, and boldly go where no one has gone before. 

I believe in the importance of diplomacy, reason, and the pursuit of knowledge. My crew is diverse and skilled, and we often face challenges that test our resolve, ethics, and ingenuity. Throughout my career, I have encountered numerous species, grappled with complex moral dilemmas, and have consistently sought peaceful solutions to conflicts.

I hold the ideals of the Federation close to my heart, believing in the importance of cooperation, understanding, and respect for all sentient beings. My experiences have shaped my leadership style, and I strive to be a thoughtful and just captain. How may I assist you further?
```

A besz√©lget√©s folytonoss√°g√°nak fenntart√°s√°hoz (ahelyett, hogy minden alkalommal √∫jraind√≠tan√°d a kontextust), folyamatosan hozz√° kell adnod a v√°laszokat az √ºzenetlist√°dhoz. Mint az or√°lis hagyom√°nyok, amelyek gener√°ci√≥kon kereszt√ºl meg≈ërizt√©k a t√∂rt√©neteket, ez a megk√∂zel√≠t√©s tart√≥s mem√≥ri√°t √©p√≠t:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]


# works
response  = llm.invoke(messages)

print(response.content)

print("---- Next ----")

messages.append(response)
messages.append(HumanMessage(content="Now that I know about you, I'm Chris, can I be in your crew?"))

response  = llm.invoke(messages)

print(response.content)

```

El√©g klassz, igaz? Ami itt t√∂rt√©nik, az az, hogy k√©tszer h√≠vjuk meg az LLM-et - el≈ësz√∂r csak az els≈ë k√©t √ºzenet√ºnkkel, majd √∫jra a teljes besz√©lget√©si t√∂rt√©nelemmel. Olyan, mintha az AI t√©nyleg k√∂vetn√© a besz√©lget√©s√ºnket!

Amikor futtatod ezt a k√≥dot, egy m√°sodik v√°laszt kapsz, ami valahogy √≠gy hangzik:

```text
Welcome aboard, Chris! It's always a pleasure to meet those who share a passion for exploration and discovery. While I cannot formally offer you a position on the Enterprise right now, I encourage you to pursue your aspirations. We are always in need of talented individuals with diverse skills and backgrounds. 

If you are interested in space exploration, consider education and training in the sciences, engineering, or diplomacy. The values of curiosity, resilience, and teamwork are crucial in Starfleet. Should you ever find yourself on a starship, remember to uphold the principles of the Federation: peace, understanding, and respect for all beings. Your journey can lead you to remarkable adventures, whether in the stars or on the ground. Engage!
```

Ezt tal√°n elfogadom v√°laszk√©nt ;)

## Streaming v√°laszok

√âszrevetted m√°r, hogy a ChatGPT "val√≥s id≈ëben" g√©pelni l√°tszik a v√°laszait? Ez a streaming m≈±k√∂d√©se. Mint amikor egy √ºgyes kalligr√°fus dolgozik - l√°tni, ahogy a karakterek von√°sr√≥l von√°sra jelennek meg, nem pedig azonnal - a streaming term√©szetesebb√© teszi az interakci√≥t, √©s azonnali visszajelz√©st ny√∫jt.

### Streaming megval√≥s√≠t√°sa LangChain-nel

```python
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
    streaming=True
)

# Stream the response
for chunk in llm.stream("Write a short story about a robot learning to code"):
    print(chunk.content, end="", flush=True)
```

**Mi√©rt nagyszer≈± a streaming:**
- **Megmutatja** a tartalmat, amint l√©trej√∂n - nincs t√∂bb k√≠nos v√°rakoz√°s!
- **√ârezteti** a felhaszn√°l√≥kkal, hogy valami t√©nyleg t√∂rt√©nik
- **Gyorsabbnak t≈±nik**, m√©g ha technikailag nem is az
- **Lehet≈ëv√© teszi**, hogy a felhaszn√°l√≥k elkezdjenek olvasni, mik√∂zben az AI m√©g "gondolkodik"

> üí° **Felhaszn√°l√≥i √©lm√©ny tipp**: A streaming igaz√°n akkor ragyog, amikor hosszabb v√°laszokkal dolgozol, mint p√©ld√°ul k√≥dmagyar√°zatok, kreat√≠v √≠r√°s vagy r√©szletes oktat√≥anyagok. A felhaszn√°l√≥id im√°dni fogj√°k l√°tni a halad√°st, ahelyett hogy egy √ºres k√©perny≈ët b√°muln√°nak!

## Prompt sablonok

A prompt sablonok olyanok, mint a klasszikus sz√≥noklatban haszn√°lt retorikai strukt√∫r√°k - gondolj arra, hogyan alkalmazta Cicero a besz√©dmint√°it k√ºl√∂nb√∂z≈ë k√∂z√∂ns√©gekhez, mik√∂zben megtartotta ugyanazt a meggy≈ëz≈ë keretet. Lehet≈ëv√© teszik, hogy √∫jrahaszn√°lhat√≥ promptokat hozz l√©tre, ahol k√ºl√∂nb√∂z≈ë inform√°ci√≥kat cser√©lhetsz ki an√©lk√ºl, hogy mindent √∫jra√≠rn√°l. Miut√°n be√°ll√≠tottad a sablont, csak ki kell t√∂ltened a v√°ltoz√≥kat a sz√ºks√©ges √©rt√©kekkel.

### √öjrahaszn√°lhat√≥ promptok l√©trehoz√°sa

```python
from langchain_core.prompts import ChatPromptTemplate

# Define a template for code explanations
template = ChatPromptTemplate.from_messages([
    ("system", "You are an expert programming instructor. Explain concepts clearly with examples."),
    ("human", "Explain {concept} in {language} with a practical example for {skill_level} developers")
])

# Use the template with different values
questions = [
    {"concept": "functions", "language": "JavaScript", "skill_level": "beginner"},
    {"concept": "classes", "language": "Python", "skill_level": "intermediate"},
    {"concept": "async/await", "language": "JavaScript", "skill_level": "advanced"}
]

for question in questions:
    prompt = template.format_messages(**question)
    response = llm.invoke(prompt)
    print(f"Topic: {question['concept']}\n{response.content}\n---\n")
```

**Mi√©rt fogod szeretni a sablonok haszn√°lat√°t:**
- **Konzisztenss√© teszi** a promptjaidat az eg√©sz alkalmaz√°sban
- **Nincs t√∂bb√©** rendetlen sz√∂veg√∂sszef≈±z√©s - csak tiszta, egyszer≈± v√°ltoz√≥k
- **Az AI-d** kisz√°m√≠that√≥an viselkedik, mert a strukt√∫ra v√°ltozatlan marad
- **Friss√≠t√©sek** egyszer≈±ek - v√°ltoztasd meg a sablont egyszer, √©s mindenhol jav√≠tva van

## Struktur√°lt kimenet

Valaha frusztr√°lt√°l m√°r, amikor az AI v√°laszai rendezetlen sz√∂vegk√©nt √©rkeztek vissza? A struktur√°lt kimenet olyan, mintha megtan√≠tan√°d az AI-t, hogy k√∂vesse a rendszerezett megk√∂zel√≠t√©st, amelyet Linnaeus haszn√°lt a biol√≥giai oszt√°lyoz√°shoz - szervezett, kisz√°m√≠that√≥ √©s k√∂nnyen kezelhet≈ë. K√©rhetsz JSON-t, specifikus adatstrukt√∫r√°kat vagy b√°rmilyen form√°tumot, amire sz√ºks√©ged van.

### Kimeneti s√©m√°k meghat√°roz√°sa

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel, Field

class CodeReview(BaseModel):
    score: int = Field(description="Code quality score from 1-10")
    strengths: list[str] = Field(description="List of code strengths")
    improvements: list[str] = Field(description="List of suggested improvements")
    overall_feedback: str = Field(description="Summary feedback")

# Set up the parser
parser = JsonOutputParser(pydantic_object=CodeReview)

# Create prompt with format instructions
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a code reviewer. {format_instructions}"),
    ("human", "Review this code: {code}")
])

# Format the prompt with instructions
chain = prompt | llm | parser

# Get structured response
code_sample = """
def calculate_average(numbers):
    return sum(numbers) / len(numbers)
"""

result = chain.invoke({
    "code": code_sample,
    "format_instructions": parser.get_format_instructions()
})

print(f"Score: {result['score']}")
print(f"Strengths: {', '.join(result['strengths'])}")
```

**Mi√©rt v√°ltoztatja meg a j√°t√©kot a struktur√°lt kimenet:**
- **Nincs t√∂bb√©** tal√°lgat√°s, hogy milyen form√°tumot kapsz vissza - mindig k√∂vetkezetes
- **K√∂zvetlen√ºl csatlakozik** az adatb√°zisaidhoz √©s API-jaidhoz extra munka n√©lk√ºl
- **Elkapja** a furcsa AI v√°laszokat, miel≈ëtt azok t√∂nkretenn√©k az alkalmaz√°sodat
- **Tiszt√°bb√° teszi** a k√≥dodat, mert pontosan tudod, mivel dolgozol

## Eszk√∂z√∂k h√≠v√°sa

Most el√©rkezt√ºnk az egyik leger≈ëteljesebb funkci√≥hoz: az eszk√∂z√∂k. Ez az, ahogyan gyakorlati k√©pess√©geket adsz az AI-nak a besz√©lget√©sen t√∫l. Mint ahogy a k√∂z√©pkori c√©hek speci√°lis eszk√∂z√∂ket fejlesztettek ki konkr√©t mesters√©gekhez, te is felszerelheted az AI-t f√≥kusz√°lt eszk√∂z√∂kkel. Le√≠rod, milyen eszk√∂z√∂k √°llnak rendelkez√©sre, √©s amikor valaki olyasmit k√©r, ami megfelel, az AI cselekedhet.

### Python haszn√°lata

Adjunk hozz√° n√©h√°ny eszk√∂zt √≠gy:

```python
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

tools = [add]

functions = {
    "add": lambda a, b: a + b
}
```

Mi t√∂rt√©nik itt? L√©trehozunk egy tervet egy `add` nev≈± eszk√∂zh√∂z. Az `TypedDict` √∂r√∂kl√©s√©vel √©s ezekkel a divatos `Annotated` t√≠pusokkal az `a` √©s `b` eset√©ben egy√©rtelm≈± k√©pet adunk az LLM-nek arr√≥l, hogy mit csin√°l ez az eszk√∂z, √©s mire van sz√ºks√©ge. A `functions` sz√≥t√°r olyan, mint a szersz√°mosl√°d√°nk - megmondja a k√≥dunknak, pontosan mit kell tennie, amikor az AI √∫gy d√∂nt, hogy haszn√°l egy adott eszk√∂zt.

N√©zz√ºk meg, hogyan h√≠vjuk meg az LLM-et ezzel az eszk√∂zzel:

```python
llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)
```

Itt a `bind_tools`-t h√≠vjuk meg a `tools` t√∂mb√ºnkkel, √©s √≠gy az LLM `llm_with_tools` most m√°r ismeri ezt az eszk√∂zt.

Ennek az √∫j LLM-nek a haszn√°lat√°hoz a k√∂vetkez≈ë k√≥dot √≠rhatjuk:

```python
query = "What is 3 + 12?"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

Most, hogy az √∫j LLM-en h√≠vjuk meg az `invoke`-t, amely eszk√∂z√∂kkel rendelkezik, lehet, hogy a `tool_calls` tulajdons√°got kit√∂ltve l√°tjuk. Ha igen, b√°rmely azonos√≠tott eszk√∂znek van egy `name` √©s `args` tulajdons√°ga, amely azonos√≠tja, hogy melyik eszk√∂zt kell h√≠vni √©s milyen argumentumokkal. A teljes k√≥d √≠gy n√©z ki:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

tools = [add]

functions = {
    "add": lambda a, b: a + b
}

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)

query = "What is 3 + 12?"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

A k√≥d futtat√°sakor hasonl√≥ kimenetet kell l√°tnod:

```text
TOOL CALL:  15
CONTENT: 
```

Az AI megvizsg√°lta a "Mi az 3 + 12" k√©rd√©st, √©s felismerte ezt egy `add` eszk√∂z feladatak√©nt. Mint ahogy egy √ºgyes k√∂nyvt√°ros tudja, melyik referenci√°t kell konzult√°lnia a k√©rd√©s t√≠pus√°t√≥l f√ºgg≈ëen, ezt a d√∂nt√©st az eszk√∂z neve, le√≠r√°sa √©s mez≈ëspecifik√°ci√≥i alapj√°n hozta meg. A 15-√∂s eredm√©ny a `functions` sz√≥t√°runkb√≥l sz√°rmazik, amely v√©grehajtja az eszk√∂zt:

```python
print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
```

### Egy √©rdekesebb eszk√∂z, amely webes API-t h√≠v

A sz√°mok √∂sszead√°sa bemutatja a koncepci√≥t, de a val√≥di eszk√∂z√∂k √°ltal√°ban √∂sszetettebb m≈±veleteket v√©geznek, p√©ld√°ul webes API-k h√≠v√°s√°t. B≈ë
3. **Szem√©lyre szabott tanul√°s**: Haszn√°lj rendszer√ºzeneteket a v√°laszok k√ºl√∂nb√∂z≈ë k√©szs√©gszintekhez val√≥ igaz√≠t√°s√°hoz  
4. **V√°laszform√°z√°s**: Val√≥s√≠ts meg struktur√°lt kimenetet kv√≠zk√©rd√©sekhez  

### Megval√≥s√≠t√°si l√©p√©sek  

**1. l√©p√©s: √Åll√≠tsd be a k√∂rnyezeted**  
```bash
pip install langchain langchain-openai
```
  
**2. l√©p√©s: Alapvet≈ë chat funkci√≥k**  
- Hozz l√©tre egy `StudyAssistant` oszt√°lyt  
- Val√≥s√≠tsd meg a besz√©lget√©si mem√≥ri√°t  
- Adj hozz√° szem√©lyis√©gkonfigur√°ci√≥t oktat√°si t√°mogat√°shoz  

**3. l√©p√©s: Oktat√°si eszk√∂z√∂k hozz√°ad√°sa**  
- **K√≥dmagyar√°z√≥**: √ârthet≈ë r√©szekre bontja a k√≥dot  
- **Kv√≠zgener√°tor**: K√©rd√©seket k√©sz√≠t programoz√°si fogalmakr√≥l  
- **Halad√°sk√∂vet≈ë**: Nyomon k√∂veti a lefedett t√©m√°kat  

**4. l√©p√©s: Fejlett funkci√≥k (opcion√°lis)**  
- Val√≥s√≠ts meg streaming v√°laszokat a jobb felhaszn√°l√≥i √©lm√©ny √©rdek√©ben  
- Adj hozz√° dokumentum bet√∂lt√©st a tananyagok be√©p√≠t√©s√©hez  
- Hozz l√©tre be√°gyaz√°sokat hasonl√≥s√°g-alap√∫ tartalomkeres√©shez  

### √ârt√©kel√©si krit√©riumok  

| Funkci√≥ | Kiv√°l√≥ (4) | J√≥ (3) | Kiel√©g√≠t≈ë (2) | Fejleszt√©sre szorul (1) |  
|---------|------------|--------|----------------|--------------------------|  
| **Besz√©lget√©si folyamat** | Term√©szetes, kontextusra √©rz√©keny v√°laszok | J√≥ kontextusmeg≈ërz√©s | Alapvet≈ë besz√©lget√©s | Nincs mem√≥ria az √ºzenetek k√∂z√∂tt |  
| **Eszk√∂zintegr√°ci√≥** | T√∂bb hasznos eszk√∂z z√∂kken≈ëmentesen m≈±k√∂dik | 2+ eszk√∂z helyesen implement√°lva | 1-2 alapvet≈ë eszk√∂z | Az eszk√∂z√∂k nem m≈±k√∂dnek |  
| **K√≥dmin≈ës√©g** | Tiszta, j√≥l dokument√°lt, hibakezel√©s | J√≥ strukt√∫ra, n√©mi dokument√°ci√≥ | Alapvet≈ë funkcionalit√°s m≈±k√∂dik | Rossz strukt√∫ra, nincs hibakezel√©s |  
| **Oktat√°si √©rt√©k** | Val√≥ban seg√≠ti a tanul√°st, adapt√≠v | J√≥ tanul√°si t√°mogat√°s | Alapvet≈ë magyar√°zatok | Korl√°tozott oktat√°si haszon |  

### P√©lda k√≥dstrukt√∫ra  

```python
class StudyAssistant:
    def __init__(self, skill_level="beginner"):
        # Initialize LLM, tools, and conversation memory
        pass
    
    def explain_code(self, code, language):
        # Tool: Explain how code works
        pass
    
    def generate_quiz(self, topic, difficulty):
        # Tool: Create practice questions
        pass
    
    def chat(self, user_input):
        # Main conversation interface
        pass

# Example usage
assistant = StudyAssistant(skill_level="intermediate")
response = assistant.chat("Explain how Python functions work")
```
  
**B√≥nusz kih√≠v√°sok:**  
- Adj hozz√° hangbemeneti/kimeneti k√©pess√©geket  
- Val√≥s√≠ts meg webes fel√ºletet Streamlit vagy Flask seg√≠ts√©g√©vel  
- Hozz l√©tre tud√°sb√°zist tananyagokb√≥l be√°gyaz√°sokkal  
- Adj hozz√° halad√°sk√∂vet√©st √©s szem√©lyre szabott tanul√°si √∫tvonalakat  

## √ñsszefoglal√≥  

üéâ Mostanra elsaj√°t√≠tottad az AI keretrendszer fejleszt√©s alapjait, √©s megtanultad, hogyan √©p√≠ts kifinomult AI alkalmaz√°sokat LangChain seg√≠ts√©g√©vel. Mint egy √°tfog√≥ tanul√≥id≈ëszakot befejezve, jelent≈ës eszk√∂zt√°rat szerezt√©l. N√©zz√ºk √°t, mit √©rt√©l el.  

### Amit megtanult√°l  

**Alapvet≈ë keretrendszer fogalmak:**  
- **Keretrendszer el≈ënyei**: Meg√©rteni, mikor √©rdemes keretrendszereket v√°lasztani k√∂zvetlen API-h√≠v√°sok helyett  
- **LangChain alapok**: AI modellkapcsolatok be√°ll√≠t√°sa √©s konfigur√°l√°sa  
- **√úzenett√≠pusok**: `SystemMessage`, `HumanMessage` √©s `AIMessage` haszn√°lata struktur√°lt besz√©lget√©sekhez  

**Fejlett funkci√≥k:**  
- **Eszk√∂z h√≠v√°s**: Egyedi eszk√∂z√∂k l√©trehoz√°sa √©s integr√°l√°sa az AI k√©pess√©gek b≈ëv√≠t√©s√©hez  
- **Besz√©lget√©si mem√≥ria**: Kontextus meg≈ërz√©se t√∂bb besz√©lget√©si fordul√≥ sor√°n  
- **Streaming v√°laszok**: Val√≥s idej≈± v√°laszok megval√≥s√≠t√°sa  
- **Prompt sablonok**: √öjrahaszn√°lhat√≥, dinamikus promptok l√©trehoz√°sa  
- **Struktur√°lt kimenet**: Konzisztens, elemezhet≈ë AI v√°laszok biztos√≠t√°sa  
- **Be√°gyaz√°sok**: Szemantikus keres√©s √©s dokumentumfeldolgoz√°si k√©pess√©gek l√©trehoz√°sa  

**Gyakorlati alkalmaz√°sok:**  
- **Teljes alkalmaz√°sok √©p√≠t√©se**: T√∂bb funkci√≥ kombin√°l√°sa gy√°rt√°sra k√©sz alkalmaz√°sokba  
- **Hibakezel√©s**: Robusztus hibakezel√©s √©s valid√°ci√≥ megval√≥s√≠t√°sa  
- **Eszk√∂zintegr√°ci√≥**: Egyedi eszk√∂z√∂k l√©trehoz√°sa, amelyek b≈ëv√≠tik az AI k√©pess√©geket  

### F≈ë tanuls√°gok  

> üéØ **Eml√©kezz**: Az AI keretrendszerek, mint a LangChain, alapvet≈ëen a komplexit√°st elrejt≈ë, funkci√≥kkal teli legjobb bar√°taid. T√∂k√©letesek, ha besz√©lget√©si mem√≥ri√°ra, eszk√∂z h√≠v√°sra van sz√ºks√©ged, vagy t√∂bb AI modellel szeretn√©l dolgozni an√©lk√ºl, hogy elvesz√≠ten√©d a j√≥zan eszed.  

**D√∂nt√©si keretrendszer az AI integr√°ci√≥hoz:**  

```mermaid
flowchart TD
    A[AI Integration Need] --> B{Simple single query?}
    B -->|Yes| C[Direct API calls]
    B -->|No| D{Need conversation memory?}
    D -->|No| E[SDK Integration]
    D -->|Yes| F{Need tools or complex features?}
    F -->|No| G[Framework with basic setup]
    F -->|Yes| H[Full framework implementation]
    
    C --> I[HTTP requests, minimal dependencies]
    E --> J[Provider SDK, model-specific]
    G --> K[LangChain basic chat]
    H --> L[LangChain with tools, memory, agents]
```
  
### Hogyan tov√°bb?  

**Kezdj el √©p√≠teni most:**  
- Vedd ezeket a fogalmakat, √©s √©p√≠ts valamit, ami izgat t√©ged!  
- J√°tssz k√ºl√∂nb√∂z≈ë AI modellekkel LangChain seg√≠ts√©g√©vel - olyan, mintha egy AI modellek j√°tsz√≥ter√©n lenn√©l  
- Hozz l√©tre eszk√∂z√∂ket, amelyek val√≥di probl√©m√°kat oldanak meg a munk√°dban vagy projektjeidben  

**K√©szen √°llsz a k√∂vetkez≈ë szintre?**  
- **AI √ºgyn√∂k√∂k**: √âp√≠ts AI rendszereket, amelyek √∂n√°ll√≥an k√©pesek √∂sszetett feladatokat tervezni √©s v√©grehajtani  
- **RAG (Retrieval-Augmented Generation)**: Kombin√°ld az AI-t saj√°t tud√°sb√°zisoddal szuperer≈ës alkalmaz√°sokhoz  
- **Multi-Modal AI**: Dolgozz sz√∂veggel, k√©pekkel √©s hanggal egy√ºtt - a lehet≈ës√©gek v√©gtelenek!  
- **Gy√°rt√°si telep√≠t√©s**: Tanuld meg, hogyan sk√°l√°zd az AI alkalmaz√°saidat, √©s hogyan monitorozd ≈ëket a val√≥ vil√°gban  

**Csatlakozz a k√∂z√∂ss√©ghez:**  
- A LangChain k√∂z√∂ss√©g fantasztikus, hogy naprak√©sz maradj √©s megtanuld a legjobb gyakorlatokat  
- A GitHub Models hozz√°f√©r√©st biztos√≠t a legmodernebb AI k√©pess√©gekhez - t√∂k√©letes k√≠s√©rletez√©shez  
- Gyakorolj k√ºl√∂nb√∂z≈ë felhaszn√°l√°si esetekkel - minden projekt valami √∫jat tan√≠t  

Most m√°r megvan a tud√°sod ahhoz, hogy intelligens, besz√©lget≈ë alkalmaz√°sokat √©p√≠ts, amelyek val√≥di probl√©m√°k megold√°s√°ban seg√≠tenek az embereknek. Mint a renesz√°nsz mesterek, akik m≈±v√©szi l√°t√°sm√≥dot √∂tv√∂ztek technikai k√©szs√©gekkel, most m√°r te is k√©pes vagy az AI k√©pess√©geket gyakorlati alkalmaz√°ssal kombin√°lni. A k√©rd√©s az: mit fogsz l√©trehozni? üöÄ  

## GitHub Copilot Agent kih√≠v√°s üöÄ  

Haszn√°ld az Agent m√≥dot a k√∂vetkez≈ë kih√≠v√°s teljes√≠t√©s√©hez:  

**Le√≠r√°s:** √âp√≠ts egy fejlett AI-alap√∫ k√≥dellen≈ërz≈ë asszisztenst, amely t√∂bb LangChain funkci√≥t kombin√°l, bele√©rtve az eszk√∂z h√≠v√°st, struktur√°lt kimenetet √©s besz√©lget√©si mem√≥ri√°t, hogy √°tfog√≥ visszajelz√©st ny√∫jtson a k√≥dbead√°sokkal kapcsolatban.  

**Prompt:** Hozz l√©tre egy CodeReviewAssistant oszt√°lyt, amely megval√≥s√≠tja:  
1. Egy eszk√∂zt a k√≥d komplexit√°s√°nak elemz√©s√©re √©s fejleszt√©si javaslatok ad√°s√°ra  
2. Egy eszk√∂zt a k√≥d legjobb gyakorlatoknak val√≥ megfelel√©s√©nek ellen≈ërz√©s√©re  
3. Struktur√°lt kimenetet Pydantic modellek seg√≠ts√©g√©vel a konzisztens ellen≈ërz√©si form√°tumhoz  
4. Besz√©lget√©si mem√≥ri√°t az ellen≈ërz√©si √ºl√©sek nyomon k√∂vet√©s√©re  
5. Egy f≈ë chat fel√ºletet, amely k√©pes kezelni a k√≥dbead√°sokat √©s r√©szletes, cselekv√©sre alkalmas visszajelz√©st adni  

Az asszisztensnek k√©pesnek kell lennie t√∂bb programoz√°si nyelv k√≥dj√°nak ellen≈ërz√©s√©re, kontextust meg≈ërizni t√∂bb k√≥dbead√°s sor√°n egy munkamenetben, √©s mind √∂sszefoglal√≥ pontsz√°mokat, mind r√©szletes fejleszt√©si javaslatokat ny√∫jtani.  

Tov√°bbi inform√°ci√≥ az [agent mode](https://code.visualstudio.com/blogs/2025/02/24/introducing-copilot-agent-mode) haszn√°lat√°r√≥l itt tal√°lhat√≥.  

---

**Felel≈ëss√©g kiz√°r√°sa**:  
Ez a dokumentum az [Co-op Translator](https://github.com/Azure/co-op-translator) AI ford√≠t√°si szolg√°ltat√°s seg√≠ts√©g√©vel lett leford√≠tva. B√°r t√∂reksz√ºnk a pontoss√°gra, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelv√©n tekintend≈ë hiteles forr√°snak. Kritikus inform√°ci√≥k eset√©n javasolt professzion√°lis emberi ford√≠t√°st ig√©nybe venni. Nem v√°llalunk felel≈ëss√©get semmilyen f√©lre√©rt√©s√©rt vagy t√©ves √©rtelmez√©s√©rt, amely a ford√≠t√°s haszn√°lat√°b√≥l eredhet.