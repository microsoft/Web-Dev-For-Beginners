<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2c4ae5688e34b4b8b09d52aec56c79e",
  "translation_date": "2025-10-22T23:52:36+00:00",
  "source_file": "10-ai-framework-project/README.md",
  "language_code": "tr"
}
-->
# AI Ã‡erÃ§evesi

HiÃ§ sÄ±fÄ±rdan yapay zeka uygulamalarÄ± oluÅŸtururken bunalmÄ±ÅŸ hissettiniz mi? YalnÄ±z deÄŸilsiniz! Yapay zeka Ã§erÃ§eveleri, yapay zeka geliÅŸtirme iÃ§in bir Ä°sviÃ§re Ã§akÄ±sÄ± gibidir - akÄ±llÄ± uygulamalar oluÅŸtururken zaman ve zahmetten tasarruf etmenizi saÄŸlayan gÃ¼Ã§lÃ¼ araÃ§lardÄ±r. Bir yapay zeka Ã§erÃ§evesini iyi organize edilmiÅŸ bir kÃ¼tÃ¼phane gibi dÃ¼ÅŸÃ¼nÃ¼n: Ã¶nceden oluÅŸturulmuÅŸ bileÅŸenler, standartlaÅŸtÄ±rÄ±lmÄ±ÅŸ API'ler ve akÄ±llÄ± soyutlamalar sunar, bÃ¶ylece uygulama detaylarÄ±yla uÄŸraÅŸmak yerine sorunlarÄ± Ã§Ã¶zmeye odaklanabilirsiniz.

Bu derste, LangChain gibi Ã§erÃ§evelerin eskiden karmaÅŸÄ±k olan yapay zeka entegrasyon gÃ¶revlerini nasÄ±l temiz ve okunabilir kodlara dÃ¶nÃ¼ÅŸtÃ¼rebileceÄŸini keÅŸfedeceÄŸiz. GerÃ§ek dÃ¼nya zorluklarÄ±nÄ±, Ã¶rneÄŸin konuÅŸmalarÄ± takip etme, araÃ§ Ã§aÄŸÄ±rma uygulama ve farklÄ± yapay zeka modellerini tek bir birleÅŸik arayÃ¼z Ã¼zerinden yÃ¶netme gibi konularÄ± ele almayÄ± Ã¶ÄŸreneceksiniz.

Dersin sonunda, Ã§erÃ§eveleri ne zaman ham API Ã§aÄŸrÄ±larÄ± yerine kullanmanÄ±z gerektiÄŸini, soyutlamalarÄ±nÄ± nasÄ±l etkili bir ÅŸekilde kullanacaÄŸÄ±nÄ±zÄ± ve gerÃ§ek dÃ¼nya kullanÄ±mÄ± iÃ§in hazÄ±r yapay zeka uygulamalarÄ± nasÄ±l oluÅŸturacaÄŸÄ±nÄ±zÄ± Ã¶ÄŸreneceksiniz. Hadi, yapay zeka Ã§erÃ§evelerinin projeleriniz iÃ§in neler yapabileceÄŸini keÅŸfedelim.

## Neden bir Ã§erÃ§eve seÃ§melisiniz?

Yapay zeka uygulamasÄ± oluÅŸturmaya hazÄ±rsÄ±nÄ±z - harika! Ama iÅŸte mesele ÅŸu: birkaÃ§ farklÄ± yol seÃ§eneÄŸiniz var ve her birinin kendi avantajlarÄ± ve dezavantajlarÄ± var. Bu, bir yere gitmek iÃ§in yÃ¼rÃ¼mek, bisiklete binmek veya araba kullanmak arasÄ±nda seÃ§im yapmaya benzer - hepsi sizi oraya gÃ¶tÃ¼rÃ¼r, ancak deneyim (ve Ã§aba) tamamen farklÄ± olacaktÄ±r.

Yapay zekayÄ± projelerinize entegre etmenin Ã¼Ã§ ana yolunu inceleyelim:

| YaklaÅŸÄ±m | Avantajlar | En Ä°yi KullanÄ±m AlanÄ± | Dikkat Edilmesi Gerekenler |
|----------|------------|-----------------------|---------------------------|
| **DoÄŸrudan HTTP Ä°stekleri** | Tam kontrol, baÄŸÄ±mlÄ±lÄ±k yok | Basit sorgular, temel bilgileri Ã¶ÄŸrenme | Daha uzun kod, manuel hata yÃ¶netimi |
| **SDK Entegrasyonu** | Daha az kod tekrarÄ±, modele Ã¶zgÃ¼ optimizasyon | Tek model uygulamalarÄ± | Belirli saÄŸlayÄ±cÄ±larla sÄ±nÄ±rlÄ± |
| **Yapay Zeka Ã‡erÃ§eveleri** | BirleÅŸik API, yerleÅŸik soyutlamalar | Ã‡oklu model uygulamalarÄ±, karmaÅŸÄ±k iÅŸ akÄ±ÅŸlarÄ± | Ã–ÄŸrenme eÄŸrisi, aÅŸÄ±rÄ± soyutlama riski |

### Ã‡erÃ§eve FaydalarÄ± Pratikte

```mermaid
graph TD
    A[Your Application] --> B[AI Framework]
    B --> C[OpenAI GPT]
    B --> D[Anthropic Claude]
    B --> E[GitHub Models]
    B --> F[Local Models]
    
    B --> G[Built-in Tools]
    G --> H[Memory Management]
    G --> I[Conversation History]
    G --> J[Function Calling]
    G --> K[Error Handling]
```

**Ã‡erÃ§eveler neden Ã¶nemlidir:**
- **BirleÅŸtirir** birden fazla yapay zeka saÄŸlayÄ±cÄ±sÄ±nÄ± tek bir arayÃ¼z altÄ±nda
- **Otomatik olarak yÃ¶netir** konuÅŸma hafÄ±zasÄ±nÄ±
- **HazÄ±r araÃ§lar saÄŸlar** gÃ¶mme ve fonksiyon Ã§aÄŸÄ±rma gibi yaygÄ±n gÃ¶revler iÃ§in
- **Hata yÃ¶netimi ve yeniden deneme mantÄ±ÄŸÄ±nÄ±** dÃ¼zenler
- **KarmaÅŸÄ±k iÅŸ akÄ±ÅŸlarÄ±nÄ±** okunabilir metot Ã§aÄŸrÄ±larÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r

> ğŸ’¡ **Profesyonel Ä°pucu**: FarklÄ± yapay zeka modelleri arasÄ±nda geÃ§iÅŸ yaparken veya ajanlar, hafÄ±za ya da araÃ§ Ã§aÄŸÄ±rma gibi karmaÅŸÄ±k Ã¶zellikler oluÅŸtururken Ã§erÃ§eveleri kullanÄ±n. Temel bilgileri Ã¶ÄŸrenirken veya basit, odaklanmÄ±ÅŸ uygulamalar oluÅŸtururken doÄŸrudan API'lerle Ã§alÄ±ÅŸmaya devam edin.

**SonuÃ§**: Bir zanaatkarÄ±n Ã¶zel araÃ§larÄ± ile tam bir atÃ¶lye arasÄ±nda seÃ§im yapmak gibi, araÃ§larÄ± gÃ¶reve uygun ÅŸekilde eÅŸleÅŸtirmekle ilgilidir. Ã‡erÃ§eveler karmaÅŸÄ±k, Ã¶zellik aÃ§Ä±sÄ±ndan zengin uygulamalar iÃ§in mÃ¼kemmeldir, doÄŸrudan API'ler ise basit kullanÄ±m durumlarÄ± iÃ§in iyi Ã§alÄ±ÅŸÄ±r.

## GiriÅŸ

Bu derste ÅŸunlarÄ± Ã¶ÄŸreneceÄŸiz:

- YaygÄ±n bir yapay zeka Ã§erÃ§evesi kullanmak.
- Sohbet konuÅŸmalarÄ±, araÃ§ kullanÄ±mÄ±, hafÄ±za ve baÄŸlam gibi yaygÄ±n sorunlarÄ± ele almak.
- BunlarÄ± yapay zeka uygulamalarÄ± oluÅŸturmak iÃ§in kullanmak.

## Ä°lk Yapay Zeka Ä°steÄŸiniz

Bir soruyu gÃ¶nderip bir cevap alarak ilk yapay zeka uygulamanÄ±zÄ± oluÅŸturarak temellerle baÅŸlayalÄ±m. ArÅŸimet'in banyosunda yer deÄŸiÅŸtirme prensibini keÅŸfetmesi gibi, bazen en basit gÃ¶zlemler en gÃ¼Ã§lÃ¼ iÃ§gÃ¶rÃ¼lere yol aÃ§ar - ve Ã§erÃ§eveler bu iÃ§gÃ¶rÃ¼leri eriÅŸilebilir kÄ±lar.

### LangChain'i GitHub Modelleriyle Kurmak

GitHub Modellerine baÄŸlanmak iÃ§in LangChain'i kullanacaÄŸÄ±z, bu oldukÃ§a harika Ã§Ã¼nkÃ¼ Ã§eÅŸitli yapay zeka modellerine Ã¼cretsiz eriÅŸim saÄŸlÄ±yor. En iyi kÄ±smÄ±? BaÅŸlamak iÃ§in yalnÄ±zca birkaÃ§ basit yapÄ±landÄ±rma parametresine ihtiyacÄ±nÄ±z var:

```python
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

# Send a simple prompt
response = llm.invoke("What's the capital of France?")
print(response.content)
```

**Burada neler oluyor:**
- **Bir LangChain istemcisi oluÅŸturur** `ChatOpenAI` sÄ±nÄ±fÄ±nÄ± kullanarak - bu sizin yapay zekaya aÃ§Ä±lan kapÄ±nÄ±z!
- **GitHub Modellerine baÄŸlantÄ±yÄ± yapÄ±landÄ±rÄ±r** kimlik doÄŸrulama tokeninizle
- **Hangi yapay zeka modelinin kullanÄ±lacaÄŸÄ±nÄ± belirtir** (`gpt-4o-mini`) - bunu yapay zeka asistanÄ±nÄ±zÄ± seÃ§mek gibi dÃ¼ÅŸÃ¼nÃ¼n
- **Sorunuzu gÃ¶nderir** `invoke()` metodu ile - iÅŸte sihir burada gerÃ§ekleÅŸiyor
- **YanÄ±tÄ± Ã§Ä±karÄ±r ve gÃ¶rÃ¼ntÃ¼ler** - ve iÅŸte, yapay zeka ile sohbet ediyorsunuz!

> ğŸ”§ **Kurulum Notu**: GitHub Codespaces kullanÄ±yorsanÄ±z ÅŸanslÄ±sÄ±nÄ±z - `GITHUB_TOKEN` zaten ayarlanmÄ±ÅŸ! Yerel olarak mÄ± Ã§alÄ±ÅŸÄ±yorsunuz? EndiÅŸelenmeyin, sadece doÄŸru izinlere sahip bir kiÅŸisel eriÅŸim tokeni oluÅŸturmanÄ±z gerekecek.

**Beklenen Ã§Ä±ktÄ±:**
```text
The capital of France is Paris.
```

```mermaid
sequenceDiagram
    participant App as Your Python App
    participant LC as LangChain
    participant GM as GitHub Models
    participant AI as GPT-4o-mini
    
    App->>LC: llm.invoke("What's the capital of France?")
    LC->>GM: HTTP request with prompt
    GM->>AI: Process prompt
    AI->>GM: Generated response
    GM->>LC: Return response
    LC->>App: response.content
```

## KonuÅŸma TabanlÄ± Yapay Zeka OluÅŸturma

Ä°lk Ã¶rnek temel bilgileri gÃ¶steriyor, ancak bu sadece tek bir alÄ±ÅŸveriÅŸ - bir soru soruyorsunuz, bir cevap alÄ±yorsunuz ve iÅŸte bu kadar. GerÃ§ek uygulamalarda, yapay zekanÄ±zÄ±n ne hakkÄ±nda konuÅŸtuÄŸunuzu hatÄ±rlamasÄ±nÄ± istersiniz, tÄ±pkÄ± Watson ve Holmes'un zamanla araÅŸtÄ±rma konuÅŸmalarÄ±nÄ± inÅŸa ettiÄŸi gibi.

LangChain burada Ã¶zellikle kullanÄ±ÅŸlÄ± hale geliyor. KonuÅŸmalarÄ± yapÄ±landÄ±rmaya yardÄ±mcÄ± olan ve yapay zekanÄ±za bir kiÅŸilik vermenizi saÄŸlayan farklÄ± mesaj tÃ¼rleri sunar. BaÄŸlam ve karakteri koruyan sohbet deneyimleri oluÅŸturacaksÄ±nÄ±z.

### Mesaj TÃ¼rlerini Anlamak

Bu mesaj tÃ¼rlerini bir konuÅŸmada katÄ±lÄ±mcÄ±larÄ±n taktÄ±ÄŸÄ± farklÄ± "ÅŸapkalar" olarak dÃ¼ÅŸÃ¼nÃ¼n. LangChain, kimin ne sÃ¶ylediÄŸini takip etmek iÃ§in farklÄ± mesaj sÄ±nÄ±flarÄ± kullanÄ±r:

| Mesaj TÃ¼rÃ¼ | AmaÃ§ | Ã–rnek KullanÄ±m Durumu |
|------------|------|-----------------------|
| `SystemMessage` | Yapay zekanÄ±n kiÅŸiliÄŸini ve davranÄ±ÅŸÄ±nÄ± tanÄ±mlar | "Sen yardÄ±mcÄ± bir kodlama asistanÄ±sÄ±n" |
| `HumanMessage` | KullanÄ±cÄ± girdisini temsil eder | "FonksiyonlarÄ±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± aÃ§Ä±kla" |
| `AIMessage` | Yapay zeka yanÄ±tlarÄ±nÄ± saklar | KonuÅŸmadaki Ã¶nceki yapay zeka yanÄ±tlarÄ± |

### Ä°lk KonuÅŸmanÄ±zÄ± OluÅŸturmak

Yapay zekamÄ±zÄ±n belirli bir rol Ã¼stlendiÄŸi bir konuÅŸma oluÅŸturalÄ±m. Onu diplomatik bilgelik ve liderlik ile tanÄ±nan bir karakter olan Kaptan Picard olarak canlandÄ±racaÄŸÄ±z:

```python
messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]
```

**Bu konuÅŸma kurulumunu aÃ§Ä±klamak:**
- **Yapay zekanÄ±n rolÃ¼nÃ¼ ve kiÅŸiliÄŸini** `SystemMessage` ile belirler
- **Ä°lk kullanÄ±cÄ± sorgusunu** `HumanMessage` ile saÄŸlar
- **Ã‡oklu dÃ¶nÃ¼ÅŸlÃ¼ konuÅŸma iÃ§in bir temel oluÅŸturur**

Bu Ã¶rneÄŸin tam kodu ÅŸÃ¶yle gÃ¶rÃ¼nÃ¼yor:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]


# works
response  = llm.invoke(messages)
print(response.content)
```

Åuna benzer bir sonuÃ§ gÃ¶rmelisiniz:

```text
I am Captain Jean-Luc Picard, the commanding officer of the USS Enterprise (NCC-1701-D), a starship in the United Federation of Planets. My primary mission is to explore new worlds, seek out new life and new civilizations, and boldly go where no one has gone before. 

I believe in the importance of diplomacy, reason, and the pursuit of knowledge. My crew is diverse and skilled, and we often face challenges that test our resolve, ethics, and ingenuity. Throughout my career, I have encountered numerous species, grappled with complex moral dilemmas, and have consistently sought peaceful solutions to conflicts.

I hold the ideals of the Federation close to my heart, believing in the importance of cooperation, understanding, and respect for all sentient beings. My experiences have shaped my leadership style, and I strive to be a thoughtful and just captain. How may I assist you further?
```

KonuÅŸma sÃ¼rekliliÄŸini korumak iÃ§in (her seferinde baÄŸlamÄ± sÄ±fÄ±rlamak yerine), yanÄ±tlarÄ± mesaj listenize eklemeye devam etmeniz gerekir. TÄ±pkÄ± hikayeleri nesiller boyunca koruyan sÃ¶zlÃ¼ gelenekler gibi, bu yaklaÅŸÄ±m kalÄ±cÄ± bir hafÄ±za oluÅŸturur:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]


# works
response  = llm.invoke(messages)

print(response.content)

print("---- Next ----")

messages.append(response)
messages.append(HumanMessage(content="Now that I know about you, I'm Chris, can I be in your crew?"))

response  = llm.invoke(messages)

print(response.content)

```

OldukÃ§a havalÄ±, deÄŸil mi? Burada olan ÅŸey, LLM'yi iki kez Ã§aÄŸÄ±rmamÄ±z - Ã¶nce sadece ilk iki mesajÄ±mÄ±zla, sonra tÃ¼m konuÅŸma geÃ§miÅŸiyle. Bu, yapay zekanÄ±n sohbetimizi gerÃ§ekten takip ediyormuÅŸ gibi davranmasÄ±nÄ± saÄŸlÄ±yor!

Bu kodu Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nÄ±zda, ÅŸÃ¶yle bir ikinci yanÄ±t alÄ±rsÄ±nÄ±z:

```text
Welcome aboard, Chris! It's always a pleasure to meet those who share a passion for exploration and discovery. While I cannot formally offer you a position on the Enterprise right now, I encourage you to pursue your aspirations. We are always in need of talented individuals with diverse skills and backgrounds. 

If you are interested in space exploration, consider education and training in the sciences, engineering, or diplomacy. The values of curiosity, resilience, and teamwork are crucial in Starfleet. Should you ever find yourself on a starship, remember to uphold the principles of the Federation: peace, understanding, and respect for all beings. Your journey can lead you to remarkable adventures, whether in the stars or on the ground. Engage!
```

Bunu bir "belki" olarak alÄ±yorum ;)

## AkÄ±ÅŸ YanÄ±tlarÄ±

HiÃ§ ChatGPT'nin yanÄ±tlarÄ±nÄ± gerÃ§ek zamanlÄ± olarak "yazÄ±yormuÅŸ" gibi gÃ¶rÃ¼ndÃ¼ÄŸÃ¼nÃ¼ fark ettiniz mi? Ä°ÅŸte bu, akÄ±ÅŸÄ±n iÅŸ baÅŸÄ±nda olduÄŸu an. TÄ±pkÄ± yetenekli bir hattatÄ±n Ã§alÄ±ÅŸmasÄ±nÄ± izlemek gibi - karakterlerin bir anda ortaya Ã§Ä±kmasÄ± yerine vuruÅŸ vuruÅŸ belirmesi - akÄ±ÅŸ, etkileÅŸimi daha doÄŸal hissettirir ve anÄ±nda geri bildirim saÄŸlar.

### LangChain ile AkÄ±ÅŸÄ± Uygulamak

```python
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
    streaming=True
)

# Stream the response
for chunk in llm.stream("Write a short story about a robot learning to code"):
    print(chunk.content, end="", flush=True)
```

**AkÄ±ÅŸ neden harika:**
- **Ä°Ã§eriÄŸi** oluÅŸturulurken gÃ¶sterir - artÄ±k garip beklemeler yok!
- **KullanÄ±cÄ±larÄ±n** bir ÅŸeylerin gerÃ§ekten olduÄŸunu hissetmesini saÄŸlar
- **Daha hÄ±zlÄ± hissedilir**, teknik olarak Ã¶yle olmasa bile
- **KullanÄ±cÄ±larÄ±n** yapay zeka "dÃ¼ÅŸÃ¼nÃ¼rken" okumaya baÅŸlamasÄ±na olanak tanÄ±r

> ğŸ’¡ **KullanÄ±cÄ± Deneyimi Ä°pucu**: AkÄ±ÅŸ, kod aÃ§Ä±klamalarÄ±, yaratÄ±cÄ± yazÄ±lar veya ayrÄ±ntÄ±lÄ± eÄŸitimler gibi daha uzun yanÄ±tlarla uÄŸraÅŸÄ±rken gerÃ§ekten parlÄ±yor. KullanÄ±cÄ±larÄ±nÄ±z boÅŸ bir ekrana bakmak yerine ilerlemeyi gÃ¶rmeyi sevecek!

## Ä°stek ÅablonlarÄ±

Ä°stek ÅŸablonlarÄ±, klasik hitabet sanatÄ±nda kullanÄ±lan retorik yapÄ±lar gibi Ã§alÄ±ÅŸÄ±r - Cicero'nun farklÄ± dinleyicilere hitap ederken aynÄ± ikna edici Ã§erÃ§eveyi koruyarak konuÅŸma kalÄ±plarÄ±nÄ± nasÄ±l uyarladÄ±ÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼n. Yeniden yazmak zorunda kalmadan farklÄ± bilgileri deÄŸiÅŸtirerek yeniden kullanÄ±labilir istekler oluÅŸturmanÄ±za olanak tanÄ±r. Åablonu bir kez ayarladÄ±ktan sonra, sadece deÄŸiÅŸkenleri ihtiyacÄ±nÄ±z olan deÄŸerlerle doldurursunuz.

### Yeniden KullanÄ±labilir Ä°stekler OluÅŸturmak

```python
from langchain_core.prompts import ChatPromptTemplate

# Define a template for code explanations
template = ChatPromptTemplate.from_messages([
    ("system", "You are an expert programming instructor. Explain concepts clearly with examples."),
    ("human", "Explain {concept} in {language} with a practical example for {skill_level} developers")
])

# Use the template with different values
questions = [
    {"concept": "functions", "language": "JavaScript", "skill_level": "beginner"},
    {"concept": "classes", "language": "Python", "skill_level": "intermediate"},
    {"concept": "async/await", "language": "JavaScript", "skill_level": "advanced"}
]

for question in questions:
    prompt = template.format_messages(**question)
    response = llm.invoke(prompt)
    print(f"Topic: {question['concept']}\n{response.content}\n---\n")
```

**ÅablonlarÄ± kullanmayÄ± neden seveceksiniz:**
- **Ä°steklerinizi** uygulamanÄ±zÄ±n tamamÄ±nda tutarlÄ± tutar
- **DaÄŸÄ±nÄ±k dize birleÅŸtirme yok** - sadece temiz, basit deÄŸiÅŸkenler
- **Yapay zekanÄ±z** Ã¶ngÃ¶rÃ¼lebilir ÅŸekilde davranÄ±r Ã§Ã¼nkÃ¼ yapÄ± aynÄ± kalÄ±r
- **GÃ¼ncellemeler** Ã§ok kolay - ÅŸablonu bir kez deÄŸiÅŸtirin ve her yerde dÃ¼zelir

## YapÄ±landÄ±rÄ±lmÄ±ÅŸ Ã‡Ä±ktÄ±

Yapay zekadan gelen yanÄ±tlarÄ± yapÄ±landÄ±rÄ±lmamÄ±ÅŸ metin olarak almaya Ã§alÄ±ÅŸÄ±rken hiÃ§ hayal kÄ±rÄ±klÄ±ÄŸÄ±na uÄŸradÄ±nÄ±z mÄ±? YapÄ±landÄ±rÄ±lmÄ±ÅŸ Ã§Ä±ktÄ±, yapay zekanÄ±za biyolojik sÄ±nÄ±flandÄ±rma iÃ§in Linnaeus'un kullandÄ±ÄŸÄ± sistematik yaklaÅŸÄ±mÄ± Ã¶ÄŸretmek gibidir - dÃ¼zenli, Ã¶ngÃ¶rÃ¼lebilir ve Ã§alÄ±ÅŸmasÄ± kolay. JSON, belirli veri yapÄ±larÄ± veya ihtiyacÄ±nÄ±z olan herhangi bir formatÄ± talep edebilirsiniz.

### Ã‡Ä±ktÄ± ÅemalarÄ±nÄ± TanÄ±mlamak

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel, Field

class CodeReview(BaseModel):
    score: int = Field(description="Code quality score from 1-10")
    strengths: list[str] = Field(description="List of code strengths")
    improvements: list[str] = Field(description="List of suggested improvements")
    overall_feedback: str = Field(description="Summary feedback")

# Set up the parser
parser = JsonOutputParser(pydantic_object=CodeReview)

# Create prompt with format instructions
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a code reviewer. {format_instructions}"),
    ("human", "Review this code: {code}")
])

# Format the prompt with instructions
chain = prompt | llm | parser

# Get structured response
code_sample = """
def calculate_average(numbers):
    return sum(numbers) / len(numbers)
"""

result = chain.invoke({
    "code": code_sample,
    "format_instructions": parser.get_format_instructions()
})

print(f"Score: {result['score']}")
print(f"Strengths: {', '.join(result['strengths'])}")
```

**YapÄ±landÄ±rÄ±lmÄ±ÅŸ Ã§Ä±ktÄ± neden oyunun kurallarÄ±nÄ± deÄŸiÅŸtirir:**
- **ArtÄ±k** hangi formatÄ± alacaÄŸÄ±nÄ±zÄ± tahmin etmeye gerek yok - her zaman tutarlÄ±
- **VeritabanlarÄ±nÄ±za ve API'lerinize** ekstra iÅŸ olmadan doÄŸrudan baÄŸlanÄ±r
- **Garip yapay zeka yanÄ±tlarÄ±nÄ±** uygulamanÄ±zÄ± bozmadan Ã¶nce yakalar
- **Kodunuzu** daha temiz hale getirir Ã§Ã¼nkÃ¼ tam olarak neyle Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±zÄ± bilirsiniz

## AraÃ§ Ã‡aÄŸÄ±rma

Åimdi en gÃ¼Ã§lÃ¼ Ã¶zelliklerden birine ulaÅŸÄ±yoruz: araÃ§lar. Bu, yapay zekanÄ±za konuÅŸmanÄ±n Ã¶tesinde pratik yetenekler kazandÄ±rmanÄ±n yoludur. TÄ±pkÄ± ortaÃ§aÄŸ loncalarÄ±nÄ±n belirli zanaatlar iÃ§in Ã¶zel araÃ§lar geliÅŸtirdiÄŸi gibi, yapay zekanÄ±zÄ± odaklanmÄ±ÅŸ enstrÃ¼manlarla donatabilirsiniz. Hangi araÃ§larÄ±n mevcut olduÄŸunu tanÄ±mlarsÄ±nÄ±z ve biri eÅŸleÅŸen bir ÅŸey talep ettiÄŸinde, yapay zekanÄ±z harekete geÃ§ebilir.

### Python KullanÄ±mÄ±

ÅÃ¶yle araÃ§lar ekleyelim:

```python
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

tools = [add]

functions = {
    "add": lambda a, b: a + b
}
```

Burada ne oluyor? `add` adlÄ± bir araÃ§ iÃ§in bir taslak oluÅŸturuyoruz. `TypedDict`'ten tÃ¼reyerek ve `a` ve `b` iÃ§in bu ÅŸÄ±k `Annotated` tÃ¼rlerini kullanarak, LLM'ye bu aracÄ±n ne yaptÄ±ÄŸÄ± ve neye ihtiyaÃ§ duyduÄŸu hakkÄ±nda net bir resim veriyoruz. `functions` sÃ¶zlÃ¼ÄŸÃ¼ bizim araÃ§ kutumuz gibi - yapay zeka belirli bir aracÄ± kullanmaya karar verdiÄŸinde kodumuzun tam olarak ne yapmasÄ± gerektiÄŸini sÃ¶ylÃ¼yor.

Sonraki adÄ±mda bu aracÄ± nasÄ±l Ã§aÄŸÄ±racaÄŸÄ±mÄ±zÄ± gÃ¶relim:

```python
llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)
```

Burada `bind_tools`'u `tools` dizimizle Ã§aÄŸÄ±rÄ±yoruz ve bÃ¶ylece LLM `llm_with_tools` artÄ±k bu aracÄ± biliyor.

Bu yeni LLM'yi kullanmak iÃ§in ÅŸu kodu yazabiliriz:

```python
query = "What is 3 + 12?"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

ArtÄ±k araÃ§lara sahip olan bu yeni LLM'de `invoke` Ã§aÄŸrÄ±sÄ± yaptÄ±ÄŸÄ±mÄ±zda, `tool_calls` Ã¶zelliÄŸi dolu olabilir. EÄŸer Ã¶yleyse, tanÄ±mlanan herhangi bir araÃ§, hangi aracÄ±n Ã§aÄŸrÄ±lmasÄ± gerektiÄŸini ve hangi argÃ¼manlarla Ã§aÄŸrÄ±lmasÄ± gerektiÄŸini belirten bir `name` ve `args` Ã¶zelliÄŸine sahiptir. Tam kod ÅŸÃ¶yle gÃ¶rÃ¼nÃ¼yor:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

tools = [add]

functions = {
    "add": lambda a, b: a + b
}

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)

query = "What is 3 + 12?"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

Bu kodu Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nÄ±zda, ÅŸuna benzer bir Ã§Ä±ktÄ± gÃ¶rmelisiniz:

```text
TOOL CALL:  15
CONTENT: 
```

Yapay zeka "3 + 12 nedir" sorusunu inceledi ve bunu `add` aracÄ± iÃ§in bir gÃ¶rev olarak tanÄ±mladÄ±. TÄ±pkÄ± yetenekli bir kÃ¼tÃ¼phanecinin sorulan sorunun tÃ¼rÃ¼ne gÃ¶re hangi kaynaÄŸa baÅŸvuracaÄŸÄ±nÄ± bilmesi gibi, bu kararÄ± aracÄ±n adÄ±, aÃ§Ä±klamasÄ± ve alan Ã¶zelliklerinden yaptÄ±. 15 sonucu, aracÄ±n `functions` sÃ¶zlÃ¼ÄŸÃ¼mÃ¼z tarafÄ±ndan yÃ¼rÃ¼tÃ¼lmesinden geliyor:

```python
print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
```

### Bir web API'sini Ã§aÄŸÄ±ran daha ilginÃ§ bir araÃ§

SayÄ±larÄ± toplamak konsepti gÃ¶steriyor, ancak gerÃ§ek araÃ§lar genellikle web API'lerini Ã§aÄŸÄ±rmak gibi daha karmaÅŸÄ±k iÅŸlemler gerÃ§ekleÅŸtirir. Ã–rneÄŸimizi geniÅŸletelim ve yapay zekanÄ±n internetten iÃ§erik almasÄ±nÄ± saÄŸlayalÄ±m - tÄ±pkÄ± telgraf operatÃ¶rlerinin bir zamanlar uzak yerleri birbirine baÄŸlamasÄ± gibi:

```python
class joke(TypedDict):
    """Tell a joke."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    category: Annotated[str, ..., "The joke category"]

def get_joke(category: str) -> str:
    response = requests.get(f"https://api.chucknorris.io/jokes/random?category={category}", headers={"Accept": "application/json"})
    if response.status_code == 200:
        return response.json().get("value", f"Here's a {category} joke!")
    return f"Here's a {category} joke!"

functions = {
    "add": lambda a, b: a + b,
    "joke": lambda category: get_joke(category)
}

query = "Tell me a joke about animals"

# the rest of the code is the same
```

Åimdi bu kodu Ã§alÄ±ÅŸtÄ±rÄ±rsanÄ±z, ÅŸÃ¶yle bir yanÄ±t alÄ±rsÄ±nÄ±z:

```text
TOOL CALL:  Chuck Norris once rode a nine foot grizzly bear through an automatic car wash, instead of taking a shower.
CONTENT:  
```

Ä°ÅŸte kodun tamamÄ±:

```python
from langchain_openai import ChatOpenAI
import requests
import os
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

class joke(TypedDict):
    """Tell a joke."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    category: Annotated[str, ..., "The joke category"]

tools = [add, joke]

def get_joke(category: str) -> str:
    response = requests.get(f"https://api.chucknorris.io/jokes/random?category={category}", headers={"Accept": "application/json"})
    if response.status_code == 200:
        return response.json().get("value", f"Here's a {category} joke!")
    return f"Here's a {category} joke!"

functions = {
    "add": lambda a, b: a + b,
    "joke": lambda category: get_joke(category)
}

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)

query = "Tell me a joke about animals"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        # print("TOOL CALL: ", tool)
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

## GÃ¶mme ve Belge Ä°ÅŸleme

GÃ¶mme, modern yapay zekanÄ±n en zarif Ã§Ã¶zÃ¼mlerinden birini temsil eder. Herhangi bir metni alÄ±p anlamÄ±nÄ± yakalayan sayÄ±sal koordinatlara dÃ¶nÃ¼ÅŸtÃ¼rebileceÄŸinizi hayal edin. GÃ¶mme tam olarak bunu yapar - metni Ã§ok boyutlu bir uzayda benzer kavramlarÄ±n bir arada toplandÄ±ÄŸÄ± noktalara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. Bu, fikirler iÃ§in bir koordinat sistemi oluÅŸturmak gibidir, tÄ±pkÄ± Mendeleev'in periyodik tabloyu atomik Ã¶zelliklere gÃ¶re dÃ¼zenlemesi gibi.

### GÃ¶mme OluÅŸturma ve Kullanma

```python
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter

# Initialize embeddings
embeddings = OpenAIEmbeddings(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="text-embedding-3-small"
)

# Load and split documents
loader = TextLoader("documentation.txt")
documents = loader.load()

text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(documents)

# Create vector store
vectorstore = FAISS.from_documents(texts, embeddings)

# Perform similarity search
query = "How do I handle user authentication?"
similar_docs = vectorstore.similarity_search(query, k=3)

for doc in similar_docs:
    print(f"Relevant content: {doc.page_content[:200]}...")
```

### Ã‡eÅŸitli Formatlar iÃ§in Belge YÃ¼kleyiciler

```python
from langchain_community.document_loaders import (
    PyPDFLoader,
    CSVLoader,
    JSONLoader,
    WebBaseLoader
)

# Load different document types
pdf_loader = PyPDFLoader("manual.pdf")
csv_loader = CSVLoader("data.csv")
json_loader = JSONLoader("config.json")
web_loader = WebBaseLoader("https://example.com/docs")

# Process all documents
all_documents = []
for loader in [pdf_loader, csv_loader, json_loader, web_loader]:
    docs = loader.load()
    all_documents.extend(docs)
```

**GÃ¶mme ile neler yapabilirsiniz:**
- **Arama oluÅŸturun** ki gerÃ§ekten ne demek istediÄŸinizi anlasÄ±n, sadece anahtar kelimeleri eÅŸleÅŸtirmekle kalmasÄ±n
- **Yapay zeka oluÅŸturun** ki belgeleriniz hakkÄ±nda sorularÄ± yanÄ±tlayabilsin
- **Ã–neri sistemleri oluÅŸturun** ki gerÃ§ekten ilgili iÃ§erikleri Ã¶nerebilsin
- **Ä°Ã§eriÄŸinizi otomatik olarak** organize edin ve kategorilere ayÄ±rÄ±n

## Tam Bir Yapay Zeka UygulamasÄ± OluÅŸturmak

Åimdi Ã¶ÄŸrendiklerinizi kapsamlÄ± bir uygulamaya entegre edeceÄŸiz - sorularÄ± yanÄ±tlayabilen, araÃ§larÄ± kullanabilen ve konuÅŸma hafÄ±zasÄ±nÄ± koruyabilen bir kodlama asistanÄ±. TÄ±pkÄ± matbaanÄ±n mevcut teknolojileri (hareketli harfler, mÃ¼rekkep, kaÄŸÄ±t ve baskÄ±) bir araya getirerek dÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼ bir ÅŸey yaratmasÄ± gibi, yapay zeka bileÅŸenlerimizi pratik ve kullanÄ±ÅŸlÄ± bir ÅŸeye dÃ¶nÃ¼ÅŸtÃ¼receÄŸiz.

### Tam Uygulama Ã–rneÄŸi

```python
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_community.vectorstores import FAISS
from typing_extensions import Annotated, TypedDict
import os
import requests

class CodingAssistant:
    def __init__(self):
        self.llm = ChatOpenAI(
            api_key=os.environ["GITHUB_TOKEN"],
            base_url="https://models.github.ai/inference",
            model="openai/gpt-4o-mini"
        )
        
        self.conversation_history = [
            SystemMessage(content="""You are an expert coding assistant. 
            Help users learn programming concepts, debug code, and write better software.
            Use tools when needed and maintain a helpful, encouraging tone.""")
        ]
        
        # Define tools
        self.setup_tools()
    
    def setup_tools(self):
        class web_search(TypedDict):
            """Search for programming documentation or examples."""
            query: Annotated[str, "Search query for programming help"]
        
        class code_formatter(TypedDict):
            """Format and validate code snippets."""
            code: Annotated[str, "Code to format"]
            language: Annotated[str, "Programming language"]
        
        self.tools = [web_search, code_formatter]
        self.llm_with_tools = self.llm.bind_tools(self.tools)
    
    def chat(self, user_input: str):
        # Add user message to conversation
        self.conversation_history.append(HumanMessage(content=user_input))
        
        # Get AI response
        response = self.llm_with_tools.invoke(self.conversation_history)
        
        # Handle tool calls if any
        if response.tool_calls:
            for tool_call in response.tool_calls:
                tool_result = self.execute_tool(tool_call)
                print(f"ğŸ”§ Tool used: {tool_call['name']}")
                print(f"ğŸ“Š Result: {tool_result}")
        
        # Add AI response to conversation
        self.conversation_history.append(response)
        
        return response.content
    
    def execute_tool(self, tool_call):
        tool_name = tool_call['name']
        args = tool_call['args']
        
        if tool_name == 'web_search':
            return f"Found documentation for: {args['query']}"
        elif tool_name == 'code_formatter':
            return f"Formatted {args['language']} code: {args['code'][:50]}..."
        
        return "Tool execution completed"

# Usage example
assistant = CodingAssistant()

print("ğŸ¤– Coding Assistant Ready! Type 'quit' to exit.\n")

while True:
    user_input = input("You: ")
    if user_input.lower() == 'quit':
        break
    
    response = assistant.chat(user_input)
    print(f"ğŸ¤– Assistant: {response}\n")
```

**Uygulama mimarisi:**

```mermaid
graph TD
    A[User Input] --> B[Coding Assistant]
    B --> C[Conversation Memory]
    B --> D[Tool Detection]
    B --> E[LLM Processing]
    
    D --> F[Web Search Tool]
    D --> G[Code Formatter Tool]
    
    E --> H[Response Generation]
    F --> H
    G --> H
    
    H --> I[User Interface]
    H --> C
```

**UyguladÄ±ÄŸÄ±mÄ±z temel Ã¶zellikler:**
- **TÃ¼m konuÅŸmanÄ±zÄ± hatÄ±rlar** baÄŸlam sÃ¼rekliliÄŸi iÃ§in
- **AraÃ§ Ã§aÄŸÄ±rma yoluyla iÅŸlem yapar**, sadece konuÅŸma deÄŸil
- **Ã–ngÃ¶rÃ¼lebilir etkileÅŸim kalÄ±plarÄ±nÄ± takip eder**
- **Hata yÃ¶netimini ve karmaÅŸÄ±k iÅŸ akÄ±ÅŸlarÄ±nÄ± otomatik olarak dÃ¼zenler**

## Ã–dev: Kendi Yapay Zeka Destekli Ã‡alÄ±ÅŸma AsistanÄ±nÄ±zÄ± OluÅŸturun

**
3. **KiÅŸiselleÅŸtirilmiÅŸ Ã–ÄŸrenme**: Sistem mesajlarÄ±nÄ± kullanarak yanÄ±tlarÄ± farklÄ± beceri seviyelerine uyarlayÄ±n  
4. **YanÄ±t Formatlama**: Quiz sorularÄ± iÃ§in yapÄ±landÄ±rÄ±lmÄ±ÅŸ Ã§Ä±ktÄ± uygulayÄ±n  

### Uygulama AdÄ±mlarÄ±  

**AdÄ±m 1: OrtamÄ±nÄ±zÄ± kurun**  
```bash
pip install langchain langchain-openai
```
  
**AdÄ±m 2: Temel sohbet iÅŸlevselliÄŸi**  
- `StudyAssistant` sÄ±nÄ±fÄ±nÄ± oluÅŸturun  
- KonuÅŸma hafÄ±zasÄ±nÄ± uygulayÄ±n  
- EÄŸitim desteÄŸi iÃ§in kiÅŸilik yapÄ±landÄ±rmasÄ± ekleyin  

**AdÄ±m 3: EÄŸitim araÃ§larÄ± ekleyin**  
- **Kod AÃ§Ä±klayÄ±cÄ±**: KodlarÄ± anlaÅŸÄ±lÄ±r parÃ§alara ayÄ±rÄ±r  
- **Quiz OluÅŸturucu**: Programlama kavramlarÄ± hakkÄ±nda sorular oluÅŸturur  
- **Ä°lerleme TakipÃ§isi**: Ele alÄ±nan konularÄ± takip eder  

**AdÄ±m 4: GeliÅŸmiÅŸ Ã¶zellikler (Opsiyonel)**  
- Daha iyi kullanÄ±cÄ± deneyimi iÃ§in akÄ±ÅŸ yanÄ±tlarÄ±nÄ± uygulayÄ±n  
- Ders materyallerini dahil etmek iÃ§in belge yÃ¼kleme ekleyin  
- Benzerlik tabanlÄ± iÃ§erik alÄ±mÄ± iÃ§in gÃ¶mme oluÅŸturun  

### DeÄŸerlendirme Kriterleri  

| Ã–zellik | MÃ¼kemmel (4) | Ä°yi (3) | Tatmin Edici (2) | GeliÅŸtirme Gerekli (1) |  
|---------|---------------|----------|------------------|----------------|  
| **KonuÅŸma AkÄ±ÅŸÄ±** | DoÄŸal, baÄŸlama duyarlÄ± yanÄ±tlar | Ä°yi baÄŸlam koruma | Temel sohbet | DeÄŸiÅŸimler arasÄ±nda hafÄ±za yok |  
| **AraÃ§ Entegrasyonu** | Birden fazla faydalÄ± araÃ§ sorunsuz Ã§alÄ±ÅŸÄ±yor | 2+ araÃ§ doÄŸru ÅŸekilde uygulanmÄ±ÅŸ | 1-2 temel araÃ§ | AraÃ§lar iÅŸlevsel deÄŸil |  
| **Kod Kalitesi** | Temiz, iyi belgelenmiÅŸ, hata yÃ¶netimi | Ä°yi yapÄ±, biraz belgeleme | Temel iÅŸlevsellik Ã§alÄ±ÅŸÄ±yor | KÃ¶tÃ¼ yapÄ±, hata yÃ¶netimi yok |  
| **EÄŸitim DeÄŸeri** | Ã–ÄŸrenme iÃ§in gerÃ§ekten faydalÄ±, uyarlanabilir | Ä°yi Ã¶ÄŸrenme desteÄŸi | Temel aÃ§Ä±klamalar | SÄ±nÄ±rlÄ± eÄŸitim faydasÄ± |  

### Ã–rnek kod yapÄ±sÄ±  

```python
class StudyAssistant:
    def __init__(self, skill_level="beginner"):
        # Initialize LLM, tools, and conversation memory
        pass
    
    def explain_code(self, code, language):
        # Tool: Explain how code works
        pass
    
    def generate_quiz(self, topic, difficulty):
        # Tool: Create practice questions
        pass
    
    def chat(self, user_input):
        # Main conversation interface
        pass

# Example usage
assistant = StudyAssistant(skill_level="intermediate")
response = assistant.chat("Explain how Python functions work")
```
  
**Bonus Zorluklar:**  
- Ses giriÅŸ/Ã§Ä±kÄ±ÅŸ yetenekleri ekleyin  
- Streamlit veya Flask kullanarak bir web arayÃ¼zÃ¼ uygulayÄ±n  
- GÃ¶mme kullanarak ders materyallerinden bir bilgi tabanÄ± oluÅŸturun  
- Ä°lerleme takibi ve kiÅŸiselleÅŸtirilmiÅŸ Ã¶ÄŸrenme yollarÄ± ekleyin  

## Ã–zet  

ğŸ‰ ArtÄ±k AI Ã§erÃ§eve geliÅŸtirme temellerini Ã¶ÄŸrendiniz ve LangChain kullanarak sofistike AI uygulamalarÄ± oluÅŸturmayÄ± baÅŸardÄ±nÄ±z. KapsamlÄ± bir Ã§Ä±raklÄ±k tamamlamÄ±ÅŸ gibi, Ã¶nemli bir beceri seti kazandÄ±nÄ±z. Åimdi neler baÅŸardÄ±ÄŸÄ±nÄ±zÄ± gÃ¶zden geÃ§irelim.  

### Neler Ã¶ÄŸrendiniz  

**Temel Ã‡erÃ§eve KavramlarÄ±:**  
- **Ã‡erÃ§eve FaydalarÄ±**: Ã‡erÃ§eveleri doÄŸrudan API Ã§aÄŸrÄ±larÄ±na tercih etme zamanÄ±nÄ± anlamak  
- **LangChain Temelleri**: AI model baÄŸlantÄ±larÄ±nÄ± kurma ve yapÄ±landÄ±rma  
- **Mesaj TÃ¼rleri**: YapÄ±landÄ±rÄ±lmÄ±ÅŸ konuÅŸmalar iÃ§in `SystemMessage`, `HumanMessage` ve `AIMessage` kullanÄ±mÄ±  

**GeliÅŸmiÅŸ Ã–zellikler:**  
- **AraÃ§ Ã‡aÄŸÄ±rma**: GeliÅŸmiÅŸ AI yetenekleri iÃ§in Ã¶zel araÃ§lar oluÅŸturma ve entegre etme  
- **KonuÅŸma HafÄ±zasÄ±**: Birden fazla konuÅŸma turunda baÄŸlamÄ± koruma  
- **AkÄ±ÅŸ YanÄ±tlarÄ±**: GerÃ§ek zamanlÄ± yanÄ±t teslimatÄ± uygulama  
- **Prompt ÅablonlarÄ±**: Yeniden kullanÄ±labilir, dinamik promptlar oluÅŸturma  
- **YapÄ±landÄ±rÄ±lmÄ±ÅŸ Ã‡Ä±ktÄ±**: TutarlÄ±, ayrÄ±ÅŸtÄ±rÄ±labilir AI yanÄ±tlarÄ± saÄŸlama  
- **GÃ¶mme**: Anlamsal arama ve belge iÅŸleme yetenekleri oluÅŸturma  

**Pratik Uygulamalar:**  
- **Tam Uygulamalar OluÅŸturma**: Birden fazla Ã¶zelliÄŸi Ã¼retime hazÄ±r uygulamalara birleÅŸtirme  
- **Hata YÃ¶netimi**: SaÄŸlam hata yÃ¶netimi ve doÄŸrulama uygulama  
- **AraÃ§ Entegrasyonu**: AI yeteneklerini geniÅŸleten Ã¶zel araÃ§lar oluÅŸturma  

### Ã–nemli Ã‡Ä±karÄ±mlar  

> ğŸ¯ **UnutmayÄ±n**: LangChain gibi AI Ã§erÃ§eveleri, karmaÅŸÄ±klÄ±ÄŸÄ± gizleyen, Ã¶zelliklerle dolu en iyi arkadaÅŸlarÄ±nÄ±zdÄ±r. KonuÅŸma hafÄ±zasÄ±na, araÃ§ Ã§aÄŸÄ±rmaya veya birden fazla AI modeliyle Ã§alÄ±ÅŸmaya ihtiyacÄ±nÄ±z olduÄŸunda mÃ¼kemmeldir.  

**AI entegrasyonu iÃ§in karar Ã§erÃ§evesi:**  

```mermaid
flowchart TD
    A[AI Integration Need] --> B{Simple single query?}
    B -->|Yes| C[Direct API calls]
    B -->|No| D{Need conversation memory?}
    D -->|No| E[SDK Integration]
    D -->|Yes| F{Need tools or complex features?}
    F -->|No| G[Framework with basic setup]
    F -->|Yes| H[Full framework implementation]
    
    C --> I[HTTP requests, minimal dependencies]
    E --> J[Provider SDK, model-specific]
    G --> K[LangChain basic chat]
    H --> L[LangChain with tools, memory, agents]
```
  
### Buradan nereye gidebilirsiniz?  

**Hemen inÅŸa etmeye baÅŸlayÄ±n:**  
- Bu kavramlarÄ± alÄ±n ve sizi heyecanlandÄ±ran bir ÅŸeyler inÅŸa edin!  
- LangChain ile farklÄ± AI modellerini deneyin - bu, AI modellerinin oyun alanÄ± gibi  
- Ä°ÅŸinizde veya projelerinizde karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±z gerÃ§ek sorunlarÄ± Ã§Ã¶zen araÃ§lar oluÅŸturun  

**Bir sonraki seviyeye hazÄ±r mÄ±sÄ±nÄ±z?**  
- **AI AjanlarÄ±**: Kendi baÅŸÄ±na karmaÅŸÄ±k gÃ¶revleri planlayÄ±p gerÃ§ekleÅŸtirebilen AI sistemleri oluÅŸturun  
- **RAG (Retrieval-Augmented Generation)**: AI'Ä± kendi bilgi tabanlarÄ±nÄ±zla birleÅŸtirerek sÃ¼per gÃ¼Ã§lÃ¼ uygulamalar oluÅŸturun  
- **Multi-Modal AI**: Metin, gÃ¶rÃ¼ntÃ¼ ve sesle birlikte Ã§alÄ±ÅŸÄ±n - olasÄ±lÄ±klar sÄ±nÄ±rsÄ±z!  
- **Ãœretim DaÄŸÄ±tÄ±mÄ±**: AI uygulamalarÄ±nÄ±zÄ± Ã¶lÃ§eklendirmeyi ve gerÃ§ek dÃ¼nyada izlemeyi Ã¶ÄŸrenin  

**TopluluÄŸa katÄ±lÄ±n:**  
- LangChain topluluÄŸu, gÃ¼ncel kalmak ve en iyi uygulamalarÄ± Ã¶ÄŸrenmek iÃ§in harikadÄ±r  
- GitHub Modelleri, en son AI yeteneklerine eriÅŸim saÄŸlar - denemeler iÃ§in mÃ¼kemmel  
- FarklÄ± kullanÄ±m durumlarÄ±yla pratik yapmaya devam edin - her proje size yeni bir ÅŸey Ã¶ÄŸretecek  

ArtÄ±k insanlara gerÃ§ek sorunlarÄ± Ã§Ã¶zmede yardÄ±mcÄ± olabilecek akÄ±llÄ±, konuÅŸkan uygulamalar oluÅŸturma bilgisine sahipsiniz. Sanatsal vizyonu teknik beceriyle birleÅŸtiren RÃ¶nesans zanaatkarlarÄ± gibi, AI yeteneklerini pratik uygulamalarla birleÅŸtirebilirsiniz. Soru ÅŸu: ne yaratacaksÄ±nÄ±z? ğŸš€  

## GitHub Copilot Agent Challenge ğŸš€  

Agent modunu kullanarak aÅŸaÄŸÄ±daki zorluÄŸu tamamlayÄ±n:  

**AÃ§Ä±klama:** Birden fazla LangChain Ã¶zelliÄŸini birleÅŸtirerek, araÃ§ Ã§aÄŸÄ±rma, yapÄ±landÄ±rÄ±lmÄ±ÅŸ Ã§Ä±ktÄ± ve konuÅŸma hafÄ±zasÄ± iÃ§eren geliÅŸmiÅŸ bir AI destekli kod inceleme asistanÄ± oluÅŸturun.  

**Prompt:** Åu Ã¶zellikleri uygulayan bir CodeReviewAssistant sÄ±nÄ±fÄ± oluÅŸturun:  
1. Kod karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± analiz eden ve iyileÅŸtirme Ã¶nerileri sunan bir araÃ§  
2. Kodun en iyi uygulamalara uygunluÄŸunu kontrol eden bir araÃ§  
3. TutarlÄ± inceleme formatÄ± iÃ§in Pydantic modelleri kullanarak yapÄ±landÄ±rÄ±lmÄ±ÅŸ Ã§Ä±ktÄ±  
4. Ä°nceleme oturumlarÄ±nÄ± takip etmek iÃ§in konuÅŸma hafÄ±zasÄ±  
5. Kod gÃ¶nderimlerini iÅŸleyebilen ve ayrÄ±ntÄ±lÄ±, uygulanabilir geri bildirim saÄŸlayan bir ana sohbet arayÃ¼zÃ¼  

Asistan, birden fazla programlama dilinde kod inceleyebilmeli, bir oturumdaki birden fazla kod gÃ¶nderimi arasÄ±nda baÄŸlamÄ± koruyabilmeli ve hem Ã¶zet puanlar hem de ayrÄ±ntÄ±lÄ± iyileÅŸtirme Ã¶nerileri sunabilmelidir.  

Daha fazla bilgi iÃ§in [agent mode](https://code.visualstudio.com/blogs/2025/02/24/introducing-copilot-agent-mode) adresini ziyaret edin.  

---

**Feragatname**:  
Bu belge, AI Ã§eviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§evirilerin hata veya yanlÄ±ÅŸlÄ±klar iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Belgenin orijinal dili, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ±ndan kaynaklanan yanlÄ±ÅŸ anlamalar veya yanlÄ±ÅŸ yorumlamalar iÃ§in sorumluluk kabul etmiyoruz.