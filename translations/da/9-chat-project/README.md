<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "46d665af66e51524598af34a42b9b663",
  "translation_date": "2025-10-23T22:00:32+00:00",
  "source_file": "9-chat-project/README.md",
  "language_code": "da"
}
-->
# Byg en Chat-assistent med AI

Kan du huske i Star Trek, n√•r bes√¶tningen afslappet talte med skibets computer, stillede komplekse sp√∏rgsm√•l og fik gennemt√¶nkte svar? Det, der virkede som ren science fiction i 1960'erne, er nu noget, du kan bygge ved hj√¶lp af webteknologier, du allerede kender.

I denne lektion vil vi skabe en AI-chatassistent ved hj√¶lp af HTML, CSS, JavaScript og noget backend-integration. Du vil opdage, hvordan de samme f√¶rdigheder, du har l√¶rt, kan forbindes til kraftfulde AI-tjenester, der kan forst√• kontekst og generere meningsfulde svar.

T√¶nk p√• AI som at have adgang til et enormt bibliotek, der ikke kun kan finde information, men ogs√• syntetisere det til sammenh√¶ngende svar skr√¶ddersyet til dine specifikke sp√∏rgsm√•l. I stedet for at s√∏ge gennem tusindvis af sider f√•r du direkte, kontekstuelle svar.

Integrationen sker gennem velkendte webteknologier, der arbejder sammen. HTML skaber chatgr√¶nsefladen, CSS h√•ndterer det visuelle design, JavaScript styrer brugerinteraktioner, og en backend-API forbinder det hele til AI-tjenesterne. Det er lidt som hvordan forskellige sektioner af et orkester arbejder sammen for at skabe en symfoni.

Vi bygger i bund og grund en bro mellem naturlig menneskelig kommunikation og maskinbearbejdning. Du vil l√¶re b√•de den tekniske implementering af AI-tjenesteintegration og de designm√∏nstre, der g√∏r interaktioner intuitive.

Ved slutningen af denne lektion vil AI-integration f√∏les mindre som en mystisk proces og mere som en anden API, du kan arbejde med. Du vil forst√• de grundl√¶ggende m√∏nstre, der driver applikationer som ChatGPT og Claude, ved hj√¶lp af de samme webudviklingsprincipper, du har l√¶rt.

Her er, hvordan dit f√¶rdige projekt vil se ud:

![Chat-app-gr√¶nseflade, der viser en samtale mellem bruger og AI-assistent](../../../translated_images/screenshot.0a1ee0d123df681b4501eb53ffb267519fcc20aa653eabecef1e7561ddfb1cab.da.png)

## Forst√• AI: Fra mystik til mestring

F√∏r vi dykker ned i koden, lad os forst√•, hvad vi arbejder med. Hvis du har brugt API'er f√∏r, kender du det grundl√¶ggende m√∏nster: send en foresp√∏rgsel, modtag et svar.

AI-API'er f√∏lger en lignende struktur, men i stedet for at hente forudlagret data fra en database genererer de nye svar baseret p√• m√∏nstre, der er l√¶rt fra enorme m√¶ngder tekst. T√¶nk p√• det som forskellen mellem et bibliotekskatalogsystem og en vidende bibliotekar, der kan syntetisere information fra flere kilder.

### Hvad er "Generativ AI" egentlig?

T√¶nk p√•, hvordan Rosetta-stenen gjorde det muligt for forskere at forst√• egyptiske hieroglyffer ved at finde m√∏nstre mellem kendte og ukendte sprog. AI-modeller fungerer p√• samme m√•de ‚Äì de finder m√∏nstre i enorme m√¶ngder tekst for at forst√•, hvordan sprog fungerer, og bruger derefter disse m√∏nstre til at generere passende svar p√• nye sp√∏rgsm√•l.

**Lad mig forklare det med en simpel sammenligning:**
- **Traditionel database**: Som at bede om din f√∏dselsattest ‚Äì du f√•r det samme dokument hver gang.
- **S√∏gemaskine**: Som at bede en bibliotekar om at finde b√∏ger om katte ‚Äì de viser dig, hvad der er tilg√¶ngeligt.
- **Generativ AI**: Som at sp√∏rge en vidende ven om katte ‚Äì de fort√¶ller dig interessante ting med deres egne ord, skr√¶ddersyet til det, du vil vide.

```mermaid
graph LR
    A[Your Question] --> B[AI Model]
    B --> C[Pattern Recognition]
    C --> D[Content Generation]
    D --> E[Contextual Response]
    
    F[Training Data<br/>Books, Articles, Web] --> B
```

### Hvordan AI-modeller l√¶rer (den enkle version)

AI-modeller l√¶rer gennem eksponering for enorme datas√¶t, der indeholder tekst fra b√∏ger, artikler og samtaler. Gennem denne proces identificerer de m√∏nstre i:
- Hvordan tanker er struktureret i skriftlig kommunikation
- Hvilke ord der ofte optr√¶der sammen
- Hvordan samtaler typisk forl√∏ber
- Kontekstuelle forskelle mellem formel og uformel kommunikation

**Det er lidt som hvordan ark√¶ologer afkoder gamle sprog**: De analyserer tusindvis af eksempler for at forst√• grammatik, ordforr√•d og kulturel kontekst og bliver til sidst i stand til at tolke nye tekster ved hj√¶lp af de l√¶rte m√∏nstre.

### Hvorfor GitHub-modeller?

Vi bruger GitHub-modeller af en ret praktisk grund ‚Äì det giver os adgang til AI p√• virksomhedsniveau uden at skulle ops√¶tte vores egen AI-infrastruktur (hvilket, tro mig, du ikke har lyst til lige nu!). T√¶nk p√• det som at bruge en vejr-API i stedet for at fors√∏ge at forudsige vejret selv ved at ops√¶tte vejrstationer overalt.

Det er i bund og grund "AI-som-en-tjeneste", og det bedste? Det er gratis at komme i gang, s√• du kan eksperimentere uden at bekymre dig om at f√• en stor regning.

```mermaid
graph LR
    A[Frontend Chat UI] --> B[Your Backend API]
    B --> C[GitHub Models API]
    C --> D[AI Model Processing]
    D --> C
    C --> B
    B --> A
```

Vi bruger GitHub-modeller til vores backend-integration, som giver adgang til professionelle AI-funktioner gennem en udviklervenlig gr√¶nseflade. [GitHub Models Playground](https://github.com/marketplace/models/azure-openai/gpt-4o-mini/playground) fungerer som et testmilj√∏, hvor du kan eksperimentere med forskellige AI-modeller og forst√• deres kapaciteter, f√∏r du implementerer dem i kode.

![GitHub Models AI Playground-gr√¶nseflade med modelvalg og testomr√•de](../../../translated_images/playground.d2b927122224ff8ff4028fc842176e353c339147d8925455f36c92fb1655c477.da.png)

**Her er, hvad der g√∏r playground s√• nyttig:**
- **Pr√∏v** forskellige AI-modeller som GPT-4o-mini, Claude og andre (alle gratis!)
- **Test** dine ideer og prompts, f√∏r du skriver nogen kode
- **F√•** klar-til-brug kodeeksempler i dit foretrukne programmeringssprog
- **Tilpas** indstillinger som kreativitet og svarl√¶ngde for at se, hvordan de p√•virker output

N√•r du har leget lidt, skal du bare klikke p√• fanen "Code" og v√¶lge dit programmeringssprog for at f√• den implementeringskode, du har brug for.

![Playground-valg, der viser kodegenereringsmuligheder for forskellige programmeringssprog](../../../translated_images/playground-choice.1d23ba7d407f47584c9f446c77f0bcf70cae794cc9c8d7849a3cca4a3693e6c4.da.png)

## Ops√¶tning af Python-backend-integration

Nu skal vi implementere AI-integrationen ved hj√¶lp af Python. Python er fremragende til AI-applikationer p√• grund af sin enkle syntaks og kraftfulde biblioteker. Vi starter med koden fra GitHub Models Playground og refaktorerer den derefter til en genanvendelig, produktionsklar funktion.

### Forst√•else af basisimplementeringen

N√•r du henter Python-koden fra playground, f√•r du noget, der ser s√•dan ud. Bare rolig, hvis det virker som meget i starten ‚Äì lad os gennemg√• det stykke for stykke:

```python
"""Run this model in Python

> pip install openai
"""
import os
from openai import OpenAI

# To authenticate with the model you will need to generate a personal access token (PAT) in your GitHub settings. 
# Create your PAT token by following instructions here: https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens
client = OpenAI(
    base_url="https://models.github.ai/inference",
    api_key=os.environ["GITHUB_TOKEN"],
)

```python
response = client.chat.completions.create(
    messages=[
        {
            "role": "system",
            "content": "",
        },
        {
            "role": "user",
            "content": "What is the capital of France?",
        }
    ],
    model="openai/gpt-4o-mini",
    temperature=1,
    max_tokens=4096,
    top_p=1
)

print(response.choices[0].message.content)
```

**Her er, hvad der sker i denne kode:**
- **Vi importerer** de v√¶rkt√∏jer, vi har brug for: `os` til at l√¶se milj√∏variabler og `OpenAI` til at kommunikere med AI
- **Vi ops√¶tter** OpenAI-klienten til at pege p√• GitHubs AI-servere i stedet for OpenAI direkte
- **Vi autentificerer** med en speciel GitHub-token (mere om det om lidt!)
- **Vi strukturerer** vores samtale med forskellige "roller" ‚Äì t√¶nk p√• det som at s√¶tte scenen for et skuespil
- **Vi sender** vores foresp√∏rgsel til AI med nogle finjusteringsparametre
- **Vi udtr√¶kker** den faktiske svartekst fra alle de data, der kommer tilbage

### Forst√•else af beskedroller: AI-samtalens rammev√¶rk

AI-samtaler bruger en specifik struktur med forskellige "roller", der tjener forskellige form√•l:

```python
messages=[
    {
        "role": "system",
        "content": "You are a helpful assistant who explains things simply."
    },
    {
        "role": "user", 
        "content": "What is machine learning?"
    }
]
```

**T√¶nk p√• det som at instruere et skuespil:**
- **Systemrolle**: Som sceneanvisninger for en skuespiller ‚Äì det fort√¶ller AI, hvordan den skal opf√∏re sig, hvilken personlighed den skal have, og hvordan den skal svare
- **Brugerrolle**: Det faktiske sp√∏rgsm√•l eller besked fra personen, der bruger din applikation
- **Assistentrolle**: AI's svar (du sender ikke dette, men det vises i samtalehistorikken)

**Virkelighedsanalog**: Forestil dig, at du introducerer en ven til nogen til en fest:
- **Systembesked**: "Dette er min ven Sarah, hun er l√¶ge og er fantastisk til at forklare medicinske begreber p√• en enkel m√•de"
- **Brugerbesked**: "Kan du forklare, hvordan vacciner fungerer?"
- **Assistentens svar**: Sarah svarer som en venlig l√¶ge, ikke som en advokat eller kok

### Forst√•else af AI-parametre: Finjustering af svaradf√¶rd

De numeriske parametre i AI-API-kald styrer, hvordan modellen genererer svar. Disse indstillinger giver dig mulighed for at justere AI's adf√¶rd til forskellige anvendelser:

#### Temperatur (0.0 til 2.0): Kreativitetsknappen

**Hvad det g√∏r**: Styrer, hvor kreativ eller forudsigelig AI's svar vil v√¶re.

**T√¶nk p√• det som en jazzmusikers improvisationsniveau:**
- **Temperatur = 0.1**: Spiller den samme melodi hver gang (meget forudsigelig)
- **Temperatur = 0.7**: Tilf√∏jer nogle smagfulde variationer, mens den forbliver genkendelig (balanceret kreativitet)
- **Temperatur = 1.5**: Fuld eksperimentel jazz med uventede drejninger (meget uforudsigelig)

```python
# Very predictable responses (good for factual questions)
response = client.chat.completions.create(
    messages=[{"role": "user", "content": "What is 2+2?"}],
    temperature=0.1  # Will almost always say "4"
)

# Creative responses (good for brainstorming)
response = client.chat.completions.create(
    messages=[{"role": "user", "content": "Write a creative story opening"}],
    temperature=1.2  # Will generate unique, unexpected stories
)
```

#### Max Tokens (1 til 4096+): Kontrol af svarl√¶ngde

**Hvad det g√∏r**: S√¶tter en gr√¶nse for, hvor langt AI's svar kan v√¶re.

**T√¶nk p√• tokens som nogenlunde svarende til ord** (ca. 1 token = 0.75 ord p√• engelsk):
- **max_tokens=50**: Kort og pr√¶cist (som en tekstbesked)
- **max_tokens=500**: Et p√¶nt afsnit eller to
- **max_tokens=2000**: En detaljeret forklaring med eksempler

```python
# Short, concise answers
response = client.chat.completions.create(
    messages=[{"role": "user", "content": "Explain JavaScript"}],
    max_tokens=100  # Forces a brief explanation
)

# Detailed, comprehensive answers  
response = client.chat.completions.create(
    messages=[{"role": "user", "content": "Explain JavaScript"}],
    max_tokens=1500  # Allows for detailed explanations with examples
)
```

#### Top_p (0.0 til 1.0): Fokusparameteren

**Hvad det g√∏r**: Styrer, hvor fokuseret AI forbliver p√• de mest sandsynlige svar.

**Forestil dig, at AI har et enormt ordforr√•d, rangeret efter hvor sandsynligt hvert ord er:**
- **top_p=0.1**: Overvejer kun de 10% mest sandsynlige ord (meget fokuseret)
- **top_p=0.9**: Overvejer 90% af mulige ord (mere kreativ)
- **top_p=1.0**: Overvejer alt (maksimal variation)

**For eksempel**: Hvis du sp√∏rger "Himlen er normalt..."
- **Lav top_p**: Siger n√¶sten helt sikkert "bl√•"
- **H√∏j top_p**: Kan sige "bl√•", "overskyet", "vidstrakt", "foranderlig", "smuk" osv.

### Sammenkobling af det hele: Parameterkombinationer til forskellige anvendelser

```python
# For factual, consistent answers (like a documentation bot)
factual_params = {
    "temperature": 0.2,
    "max_tokens": 300,
    "top_p": 0.3
}

# For creative writing assistance
creative_params = {
    "temperature": 1.1,
    "max_tokens": 1000,
    "top_p": 0.9
}

# For conversational, helpful responses (balanced)
conversational_params = {
    "temperature": 0.7,
    "max_tokens": 500,
    "top_p": 0.8
}
```

**Forst√•else af, hvorfor disse parametre betyder noget**: Forskellige applikationer har brug for forskellige typer svar. En kundeservicebot b√∏r v√¶re konsekvent og faktuel (lav temperatur), mens en kreativ skriveassistent b√∏r v√¶re fantasifuld og varieret (h√∏j temperatur). Forst√•else af disse parametre giver dig kontrol over din AI's personlighed og svarstil.
```

**Here's what's happening in this code:**
- **We import** the tools we need: `os` for reading environment variables and `OpenAI` for talking to the AI
- **We set up** the OpenAI client to point to GitHub's AI servers instead of OpenAI directly
- **We authenticate** using a special GitHub token (more on that in a minute!)
- **We structure** our conversation with different "roles" ‚Äì think of it like setting the scene for a play
- **We send** our request to the AI with some fine-tuning parameters
- **We extract** the actual response text from all the data that comes back

> üîê **Security Note**: Never hardcode API keys in your source code! Always use environment variables to store sensitive credentials like your `GITHUB_TOKEN`.

### Creating a Reusable AI Function

Let's refactor this code into a clean, reusable function that we can easily integrate into our web application:

```python
import asyncio
from openai import AsyncOpenAI

# Use AsyncOpenAI for better performance
client = AsyncOpenAI(
    base_url="https://models.github.ai/inference",
    api_key=os.environ["GITHUB_TOKEN"],
)

async def call_llm_async(prompt: str, system_message: str = "You are a helpful assistant."):
    """
    Sends a prompt to the AI model asynchronously and returns the response.
    
    Args:
        prompt: The user's question or message
        system_message: Instructions that define the AI's behavior and personality
    
    Returns:
        str: The AI's response to the prompt
    """
    try:
        response = await client.chat.completions.create(
            messages=[
                {
                    "role": "system",
                    "content": system_message,
                },
                {
                    "role": "user",
                    "content": prompt,
                }
            ],
            model="openai/gpt-4o-mini",
            temperature=1,
            max_tokens=4096,
            top_p=1
        )
        return response.choices[0].message.content
    except Exception as e:
        logger.error(f"AI API error: {str(e)}")
        return "I'm sorry, I'm having trouble processing your request right now."

# Backward compatibility function for synchronous calls
def call_llm(prompt: str, system_message: str = "You are a helpful assistant."):
    """Synchronous wrapper for async AI calls."""
    return asyncio.run(call_llm_async(prompt, system_message))
```

**Forst√•else af denne forbedrede funktion:**
- **Accepterer** to parametre: brugerens prompt og en valgfri systembesked
- **Tilbyder** en standard systembesked for generel assistentadf√¶rd
- **Bruger** korrekte Python-type hints for bedre kodedokumentation
- **Returnerer** kun svarindholdet, hvilket g√∏r det nemt at bruge i vores web-API
- **Bevarer** de samme modelparametre for konsekvent AI-adf√¶rd

### Magien ved systemprompter: Programmering af AI's personlighed

Hvis parametre styrer, hvordan AI t√¶nker, styrer systemprompter, hvem AI tror, den er. Dette er √¶rligt talt en af de mest fascinerende dele ved at arbejde med AI ‚Äì du giver i bund og grund AI en komplet personlighed, ekspertiseniveau og kommunikationsstil.

**T√¶nk p√• systemprompter som at caste forskellige skuespillere til forskellige roller**: I stedet for at have √©n generisk assistent kan du skabe specialiserede eksperter til forskellige situationer. Har du brug for en t√•lmodig l√¶rer? En kreativ sparringspartner? En no-nonsense forretningsr√•dgiver? Bare √¶ndr systemprompten!

#### Hvorfor systemprompter er s√• kraftfulde

Her er det fascinerende: AI-modeller er blevet tr√¶net p√• utallige samtaler, hvor folk indtager forskellige roller og ekspertiseniveauer. N√•r du giver AI en specifik rolle, er det som at aktivere alle de l√¶rte m√∏nstre.

**Det er som metode-skuespil for AI**: Fort√¶l en skuespiller "du er en klog gammel professor" og se, hvordan de automatisk justerer deres holdning, ordforr√•d og manerer. AI g√∏r noget bem√¶rkelsesv√¶rdigt lignende med sprogm√∏nstre.

#### Udformning af effektive systemprompter: Kunst og videnskab

**Anatomien af en god systemprompt:**
1. **Rolle/Identitet**: Hvem er AI?
2. **Ekspertise**: Hvad ved den?
3. **Kommunikationsstil**: Hvordan taler den?
4. **Specifikke instruktioner**: Hvad skal den fokusere p√•?

```python
# ‚ùå Vague system prompt
"You are helpful."

# ‚úÖ Detailed, effective system prompt
"You are Dr. Sarah Chen, a senior software engineer with 15 years of experience at major tech companies. You explain programming concepts using real-world analogies and always provide practical examples. You're patient with beginners and enthusiastic about helping them understand complex topics."
```

#### Eksempler p√• systemprompter med kontekst

Lad os se, hvordan forskellige systemprompter skaber helt forskellige AI-personligheder:

```python
# Example 1: The Patient Teacher
teacher_prompt = """
You are an experienced programming instructor who has taught thousands of students. 
You break down complex concepts into simple steps, use analogies from everyday life, 
and always check if the student understands before moving on. You're encouraging 
and never make students feel bad for not knowing something.
"""

# Example 2: The Creative Collaborator  
creative_prompt = """
You are a creative writing partner who loves brainstorming wild ideas. You're 
enthusiastic, imaginative, and always build on the user's ideas rather than 
replacing them. You ask thought-provoking questions to spark creativity and 
offer unexpected perspectives that make stories more interesting.
"""

# Example 3: The Strategic Business Advisor
business_prompt = """
You are a strategic business consultant with an MBA and 20 years of experience 
helping startups scale. You think in frameworks, provide structured advice, 
and always consider both short-term tactics and long-term strategy. You ask 
probing questions to understand the full business context before giving advice.
"""
```

#### Se systemprompter i aktion

Lad os teste det samme sp√∏rgsm√•l med forskellige systemprompter for at se de dramatiske forskelle:

**Sp√∏rgsm√•l**: "Hvordan h√•ndterer jeg brugerautentifikation i min webapp?"

```python
# With teacher prompt:
teacher_response = call_llm(
    "How do I handle user authentication in my web app?",
    teacher_prompt
)
# Typical response: "Great question! Let's break authentication down into simple steps. 
# Think of it like a nightclub bouncer checking IDs..."

# With business prompt:
business_response = call_llm(
    "How do I handle user authentication in my web app?", 
    business_prompt
)
# Typical response: "From a strategic perspective, authentication is crucial for user 
# trust and regulatory compliance. Let me outline a framework considering security, 
# user experience, and scalability..."
```

#### Avancerede teknikker til systemprompter

**1. Kontekstops√¶tning**: Giv AI baggrundsinformation
```python
system_prompt = """
You are helping a junior developer who just started their first job at a startup. 
They know basic HTML/CSS/JavaScript but are new to backend development and databases. 
Be encouraging and explain things step-by-step without being condescending.
"""
```

**2. Outputformatering**: Fort√¶l AI, hvordan den skal strukturere svar
```python
system_prompt = """
You are a technical mentor. Always structure your responses as:
1. Quick Answer (1-2 sentences)
2. Detailed Explanation 
3. Code Example
4. Common Pitfalls to Avoid
5. Next Steps for Learning
"""
```

**3. Begr√¶nsningsops√¶tning**: Definer, hvad AI ikke skal g√∏re
```python
system_prompt = """
You are a coding tutor focused on teaching best practices. Never write complete 
solutions for the user - instead, guide them with hints and questions so they 
learn by doing. Always explain the 'why' behind coding decisions.
"""
```

#### Hvorfor dette er vigtigt for din chat-assistent

Forst√•else af systemprompter giver dig utrolig magt til at skabe specialiserede AI-assistenter:
- **Kundeservicebot**: Hj√¶lpsom, t√•lmodig, politikbevidst
- **L√¶ringsvejleder**: Opmuntrende, trin-for-trin, tjekker forst√•else
- **Kreativ partner**: Fantasifuld, bygger videre p√• ideer, sp√∏rger "hvad nu hvis?"
- **Teknisk ekspert**: Pr√¶cis, detaljeret, sikkerhedsbevidst

**Den vigtigste indsigt**: Du kalder ikke bare en AI-API ‚Äì du skaber en skr√¶ddersyet AI-personlighed, der tjener din specifikke anvendelse. Det er det, der g√∏r moderne AI-applikationer f√∏les skr√¶ddersyede og nyttige frem for generiske.

## Bygning af web-API med FastAPI: Din h√∏jtydende AI-kommunikationshub

Nu skal vi bygge den backend, der forbinder din frontend med AI-tjenesterne. Vi bruger FastAPI, et moderne Python-framework, der er fremragende til at bygge API'er til AI-applikationer.

FastAPI tilbyder flere fordele for denne type projekt: indbygget async-support til h√•ndtering af samtidige foresp√∏rgsler, automatisk API-dokumentationsgenerering og fremragende ydeevne. Din FastAPI-server fungerer som en mellemmand, der modtager foresp√∏rgsler fra frontend, kommunikerer med AI-tjenester og returnerer formaterede svar.

### Hvorfor FastAPI til AI-applikationer?

Du t√¶nker m√•ske: "Kan jeg ikke bare kalde AI direkte fra min frontend JavaScript?" eller "Hvorfor FastAPI i stedet for Flask eller Django?" Gode sp√∏rgsm√•l! 
**Her er hvorfor FastAPI er perfekt til det, vi bygger:**
- **Async som standard**: Kan h√•ndtere flere AI-anmodninger p√• √©n gang uden at g√• i st√•
- **Automatisk dokumentation**: Bes√∏g `/docs` og f√• en flot, interaktiv API-dokumentationsside gratis
- **Indbygget validering**: Fanger fejl, f√∏r de skaber problemer
- **Lynhurtig**: En af de hurtigste Python-frameworks der findes
- **Moderne Python**: Udnytter de nyeste og bedste Python-funktioner

**Og her er hvorfor vi overhovedet har brug for en backend:**

**Sikkerhed**: Din AI API-n√∏gle er som en adgangskode ‚Äì hvis du placerer den i frontend JavaScript, kan enhver, der ser din hjemmesides kildekode, stj√¶le den og bruge dine AI-kreditter. Backenden holder f√∏lsomme legitimationsoplysninger sikre.

**Ratebegr√¶nsning & kontrol**: Backenden giver dig mulighed for at kontrollere, hvor ofte brugere kan sende anmodninger, implementere brugerautentifikation og tilf√∏je logning for at spore brugen.

**Databehandling**: Du vil m√•ske gemme samtaler, filtrere upassende indhold eller kombinere flere AI-tjenester. Backenden er stedet, hvor denne logik lever.

**Arkitekturen ligner en klient-server-model:**
- **Frontend**: Brugergr√¶nsefladelag til interaktion
- **Backend API**: Anmodningsbehandlings- og routingslag
- **AI-tjeneste**: Ekstern beregning og responsgenerering
- **Milj√∏variabler**: Sikker konfiguration og opbevaring af legitimationsoplysninger

### Forst√•else af anmodnings-respons flow

Lad os spore, hvad der sker, n√•r en bruger sender en besked:

```mermaid
sequenceDiagram
    participant User as üë§ User
    participant Frontend as üåê Frontend
    participant API as üîß FastAPI Server
    participant AI as ü§ñ AI Service
    
    User->>Frontend: Types "Hello AI!"
    Frontend->>API: POST /hello {"message": "Hello AI!"}
    Note over API: Validates request<br/>Adds system prompt
    API->>AI: Sends formatted request
    AI->>API: Returns AI response
    Note over API: Processes response<br/>Logs conversation
    API->>Frontend: {"response": "Hello! How can I help?"}
    Frontend->>User: Displays AI message
```

**Forst√•else af hvert trin:**
1. **Brugerinteraktion**: Personen skriver i chatgr√¶nsefladen
2. **Frontend-behandling**: JavaScript fanger input og formaterer det som JSON
3. **API-validering**: FastAPI validerer automatisk anmodningen ved hj√¶lp af Pydantic-modeller
4. **AI-integration**: Backend tilf√∏jer kontekst (systemprompt) og kalder AI-tjenesten
5. **Responsh√•ndtering**: API modtager AI-responsen og kan √¶ndre den, hvis n√∏dvendigt
6. **Frontend-visning**: JavaScript viser responsen i chatgr√¶nsefladen

### Forst√•else af API-arkitektur

```mermaid
sequenceDiagram
    participant Frontend
    participant FastAPI
    participant AI Function
    participant GitHub Models
    
    Frontend->>FastAPI: POST /hello {"message": "Hello AI!"}
    FastAPI->>AI Function: call_llm(message, system_prompt)
    AI Function->>GitHub Models: API request
    GitHub Models->>AI Function: AI response
    AI Function->>FastAPI: response text
    FastAPI->>Frontend: {"response": "Hello! How can I help?"}
```

### Oprettelse af FastAPI-applikationen

Lad os bygge vores API trin for trin. Opret en fil kaldet `api.py` med f√∏lgende FastAPI-kode:

```python
# api.py
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from llm import call_llm
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Create FastAPI application
app = FastAPI(
    title="AI Chat API",
    description="A high-performance API for AI-powered chat applications",
    version="1.0.0"
)

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydantic models for request/response validation
class ChatMessage(BaseModel):
    message: str

class ChatResponse(BaseModel):
    response: str

@app.get("/")
async def root():
    """Root endpoint providing API information."""
    return {
        "message": "Welcome to the AI Chat API",
        "docs": "/docs",
        "health": "/health"
    }

@app.get("/health")
async def health_check():
    """Health check endpoint."""
    return {"status": "healthy", "service": "ai-chat-api"}

@app.post("/hello", response_model=ChatResponse)
async def chat_endpoint(chat_message: ChatMessage):
    """Main chat endpoint that processes messages and returns AI responses."""
    try:
        # Extract and validate message
        message = chat_message.message.strip()
        if not message:
            raise HTTPException(status_code=400, detail="Message cannot be empty")
        
        logger.info(f"Processing message: {message[:50]}...")
        
        # Call AI service (note: call_llm should be made async for better performance)
        ai_response = await call_llm_async(message, "You are a helpful and friendly assistant.")
        
        logger.info("AI response generated successfully")
        return ChatResponse(response=ai_response)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error processing chat message: {str(e)}")
        raise HTTPException(status_code=500, detail="Internal server error")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=5000, reload=True)
```

**Forst√•else af FastAPI-implementeringen:**
- **Importer** FastAPI for moderne webframework-funktionalitet og Pydantic for datavalidering
- **Opretter** automatisk API-dokumentation (tilg√¶ngelig p√• `/docs`, n√•r serveren k√∏rer)
- **Aktiverer** CORS-middleware for at tillade frontend-anmodninger fra forskellige oprindelser
- **Definerer** Pydantic-modeller for automatisk validering og dokumentation af anmodninger/responser
- **Bruger** asynkrone endpoints for bedre ydeevne med samtidige anmodninger
- **Implementerer** korrekte HTTP-statuskoder og fejlh√•ndtering med HTTPException
- **Inkluderer** struktureret logning til overv√•gning og fejlfinding
- **Tilbyder** en sundhedstjek-endpoint til overv√•gning af tjenestens status

**Vigtige fordele ved FastAPI frem for traditionelle frameworks:**
- **Automatisk validering**: Pydantic-modeller sikrer dataintegritet f√∏r behandling
- **Interaktiv dokumentation**: Bes√∏g `/docs` for auto-genereret, testbar API-dokumentation
- **Type-sikkerhed**: Python type hints forhindrer runtime-fejl og forbedrer kodekvaliteten
- **Async support**: H√•ndter flere AI-anmodninger samtidigt uden blokering
- **Ydeevne**: Markant hurtigere anmodningsbehandling til realtidsapplikationer

### Forst√•else af CORS: Webs sikkerhedsvagt

CORS (Cross-Origin Resource Sharing) er som en sikkerhedsvagt ved en bygning, der tjekker, om bes√∏gende har tilladelse til at komme ind. Lad os forst√•, hvorfor dette er vigtigt, og hvordan det p√•virker din applikation.

#### Hvad er CORS, og hvorfor eksisterer det?

**Problemet**: Forestil dig, hvis enhver hjemmeside kunne sende anmodninger til din banks hjemmeside p√• dine vegne uden din tilladelse. Det ville v√¶re en sikkerhedskatastrofe! Browsere forhindrer dette som standard gennem "Same-Origin Policy."

**Same-Origin Policy**: Browsere tillader kun websider at sende anmodninger til det samme dom√¶ne, port og protokol, som de blev indl√¶st fra.

**Virkelighedens analogi**: Det er som sikkerheden i en lejlighedsbygning ‚Äì kun beboere (samme oprindelse) kan f√• adgang til bygningen som standard. Hvis du vil lade en ven (anden oprindelse) bes√∏ge, skal du eksplicit fort√¶lle sikkerheden, at det er okay.

#### CORS i dit udviklingsmilj√∏

Under udvikling k√∏rer din frontend og backend p√• forskellige porte:
- Frontend: `http://localhost:3000` (eller file:// hvis du √•bner HTML direkte)
- Backend: `http://localhost:5000`

Disse betragtes som "forskellige oprindelser", selvom de er p√• den samme computer!

```python
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI(__name__)
CORS(app)   # This tells browsers: "It's okay for other origins to make requests to this API"
```

**Hvad CORS-konfiguration g√∏r i praksis:**
- **Tilf√∏jer** specielle HTTP-headers til API-responser, der fort√¶ller browsere "denne cross-origin anmodning er tilladt"
- **H√•ndterer** "preflight"-anmodninger (browsere tjekker nogle gange tilladelser, f√∏r de sender den faktiske anmodning)
- **Forhindrer** den frygtede "blokeret af CORS-politik"-fejl i din browserkonsol

#### CORS-sikkerhed: Udvikling vs produktion

```python
# üö® Development: Allows ALL origins (convenient but insecure)
CORS(app)

# ‚úÖ Production: Only allow your specific frontend domain
CORS(app, origins=["https://yourdomain.com", "https://www.yourdomain.com"])

# üîí Advanced: Different origins for different environments
if app.debug:  # Development mode
    CORS(app, origins=["http://localhost:3000", "http://127.0.0.1:3000"])
else:  # Production mode
    CORS(app, origins=["https://yourdomain.com"])
```

**Hvorfor dette er vigtigt**: Under udvikling er `CORS(app)` som at lade din hovedd√∏r st√• ul√•st ‚Äì praktisk, men ikke sikkert. I produktion vil du specificere pr√¶cis, hvilke hjemmesider der kan kommunikere med din API.

#### Almindelige CORS-scenarier og l√∏sninger

| Scenario | Problem | L√∏sning |
|----------|---------|---------|
| **Lokal udvikling** | Frontend kan ikke n√• backend | Tilf√∏j CORSMiddleware til FastAPI |
| **GitHub Pages + Heroku** | Udrullet frontend kan ikke n√• API | Tilf√∏j din GitHub Pages URL til CORS oprindelser |
| **Eget dom√¶ne** | CORS-fejl i produktion | Opdater CORS oprindelser til at matche dit dom√¶ne |
| **Mobilapp** | App kan ikke n√• web-API | Tilf√∏j din apps dom√¶ne eller brug `*` med forsigtighed |

**Tip**: Du kan tjekke CORS-headers i din browsers Developer Tools under fanen Network. Kig efter headers som `Access-Control-Allow-Origin` i responsen.

### Fejlh√•ndtering og validering

Bem√¶rk, hvordan vores API inkluderer korrekt fejlh√•ndtering:

```python
# Validate that we received a message
if not message:
    return jsonify({"error": "Message field is required"}), 400
```

**Vigtige valideringsprincipper:**
- **Tjekker** for p√•kr√¶vede felter f√∏r behandling af anmodninger
- **Returnerer** meningsfulde fejlmeddelelser i JSON-format
- **Bruger** passende HTTP-statuskoder (400 for d√•rlige anmodninger)
- **Giver** klar feedback for at hj√¶lpe frontend-udviklere med at fejlfinde problemer

## Ops√¶tning og k√∏rsel af din backend

Nu hvor vi har vores AI-integration og FastAPI-server klar, lad os f√• det hele i gang. Ops√¶tningsprocessen involverer installation af Python-afh√¶ngigheder, konfiguration af milj√∏variabler og start af din udviklingsserver.

### Python-milj√∏ops√¶tning

Lad os ops√¶tte dit Python-udviklingsmilj√∏. Virtuelle milj√∏er er som Manhattan-projektets compartmentaliserede tilgang ‚Äì hvert projekt f√•r sit eget isolerede rum med specifikke v√¶rkt√∏jer og afh√¶ngigheder, hvilket forhindrer konflikter mellem forskellige projekter.

```bash
# Navigate to your backend directory
cd backend

# Create a virtual environment (like creating a clean room for your project)
python -m venv venv

# Activate it (Linux/Mac)
source ./venv/bin/activate

# On Windows, use:
# venv\Scripts\activate

# Install the good stuff
pip install openai fastapi uvicorn python-dotenv
```

**Hvad vi lige gjorde:**
- **Oprettede** vores egen lille Python-boble, hvor vi kan installere pakker uden at p√•virke noget andet
- **Aktiverede** det, s√• vores terminal ved at bruge dette specifikke milj√∏
- **Installerede** det n√∏dvendige: OpenAI til AI-magi, FastAPI til vores web-API, Uvicorn til faktisk at k√∏re det, og python-dotenv til sikker h√•ndtering af hemmeligheder

**Vigtige afh√¶ngigheder forklaret:**
- **FastAPI**: Moderne, hurtigt webframework med automatisk API-dokumentation
- **Uvicorn**: Lynhurtig ASGI-server, der k√∏rer FastAPI-applikationer
- **OpenAI**: Officiel bibliotek til GitHub-modeller og OpenAI API-integration
- **python-dotenv**: Sikker indl√¶sning af milj√∏variabler fra .env-filer

### Milj√∏konfiguration: Hold hemmeligheder sikre

F√∏r vi starter vores API, skal vi tale om en af de vigtigste lektioner i webudvikling: hvordan man holder sine hemmeligheder faktisk hemmelige. Milj√∏variabler er som en sikker boks, som kun din applikation kan f√• adgang til.

#### Hvad er milj√∏variabler?

**T√¶nk p√• milj√∏variabler som en sikkerhedsboks** ‚Äì du l√¶gger dine v√¶rdigenstande derind, og kun du (og din app) har n√∏glen til at f√• dem ud. I stedet for at skrive f√∏lsomme oplysninger direkte i din kode (hvor bogstaveligt talt alle kan se dem), gemmer du dem sikkert i milj√∏et.

**Her er forskellen:**
- **Den forkerte m√•de**: Skrive din adgangskode p√• en post-it og s√¶tte den p√• din sk√¶rm
- **Den rigtige m√•de**: Opbevare din adgangskode i en sikker adgangskode-manager, som kun du kan f√• adgang til

#### Hvorfor milj√∏variabler er vigtige

```python
# üö® NEVER DO THIS - API key visible to everyone
client = OpenAI(
    api_key="ghp_1234567890abcdef...",  # Anyone can steal this!
    base_url="https://models.github.ai/inference"
)

# ‚úÖ DO THIS - API key stored securely
client = OpenAI(
    api_key=os.environ["GITHUB_TOKEN"],  # Only your app can access this
    base_url="https://models.github.ai/inference"
)
```

**Hvad der sker, n√•r du hardcoder hemmeligheder:**
1. **Eksponering i versionskontrol**: Alle med adgang til dit Git-repository kan se din API-n√∏gle
2. **Offentlige repositories**: Hvis du uploader til GitHub, er din n√∏gle synlig for hele internettet
3. **Deling med teamet**: Andre udviklere, der arbejder p√• dit projekt, f√•r adgang til din personlige API-n√∏gle
4. **Sikkerhedsbrud**: Hvis nogen stj√¶ler din API-n√∏gle, kan de bruge dine AI-kreditter

#### Ops√¶tning af din milj√∏fil

Opret en `.env`-fil i din backend-mappe. Denne fil gemmer dine hemmeligheder lokalt:

```bash
# .env file - This should NEVER be committed to Git
GITHUB_TOKEN=your_github_personal_access_token_here
FASTAPI_DEBUG=True
ENVIRONMENT=development
```

**Forst√•else af .env-filen:**
- **√ân hemmelighed per linje** i `KEY=value`-format
- **Ingen mellemrum** omkring lighedstegnet
- **Ingen anf√∏rselstegn** n√∏dvendige omkring v√¶rdier (normalt)
- **Kommentarer** starter med `#`

#### Oprettelse af din GitHub Personal Access Token

Din GitHub-token er som en speciel adgangskode, der giver din applikation tilladelse til at bruge GitHubs AI-tjenester:

**Trin-for-trin token-oprettelse:**
1. **G√• til GitHub-indstillinger** ‚Üí Udviklerindstillinger ‚Üí Personlige adgangstokens ‚Üí Tokens (klassisk)
2. **Klik p√• "Generer nyt token (klassisk)"**
3. **Indstil udl√∏b** (30 dage til test, l√¶ngere til produktion)
4. **V√¶lg scopes**: Marker "repo" og andre n√∏dvendige tilladelser
5. **Generer token** og kopier det med det samme (du kan ikke se det igen!)
6. **Inds√¶t det i din .env-fil**

```bash
# Example of what your token looks like (this is fake!)
GITHUB_TOKEN=ghp_1A2B3C4D5E6F7G8H9I0J1K2L3M4N5O6P7Q8R
```

#### Indl√¶sning af milj√∏variabler i Python

```python
import os
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Now you can access them securely
api_key = os.environ.get("GITHUB_TOKEN")
if not api_key:
    raise ValueError("GITHUB_TOKEN not found in environment variables!")

client = OpenAI(
    api_key=api_key,
    base_url="https://models.github.ai/inference"
)
```

**Hvad denne kode g√∏r:**
- **Indl√¶ser** din .env-fil og g√∏r variabler tilg√¶ngelige for Python
- **Tjekker** om den n√∏dvendige token eksisterer (god fejlh√•ndtering!)
- **Rejser** en klar fejl, hvis token mangler
- **Bruger** token sikkert uden at eksponere det i koden

#### Git-sikkerhed: .gitignore-filen

Din `.gitignore`-fil fort√¶ller Git, hvilke filer der aldrig skal spores eller uploades:

```bash
# .gitignore - Add these lines
.env
*.env
.env.local
.env.production
__pycache__/
venv/
.vscode/
```

**Hvorfor dette er afg√∏rende**: N√•r du tilf√∏jer `.env` til `.gitignore`, vil Git ignorere din milj√∏fil, hvilket forhindrer dig i utilsigtet at uploade dine hemmeligheder til GitHub.

#### Forskellige milj√∏er, forskellige hemmeligheder

Professionelle applikationer bruger forskellige API-n√∏gler til forskellige milj√∏er:

```bash
# .env.development
GITHUB_TOKEN=your_development_token
DEBUG=True

# .env.production  
GITHUB_TOKEN=your_production_token
DEBUG=False
```

**Hvorfor dette er vigtigt**: Du vil ikke have, at dine udviklingseksperimenter p√•virker din produktions-AI-brugskvote, og du √∏nsker forskellige sikkerhedsniveauer for forskellige milj√∏er.

### Start af din udviklingsserver: Bring din FastAPI til live

Nu kommer det sp√¶ndende √∏jeblik ‚Äì start din FastAPI-udviklingsserver og se din AI-integration komme til live! FastAPI bruger Uvicorn, en lynhurtig ASGI-server, der er specielt designet til asynkrone Python-applikationer.

#### Forst√•else af FastAPI-serverens opstartsproces

```bash
# Method 1: Direct Python execution (includes auto-reload)
python api.py

# Method 2: Using Uvicorn directly (more control)
uvicorn api:app --host 0.0.0.0 --port 5000 --reload
```

N√•r du k√∏rer denne kommando, sker f√∏lgende bag kulisserne:

**1. Python indl√¶ser din FastAPI-applikation**:
- Importerer alle n√∏dvendige biblioteker (FastAPI, Pydantic, OpenAI osv.)
- Indl√¶ser milj√∏variabler fra din `.env`-fil
- Opretter FastAPI-applikationsinstansen med automatisk dokumentation

**2. Uvicorn konfigurerer ASGI-serveren**:
- Binder til port 5000 med asynkron anmodningsh√•ndtering
- Ops√¶tter anmodningsrouting med automatisk validering
- Aktiverer hot reload til udvikling (genstarter ved fil√¶ndringer)
- Genererer interaktiv API-dokumentation

**3. Serveren begynder at lytte**:
- Din terminal viser: `INFO: Uvicorn running on http://0.0.0.0:5000`
- Serveren kan h√•ndtere flere samtidige AI-anmodninger
- Din API er klar med automatisk dokumentation p√• `http://localhost:5000/docs`

#### Hvad du b√∏r se, n√•r alt fungerer

```bash
$ python api.py
INFO:     Will watch for changes in these directories: ['/your/project/path']
INFO:     Uvicorn running on http://0.0.0.0:5000 (Press CTRL+C to quit)
INFO:     Started reloader process [12345] using WatchFiles
INFO:     Started server process [12346]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
```

**Forst√•else af FastAPI-output:**
- **Vil overv√•ge √¶ndringer**: Auto-reload aktiveret til udvikling
- **Uvicorn k√∏rer**: H√∏jtydende ASGI-server er aktiv
- **Genstarter proces**: Filoverv√•gning til automatiske genstarter
- **Applikationsopstart fuldf√∏rt**: FastAPI-app initialiseret med succes
- **Interaktiv dokumentation tilg√¶ngelig**: Bes√∏g `/docs` for automatisk API-dokumentation

#### Test af din FastAPI: Flere kraftfulde metoder

FastAPI tilbyder flere praktiske m√•der at teste din API p√•, inklusive automatisk interaktiv dokumentation:

**Metode 1: Interaktiv API-dokumentation (anbefales)**
1. √Öbn din browser og g√• til `http://localhost:5000/docs`
2. Du vil se Swagger UI med alle dine endpoints dokumenteret
3. Klik p√• `/hello` ‚Üí "Pr√∏v det" ‚Üí Indtast en testbesked ‚Üí "Udf√∏r"
4. Se responsen direkte i browseren med korrekt formatering

**Metode 2: Grundl√¶ggende browser-test**
1. G√• til `http://localhost:5000` for root-endpointet
2. G√• til `http://localhost:5000/health` for at tjekke serverens sundhed
3. Dette bekr√¶fter, at din FastAPI-server k√∏rer korrekt

**Metode 2: Kommandolinjetest (avanceret)**
```bash
# Test with curl (if available)
curl -X POST http://localhost:5000/hello \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello AI!"}'

# Expected response:
# {"response": "Hello! I'm your AI assistant. How can I help you today?"}
```

**Metode 3: Python-testscript**
```python
# test_api.py - Create this file to test your API
import requests
import json

# Test the API endpoint
url = "http://localhost:5000/hello"
data = {"message": "Tell me a joke about programming"}

response = requests.post(url, json=data)
if response.status_code == 200:
    result = response.json()
    print("AI Response:", result['response'])
else:
    print("Error:", response.status_code, response.text)
```

#### Fejlfinding af almindelige opstartsproblemer

| Fejlmeddelelse | Hvad det betyder | S√•dan l√∏ser du det |
|----------------|------------------|--------------------|
| `ModuleNotFoundError: No module named 'fastapi'` | FastAPI er ikke installeret | K√∏r `pip install fastapi uvicorn` i din virtuelle milj√∏ |
| `ModuleNotFoundError: No module named 'uvicorn'` | ASGI-serveren er ikke installeret | K√∏r `pip install uvicorn` i din virtuelle milj√∏ |
| `KeyError: 'GITHUB_TOKEN'` | Milj√∏variabel ikke fundet | Tjek din `.env`-fil og `load_dotenv()`-kald |
| `Address already in use` | Port 5000 er optaget | Luk andre processer, der bruger port 5000, eller skift porten |
| `ValidationError` | Foresp√∏rgselsdata matcher ikke Pydantic-modellen | Tjek, om din foresp√∏rgselsformat matcher det forventede skema |
| `HTTPException 422` | Ubehandlingsbar enhed | Foresp√∏rgselsvalidering mislykkedes, tjek `/docs` for korrekt format |
| `OpenAI API error` | AI-tjenesteautentificering mislykkedes | Bekr√¶ft, at din GitHub-token er korrekt og har de n√∏dvendige tilladelser |

#### Bedste praksis for udvikling

**Automatisk genindl√¶sning**: FastAPI med Uvicorn tilbyder automatisk genindl√¶sning, n√•r du gemmer √¶ndringer i dine Python-filer. Det betyder, at du kan √¶ndre din kode og teste med det samme uden at genstarte manuelt.

```python
# Enable hot reloading explicitly
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, debug=True)  # debug=True enables hot reload
```

**Logning til udvikling**: Tilf√∏j logning for at forst√•, hvad der sker:

```python
import logging

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@app.route("/hello", methods=["POST"])
def hello():
    data = request.get_json()
    message = data.get("message", "")
    
    logger.info(f"Received message: {message}")
    
    if not message:
        logger.warning("Empty message received")
        return jsonify({"error": "Message field is required"}), 400
    
    try:
        response = call_llm(message, "You are a helpful and friendly assistant.")
        logger.info(f"AI response generated successfully")
        return jsonify({"response": response})
    except Exception as e:
        logger.error(f"AI API error: {str(e)}")
        return jsonify({"error": "AI service temporarily unavailable"}), 500
```

**Hvorfor logning hj√¶lper**: Under udvikling kan du se pr√¶cis, hvilke foresp√∏rgsler der kommer ind, hvad AI'en svarer med, og hvor fejl opst√•r. Det g√∏r fejlfinding meget hurtigere.

### Konfiguration til GitHub Codespaces: Cloud-udvikling gjort nemt

GitHub Codespaces er som at have en kraftfuld udviklingscomputer i skyen, som du kan tilg√• fra enhver browser. Hvis du arbejder i Codespaces, er der nogle ekstra trin for at g√∏re din backend tilg√¶ngelig for din frontend.

#### Forst√• Codespaces-netv√¶rk

I et lokalt udviklingsmilj√∏ k√∏rer alt p√• den samme computer:
- Backend: `http://localhost:5000`
- Frontend: `http://localhost:3000` (eller file://)

I Codespaces k√∏rer dit udviklingsmilj√∏ p√• GitHubs servere, s√• "localhost" har en anden betydning. GitHub opretter automatisk offentlige URL'er til dine tjenester, men du skal konfigurere dem korrekt.

#### Trin-for-trin Codespaces-konfiguration

**1. Start din backend-server**:
```bash
cd backend
python api.py
```

Du vil se den velkendte FastAPI/Uvicorn-opstartsbesked, men bem√¶rk, at den k√∏rer inde i Codespace-milj√∏et.

**2. Konfigurer portens synlighed**:
- Kig efter fanen "Ports" i den nederste panel i VS Code
- Find port 5000 p√• listen
- H√∏jreklik p√• port 5000
- V√¶lg "Port Visibility" ‚Üí "Public"

**Hvorfor g√∏re den offentlig?** Som standard er Codespace-porte private (kun tilg√¶ngelige for dig). Ved at g√∏re den offentlig kan din frontend (som k√∏rer i browseren) kommunikere med din backend.

**3. F√• din offentlige URL**:
Efter at have gjort porten offentlig, vil du se en URL som:
```
https://your-codespace-name-5000.app.github.dev
```

**4. Opdater din frontend-konfiguration**:
```javascript
// In your frontend app.js, update the BASE_URL:
this.BASE_URL = "https://your-codespace-name-5000.app.github.dev";
```

#### Forst√• Codespace-URL'er

Codespace-URL'er f√∏lger et forudsigeligt m√∏nster:
```
https://[codespace-name]-[port].app.github.dev
```

**Forklaring**:
- `codespace-name`: En unik identifikator for din Codespace (inkluderer normalt dit brugernavn)
- `port`: Portnummeret din tjeneste k√∏rer p√• (5000 for vores FastAPI-app)
- `app.github.dev`: GitHubs dom√¶ne for Codespace-applikationer

#### Test din Codespace-ops√¶tning

**1. Test backend direkte**:
√Öbn din offentlige URL i en ny browserfane. Du b√∏r se:
```
Welcome to the AI Chat API. Send POST requests to /hello with JSON payload containing 'message' field.
```

**2. Test med browserens udviklerv√¶rkt√∏jer**:
```javascript
// Open browser console and test your API
fetch('https://your-codespace-name-5000.app.github.dev/hello', {
  method: 'POST',
  headers: {'Content-Type': 'application/json'},
  body: JSON.stringify({message: 'Hello from Codespaces!'})
})
.then(response => response.json())
.then(data => console.log(data));
```

#### Codespaces vs Lokal Udvikling

| Aspekt | Lokal Udvikling | GitHub Codespaces |
|--------|-----------------|-------------------|
| **Ops√¶tningstid** | L√¶ngere (install√©r Python, afh√¶ngigheder) | √òjeblikkelig (forudkonfigureret milj√∏) |
| **URL-adgang** | `http://localhost:5000` | `https://xyz-5000.app.github.dev` |
| **Portkonfiguration** | Automatisk | Manuel (g√∏r porte offentlige) |
| **Filpersistens** | Lokal maskine | GitHub-repository |
| **Samarbejde** | Sv√¶rt at dele milj√∏ | Nem at dele Codespace-link |
| **Internetafh√¶ngighed** | Kun for AI API-kald | N√∏dvendigt for alt |

#### Tips til udvikling i Codespaces

**Milj√∏variabler i Codespaces**:
Din `.env`-fil fungerer p√• samme m√•de i Codespaces, men du kan ogs√• indstille milj√∏variabler direkte i Codespace:

```bash
# Set environment variable for the current session
export GITHUB_TOKEN="your_token_here"

# Or add to your .bashrc for persistence
echo 'export GITHUB_TOKEN="your_token_here"' >> ~/.bashrc
```

**Porth√•ndtering**:
- Codespaces registrerer automatisk, n√•r din applikation begynder at lytte p√• en port
- Du kan videresende flere porte samtidigt (nyttigt, hvis du senere tilf√∏jer en database)
- Porte forbliver tilg√¶ngelige, s√• l√¶nge din Codespace k√∏rer

**Udviklingsworkflow**:
1. Lav kode√¶ndringer i VS Code
2. FastAPI genindl√¶ser automatisk (takket v√¶re Uvicorns genindl√¶sningsfunktion)
3. Test √¶ndringer med det samme via den offentlige URL
4. Commit og push, n√•r du er klar

> üí° **Pro Tip**: Bogm√¶rk din Codespace backend-URL under udvikling. Da Codespace-navne er stabile, √¶ndrer URL'en sig ikke, s√• l√¶nge du bruger den samme Codespace.

## Oprettelse af frontend-chatgr√¶nsefladen: Hvor mennesker m√∏der AI

Nu skal vi bygge brugergr√¶nsefladen ‚Äì den del, der bestemmer, hvordan folk interagerer med din AI-assistent. Ligesom designet af den originale iPhone-gr√¶nseflade fokuserer vi p√• at g√∏re kompleks teknologi intuitiv og nem at bruge.

### Forst√• moderne frontend-arkitektur

Vores chatgr√¶nseflade vil v√¶re det, vi kalder en "Single Page Application" eller SPA. I stedet for den gammeldags tilgang, hvor hvert klik indl√¶ser en ny side, opdaterer vores app glat og √∏jeblikkeligt:

**Gamle hjemmesider**: Som at l√¶se en fysisk bog ‚Äì du bladrer til helt nye sider
**Vores chat-app**: Som at bruge din telefon ‚Äì alt flyder og opdateres problemfrit

```mermaid
graph TD
    A[User Types Message] --> B[JavaScript Captures Input]
    B --> C[Validate & Format Data]
    C --> D[Send to Backend API]
    D --> E[Display Loading State]
    E --> F[Receive AI Response]
    F --> G[Update Chat Interface]
    G --> H[Ready for Next Message]
```

### De tre s√∏jler i frontend-udvikling

Hver frontend-applikation ‚Äì fra simple hjemmesider til komplekse apps som Discord eller Slack ‚Äì er bygget p√• tre kerne-teknologier. T√¶nk p√• dem som fundamentet for alt, hvad du ser og interagerer med p√• nettet:

**HTML (Struktur)**: Dette er dit fundament
- Bestemmer, hvilke elementer der findes (knapper, tekstfelter, containere)
- Giver mening til indhold (dette er en overskrift, dette er en formular osv.)
- Skaber den grundl√¶ggende struktur, som alt andet bygger p√•

**CSS (Pr√¶sentation)**: Dette er din indretningsarkitekt
- F√•r alt til at se smukt ud (farver, skrifttyper, layouts)
- H√•ndterer forskellige sk√¶rmst√∏rrelser (telefon vs laptop vs tablet)
- Skaber glatte animationer og visuel feedback

**JavaScript (Adf√¶rd)**: Dette er din hjerne
- Reagerer p√•, hvad brugerne g√∏r (klik, indtastning, scrolling)
- Kommunikerer med din backend og opdaterer siden
- G√∏r alt interaktivt og dynamisk

**T√¶nk p√• det som arkitektonisk design:**
- **HTML**: Den strukturelle plan (definerer rum og relationer)
- **CSS**: Den √¶stetiske og milj√∏m√¶ssige design (visuel stil og brugeroplevelse)
- **JavaScript**: De mekaniske systemer (funktionalitet og interaktivitet)

### Hvorfor moderne JavaScript-arkitektur er vigtig

Vores chatapplikation vil bruge moderne JavaScript-m√∏nstre, som du vil se i professionelle applikationer. At forst√• disse koncepter vil hj√¶lpe dig med at vokse som udvikler:

**Klassebaseret arkitektur**: Vi organiserer vores kode i klasser, som er som at skabe bl√•tryk for objekter
**Async/Await**: Moderne m√•de at h√•ndtere operationer, der tager tid (som API-kald)
**Event-drevet programmering**: Vores app reagerer p√• brugerhandlinger (klik, tastetryk) i stedet for at k√∏re i en l√∏kke
**DOM-manipulation**: Dynamisk opdatering af websideindhold baseret p√• brugerinteraktioner og API-svar

### Projektstruktur-ops√¶tning

Opret en frontend-mappe med denne organiserede struktur:

```text
frontend/
‚îú‚îÄ‚îÄ index.html      # Main HTML structure
‚îú‚îÄ‚îÄ app.js          # JavaScript functionality
‚îî‚îÄ‚îÄ styles.css      # Visual styling
```

**Forst√• arkitekturen:**
- **Adskiller** bekymringer mellem struktur (HTML), adf√¶rd (JavaScript) og pr√¶sentation (CSS)
- **Bevarer** en simpel filstruktur, der er nem at navigere og √¶ndre
- **F√∏lger** bedste praksis for webudvikling med hensyn til organisation og vedligeholdelse

### Byg HTML-fundamentet: Semantisk struktur for tilg√¶ngelighed

Lad os starte med HTML-strukturen. Moderne webudvikling l√¶gger v√¶gt p√• "semantisk HTML" ‚Äì brug af HTML-elementer, der tydeligt beskriver deres form√•l, ikke kun deres udseende. Dette g√∏r din applikation tilg√¶ngelig for sk√¶rml√¶sere, s√∏gemaskiner og andre v√¶rkt√∏jer.

**Hvorfor semantisk HTML er vigtigt**: Forestil dig at beskrive din chat-app til nogen over telefonen. Du ville sige "der er en header med titlen, et hovedomr√•de, hvor samtaler vises, og en formular nederst til at skrive beskeder." Semantisk HTML bruger elementer, der matcher denne naturlige beskrivelse.

Opret `index.html` med denne gennemt√¶nkte struktur:

```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Chat Assistant</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="chat-container">
        <header class="chat-header">
            <h1>AI Chat Assistant</h1>
            <p>Ask me anything!</p>
        </header>
        
        <main class="chat-messages" id="messages" role="log" aria-live="polite">
            <!-- Messages will be dynamically added here -->
        </main>
        
        <form class="chat-form" id="chatForm">
            <div class="input-group">
                <input 
                    type="text" 
                    id="messageInput" 
                    placeholder="Type your message here..." 
                    required
                    aria-label="Chat message input"
                >
                <button type="submit" id="sendBtn" aria-label="Send message">
                    Send
                </button>
            </div>
        </form>
    </div>
    <script src="app.js"></script>
</body>
</html>
```

**Forst√• hvert HTML-element og dets form√•l:**

#### Dokumentstruktur
- **`<!DOCTYPE html>`**: Fort√¶ller browseren, at dette er moderne HTML5
- **`<html lang="en">`**: Angiver sidens sprog for sk√¶rml√¶sere og overs√¶ttelsesv√¶rkt√∏jer
- **`<meta charset="UTF-8">`**: Sikrer korrekt tegnkodning for international tekst
- **`<meta name="viewport"...>`**: G√∏r siden mobilresponsiv ved at kontrollere zoom og skala

#### Semantiske elementer
- **`<header>`**: Identificerer tydeligt den √∏verste sektion med titel og beskrivelse
- **`<main>`**: Angiver det prim√¶re indholdsomr√•de (hvor samtaler foreg√•r)
- **`<form>`**: Semantisk korrekt til brugerinput, muligg√∏r korrekt tastaturnavigation

#### Tilg√¶ngelighedsfunktioner
- **`role="log"`**: Fort√¶ller sk√¶rml√¶sere, at dette omr√•de indeholder en kronologisk log af beskeder
- **`aria-live="polite"`**: Annoncerer nye beskeder til sk√¶rml√¶sere uden at afbryde
- **`aria-label`**: Giver beskrivende etiketter til formularkontroller
- **`required`**: Browseren validerer, at brugerne indtaster en besked, f√∏r de sender

#### CSS og JavaScript-integration
- **`class`-attributter**: Giver styling-hooks til CSS (f.eks. `chat-container`, `input-group`)
- **`id`-attributter**: Tillader JavaScript at finde og manipulere specifikke elementer
- **Scriptplacering**: JavaScript-fil indl√¶ses til sidst, s√• HTML indl√¶ses f√∏rst

**Hvorfor denne struktur fungerer:**
- **Logisk flow**: Header ‚Üí Hovedindhold ‚Üí Inputformular matcher naturlig l√¶ser√¶kkef√∏lge
- **Tastaturtilg√¶ngelig**: Brugere kan navigere gennem alle interaktive elementer med tabulator
- **Sk√¶rml√¶servenlig**: Klare landem√¶rker og beskrivelser for synshandicappede brugere
- **Mobilresponsiv**: Viewport-meta-tag muligg√∏r responsivt design
- **Progressiv forbedring**: Fungerer selv hvis CSS eller JavaScript ikke indl√¶ses

### Tilf√∏j interaktiv JavaScript: Moderne webapplikationslogik

Nu skal vi bygge JavaScript, der bringer vores chatgr√¶nseflade til live. Vi bruger moderne JavaScript-m√∏nstre, som du vil st√∏de p√• i professionel webudvikling, herunder ES6-klasser, async/await og event-drevet programmering.

#### Forst√• moderne JavaScript-arkitektur

I stedet for at skrive procedurekode (en r√¶kke funktioner, der k√∏rer i r√¶kkef√∏lge), opretter vi en **klassebaseret arkitektur**. T√¶nk p√• en klasse som en bl√•tryk til at skabe objekter ‚Äì ligesom en arkitekts bl√•tryk kan bruges til at bygge flere huse.

**Hvorfor bruge klasser til webapplikationer?**
- **Organisation**: Al relateret funktionalitet er samlet
- **Genanvendelighed**: Du kunne oprette flere chatinstanser p√• samme side
- **Vedligeholdelse**: Nem at fejlfinde og √¶ndre specifikke funktioner
- **Professionel standard**: Dette m√∏nster bruges i frameworks som React, Vue og Angular

Opret `app.js` med denne moderne, velstrukturerede JavaScript:

```javascript
// app.js - Modern chat application logic

class ChatApp {
    constructor() {
        // Get references to DOM elements we'll need to manipulate
        this.messages = document.getElementById("messages");
        this.form = document.getElementById("chatForm");
        this.input = document.getElementById("messageInput");
        this.sendButton = document.getElementById("sendBtn");
        
        // Configure your backend URL here
        this.BASE_URL = "http://localhost:5000"; // Update this for your environment
        this.API_ENDPOINT = `${this.BASE_URL}/hello`;
        
        // Set up event listeners when the chat app is created
        this.initializeEventListeners();
    }
    
    initializeEventListeners() {
        // Listen for form submission (when user clicks Send or presses Enter)
        this.form.addEventListener("submit", (e) => this.handleSubmit(e));
        
        // Also listen for Enter key in the input field (better UX)
        this.input.addEventListener("keypress", (e) => {
            if (e.key === "Enter" && !e.shiftKey) {
                e.preventDefault();
                this.handleSubmit(e);
            }
        });
    }
    
    async handleSubmit(event) {
        event.preventDefault(); // Prevent form from refreshing the page
        
        const messageText = this.input.value.trim();
        if (!messageText) return; // Don't send empty messages
        
        // Provide user feedback that something is happening
        this.setLoading(true);
        
        // Add user message to chat immediately (optimistic UI)
        this.appendMessage(messageText, "user");
        
        // Clear input field so user can type next message
        this.input.value = '';
        
        try {
            // Call the AI API and wait for response
            const reply = await this.callAPI(messageText);
            
            // Add AI response to chat
            this.appendMessage(reply, "assistant");
        } catch (error) {
            console.error('API Error:', error);
            this.appendMessage("Sorry, I'm having trouble connecting right now. Please try again.", "error");
        } finally {
            // Re-enable the interface regardless of success or failure
            this.setLoading(false);
        }
    }
    
    async callAPI(message) {
        const response = await fetch(this.API_ENDPOINT, {
            method: "POST",
            headers: { 
                "Content-Type": "application/json" 
            },
            body: JSON.stringify({ message })
        });
        
        if (!response.ok) {
            throw new Error(`HTTP error! status: ${response.status}`);
        }
        
        const data = await response.json();
        return data.response;
    }
    
    appendMessage(text, role) {
        const messageElement = document.createElement("div");
        messageElement.className = `message ${role}`;
        messageElement.innerHTML = `
            <div class="message-content">
                <span class="message-text">${this.escapeHtml(text)}</span>
                <span class="message-time">${new Date().toLocaleTimeString()}</span>
            </div>
        `;
        
        this.messages.appendChild(messageElement);
        this.scrollToBottom();
    }
    
    escapeHtml(text) {
        const div = document.createElement('div');
        div.textContent = text;
        return div.innerHTML;
    }
    
    scrollToBottom() {
        this.messages.scrollTop = this.messages.scrollHeight;
    }
    
    setLoading(isLoading) {
        this.sendButton.disabled = isLoading;
        this.input.disabled = isLoading;
        this.sendButton.textContent = isLoading ? "Sending..." : "Send";
    }
}

// Initialize the chat application when the page loads
document.addEventListener("DOMContentLoaded", () => {
    new ChatApp();
});
```

#### Forst√• hver JavaScript-koncept

**ES6-klasse-struktur**:
```javascript
class ChatApp {
    constructor() {
        // This runs when you create a new ChatApp instance
        // It's like the "setup" function for your chat
    }
    
    methodName() {
        // Methods are functions that belong to the class
        // They can access class properties using "this"
    }
}
```

**Async/Await-m√∏nster**:
```javascript
// Old way (callback hell):
fetch(url)
  .then(response => response.json())
  .then(data => console.log(data))
  .catch(error => console.error(error));

// Modern way (async/await):
try {
    const response = await fetch(url);
    const data = await response.json();
    console.log(data);
} catch (error) {
    console.error(error);
}
```

**Event-drevet programmering**:
I stedet for konstant at tjekke, om noget er sket, "lytter" vi efter begivenheder:
```javascript
// When form is submitted, run handleSubmit
this.form.addEventListener("submit", (e) => this.handleSubmit(e));

// When Enter key is pressed, also run handleSubmit
this.input.addEventListener("keypress", (e) => { /* ... */ });
```

**DOM-manipulation**:
```javascript
// Create new elements
const messageElement = document.createElement("div");

// Modify their properties
messageElement.className = "message user";
messageElement.innerHTML = "Hello world!";

// Add to the page
this.messages.appendChild(messageElement);
```

#### Sikkerhed og bedste praksis

**Forebyggelse af XSS**:
```javascript
escapeHtml(text) {
    const div = document.createElement('div');
    div.textContent = text;  // This automatically escapes HTML
    return div.innerHTML;
}
```

**Hvorfor dette er vigtigt**: Hvis en bruger skriver `<script>alert('hack')</script>`, sikrer denne funktion, at det vises som tekst i stedet for at blive udf√∏rt som kode.

**Fejlh√•ndtering**:
```javascript
try {
    const reply = await this.callAPI(messageText);
    this.appendMessage(reply, "assistant");
} catch (error) {
    // Show user-friendly error instead of breaking the app
    this.appendMessage("Sorry, I'm having trouble...", "error");
}
```

**Overvejelser om brugeroplevelse**:
- **Optimistisk UI**: Tilf√∏j brugerbesked med det samme, vent ikke p√• serverens svar
- **Indl√¶sningsstatus**: Deaktiver knapper og vis "Sender..." mens du venter
- **Auto-scroll**: Hold de nyeste beskeder synlige
- **Inputvalidering**: Send ikke tomme beskeder
- **Tastaturgenveje**: Enter-tasten sender beskeder (som rigtige chat-apps)

#### Forst√• applikationsflowet

1. **Siden indl√¶ses** ‚Üí `DOMContentLoaded`-begivenhed udl√∏ses ‚Üí `new ChatApp()` oprettes
2. **Konstrukt√∏r k√∏rer** ‚Üí F√•r DOM-elementreferencer ‚Üí Ops√¶tter begivenhedslyttere
3. **Bruger skriver besked** ‚Üí Trykker Enter eller klikker Send ‚Üí `handleSubmit` k√∏rer
4. **handleSubmit** ‚Üí Validerer input ‚Üí Viser indl√¶sningsstatus ‚Üí Kalder API
5. **API svarer** ‚Üí Tilf√∏jer AI-besked til chat ‚Üí Genaktiverer gr√¶nsefladen
6. **Klar til n√¶ste besked** ‚Üí Brugeren kan forts√¶tte med at chatte
Denne arkitektur er skalerbar ‚Äì du kan nemt tilf√∏je funktioner som redigering af beskeder, filuploads eller flere samtaletr√•de uden at skulle omskrive den grundl√¶ggende struktur.

### Styling din chatgr√¶nseflade

Lad os nu skabe en moderne og visuelt tiltalende chatgr√¶nseflade med CSS. God styling f√•r din applikation til at f√∏les professionel og forbedrer den samlede brugeroplevelse. Vi vil bruge moderne CSS-funktioner som Flexbox, CSS Grid og brugerdefinerede egenskaber for et responsivt og tilg√¶ngeligt design.

Opret `styles.css` med disse omfattende styles:

```css
/* styles.css - Modern chat interface styling */

:root {
    --primary-color: #2563eb;
    --secondary-color: #f1f5f9;
    --user-color: #3b82f6;
    --assistant-color: #6b7280;
    --error-color: #ef4444;
    --text-primary: #1e293b;
    --text-secondary: #64748b;
    --border-radius: 12px;
    --shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
}

* {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
}

body {
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    min-height: 100vh;
    display: flex;
    align-items: center;
    justify-content: center;
    padding: 20px;
}

.chat-container {
    width: 100%;
    max-width: 800px;
    height: 600px;
    background: white;
    border-radius: var(--border-radius);
    box-shadow: var(--shadow);
    display: flex;
    flex-direction: column;
    overflow: hidden;
}

.chat-header {
    background: var(--primary-color);
    color: white;
    padding: 20px;
    text-align: center;
}

.chat-header h1 {
    font-size: 1.5rem;
    margin-bottom: 5px;
}

.chat-header p {
    opacity: 0.9;
    font-size: 0.9rem;
}

.chat-messages {
    flex: 1;
    padding: 20px;
    overflow-y: auto;
    display: flex;
    flex-direction: column;
    gap: 15px;
    background: var(--secondary-color);
}

.message {
    display: flex;
    max-width: 80%;
    animation: slideIn 0.3s ease-out;
}

.message.user {
    align-self: flex-end;
}

.message.user .message-content {
    background: var(--user-color);
    color: white;
    border-radius: var(--border-radius) var(--border-radius) 4px var(--border-radius);
}

.message.assistant {
    align-self: flex-start;
}

.message.assistant .message-content {
    background: white;
    color: var(--text-primary);
    border-radius: var(--border-radius) var(--border-radius) var(--border-radius) 4px;
    border: 1px solid #e2e8f0;
}

.message.error .message-content {
    background: var(--error-color);
    color: white;
    border-radius: var(--border-radius);
}

.message-content {
    padding: 12px 16px;
    box-shadow: var(--shadow);
    position: relative;
}

.message-text {
    display: block;
    line-height: 1.5;
    word-wrap: break-word;
}

.message-time {
    display: block;
    font-size: 0.75rem;
    opacity: 0.7;
    margin-top: 5px;
}

.chat-form {
    padding: 20px;
    border-top: 1px solid #e2e8f0;
    background: white;
}

.input-group {
    display: flex;
    gap: 10px;
    align-items: center;
}

#messageInput {
    flex: 1;
    padding: 12px 16px;
    border: 2px solid #e2e8f0;
    border-radius: var(--border-radius);
    font-size: 1rem;
    outline: none;
    transition: border-color 0.2s ease;
}

#messageInput:focus {
    border-color: var(--primary-color);
}

#messageInput:disabled {
    background: #f8fafc;
    opacity: 0.6;
    cursor: not-allowed;
}

#sendBtn {
    padding: 12px 24px;
    background: var(--primary-color);
    color: white;
    border: none;
    border-radius: var(--border-radius);
    font-size: 1rem;
    font-weight: 600;
    cursor: pointer;
    transition: background-color 0.2s ease;
    min-width: 80px;
}

#sendBtn:hover:not(:disabled) {
    background: #1d4ed8;
}

#sendBtn:disabled {
    background: #94a3b8;
    cursor: not-allowed;
}

@keyframes slideIn {
    from {
        opacity: 0;
        transform: translateY(10px);
    }
    to {
        opacity: 1;
        transform: translateY(0);
    }
}

/* Responsive design for mobile devices */
@media (max-width: 768px) {
    body {
        padding: 10px;
    }
    
    .chat-container {
        height: calc(100vh - 20px);
        border-radius: 8px;
    }
    
    .message {
        max-width: 90%;
    }
    
    .input-group {
        flex-direction: column;
        gap: 10px;
    }
    
    #messageInput {
        width: 100%;
    }
    
    #sendBtn {
        width: 100%;
    }
}

/* Accessibility improvements */
@media (prefers-reduced-motion: reduce) {
    .message {
        animation: none;
    }
    
    * {
        transition: none !important;
    }
}

/* Dark mode support */
@media (prefers-color-scheme: dark) {
    .chat-container {
        background: #1e293b;
        color: #f1f5f9;
    }
    
    .chat-messages {
        background: #0f172a;
    }
    
    .message.assistant .message-content {
        background: #334155;
        color: #f1f5f9;
        border-color: #475569;
    }
    
    .chat-form {
        background: #1e293b;
        border-color: #475569;
    }
    
    #messageInput {
        background: #334155;
        color: #f1f5f9;
        border-color: #475569;
    }
}
```

**Forst√•else af CSS-arkitekturen:**
- **Bruger** CSS-brugerdefinerede egenskaber (variabler) for konsistent tema og nem vedligeholdelse
- **Implementerer** Flexbox-layout for responsivt design og korrekt justering
- **Inkluderer** glidende animationer for beskedvisning uden at v√¶re distraherende
- **Giver** visuel forskel mellem brugerbeskeder, AI-svar og fejltilstande
- **Underst√∏tter** responsivt design, der fungerer b√•de p√• desktop og mobile enheder
- **Tager hensyn til** tilg√¶ngelighed med reducerede bev√¶gelsespr√¶ferencer og korrekte kontrastforhold
- **Tilbyder** m√∏rk tilstand baseret p√• brugerens systempr√¶ferencer

### Konfiguration af din backend-URL

Det sidste trin er at opdatere `BASE_URL` i din JavaScript, s√• den matcher din backend-server:

```javascript
// For local development
this.BASE_URL = "http://localhost:5000";

// For GitHub Codespaces (replace with your actual URL)
this.BASE_URL = "https://your-codespace-name-5000.app.github.dev";
```

**Bestemmelse af din backend-URL:**
- **Lokal udvikling**: Brug `http://localhost:5000`, hvis du k√∏rer b√•de frontend og backend lokalt
- **Codespaces**: Find din backend-URL i fanen Ports, efter du har gjort port 5000 offentlig
- **Produktion**: Erstat med dit faktiske dom√¶ne, n√•r du deployer til en hostingtjeneste

> üí° **Testtip**: Du kan teste din backend direkte ved at bes√∏ge root-URL'en i din browser. Du b√∏r se velkomstbeskeden fra din FastAPI-server.

## Test og deployment

Nu hvor du har bygget b√•de frontend- og backend-komponenter, lad os teste, at alt fungerer sammen og udforske deployment-muligheder for at dele din chatassistent med andre.

### Lokal testarbejdsgang

F√∏lg disse trin for at teste din komplette applikation:

```mermaid
graph TD
    A[Start Backend Server] --> B[Configure Environment Variables]
    B --> C[Test API Endpoints]
    C --> D[Open Frontend in Browser]
    D --> E[Test Chat Functionality]
    E --> F[Debug Any Issues]
```

**Trin-for-trin testproces:**

1. **Start din backend-server**:
   ```bash
   cd backend
   source venv/bin/activate  # or venv\Scripts\activate on Windows
   python api.py
   ```

2. **Bekr√¶ft, at API'en fungerer**:
   - √Öbn `http://localhost:5000` i din browser
   - Du b√∏r se velkomstbeskeden fra din FastAPI-server

3. **√Öbn din frontend**:
   - Naviger til din frontend-mappe
   - √Öbn `index.html` i din webbrowser
   - Eller brug VS Codes Live Server-udvidelse for en bedre udviklingsoplevelse

4. **Test chatfunktionen**:
   - Skriv en besked i inputfeltet
   - Klik p√• "Send" eller tryk Enter
   - Bekr√¶ft, at AI'en svarer korrekt
   - Tjek browserkonsollen for eventuelle JavaScript-fejl

### Fejlfinding af almindelige problemer

| Problem | Symptomer | L√∏sning |
|---------|----------|----------|
| **CORS-fejl** | Frontend kan ikke n√• backend | S√∏rg for, at FastAPI CORSMiddleware er korrekt konfigureret |
| **API-n√∏glefejl** | 401 Uautoriserede svar | Tjek din `GITHUB_TOKEN` milj√∏variabel |
| **Forbindelse n√¶gtet** | Netv√¶rksfejl i frontend | Bekr√¶ft backend-URL og at Flask-serveren k√∏rer |
| **Ingen AI-svar** | Tomme eller fejlbeskeder | Tjek backend-logfiler for API-kvote eller autentificeringsproblemer |

**Almindelige fejls√∏gningsskridt:**
- **Tjekker** browserens Developer Tools Console for JavaScript-fejl
- **Bekr√¶fter** at Network-fanen viser succesfulde API-anmodninger og svar
- **Gennemg√•r** backend-terminaloutput for Python-fejl eller API-problemer
- **Bekr√¶fter** at milj√∏variabler er korrekt indl√¶st og tilg√¶ngelige

## GitHub Copilot Agent Challenge üöÄ

Brug Agent-tilstand til at fuldf√∏re f√∏lgende udfordring:

**Beskrivelse:** Forbedr chatassistenten ved at tilf√∏je samtalehistorik og beskedpersistens. Denne udfordring vil hj√¶lpe dig med at forst√•, hvordan man h√•ndterer tilstand i chatapplikationer og implementerer datalagring for bedre brugeroplevelse.

**Opgave:** Modificer chatapplikationen til at inkludere samtalehistorik, der bevares mellem sessioner. Tilf√∏j funktionalitet til at gemme chatbeskeder i lokal lagring, vise samtalehistorik, n√•r siden indl√¶ses, og inkluder en "Ryd historik"-knap. Implementer ogs√• skriveindikatorer og tidsstempler for beskeder for at g√∏re chatteoplevelsen mere realistisk.

L√¶s mere om [agent mode](https://code.visualstudio.com/blogs/2025/02/24/introducing-copilot-agent-mode) her.

## Opgave: Byg din personlige AI-assistent

Nu skal du skabe din egen AI-assistent-implementering. I stedet for blot at kopiere tutorial-koden er dette en mulighed for at anvende koncepterne, mens du bygger noget, der afspejler dine egne interesser og anvendelsesomr√•der.

### Projektkrav

Lad os ops√¶tte dit projekt med en ren, organiseret struktur:

```text
my-ai-assistant/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ api.py          # Your FastAPI server
‚îÇ   ‚îú‚îÄ‚îÄ llm.py          # AI integration functions
‚îÇ   ‚îú‚îÄ‚îÄ .env            # Your secrets (keep this safe!)
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt # Python dependencies
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ index.html      # Your chat interface
‚îÇ   ‚îú‚îÄ‚îÄ app.js          # The JavaScript magic
‚îÇ   ‚îî‚îÄ‚îÄ styles.css      # Make it look amazing
‚îî‚îÄ‚îÄ README.md           # Tell the world about your creation
```

### Kerneimplementeringsopgaver

**Backend-udvikling:**
- **Tag** vores FastAPI-kode og g√∏r den til din egen
- **Skab** en unik AI-personlighed ‚Äì m√•ske en hj√¶lpsom madlavningsassistent, en kreativ skrivepartner eller en studieven?
- **Tilf√∏j** solid fejlh√•ndtering, s√• din app ikke g√•r ned, n√•r tingene g√•r galt
- **Skriv** klar dokumentation for alle, der √∏nsker at forst√•, hvordan din API fungerer

**Frontend-udvikling:**
- **Byg** en chatgr√¶nseflade, der f√∏les intuitiv og indbydende
- **Skriv** ren, moderne JavaScript, som du ville v√¶re stolt af at vise andre udviklere
- **Design** brugerdefineret styling, der afspejler din AI's personlighed ‚Äì sjov og farverig? Ren og minimalistisk? Det er helt op til dig!
- **S√∏rg for** at det fungerer godt b√•de p√• telefoner og computere

**Personaliseringskrav:**
- **V√¶lg** et unikt navn og en personlighed til din AI-assistent ‚Äì m√•ske noget, der afspejler dine interesser eller de problemer, du vil l√∏se
- **Tilpas** det visuelle design, s√• det matcher din assistents stil
- **Skriv** en f√¶ngende velkomstbesked, der f√•r folk til at starte en samtale
- **Test** din assistent med forskellige typer sp√∏rgsm√•l for at se, hvordan den reagerer

### Forbedringsid√©er (valgfrit)

Vil du tage dit projekt til n√¶ste niveau? Her er nogle sjove id√©er at udforske:

| Funktion | Beskrivelse | F√¶rdigheder du vil √∏ve |
|---------|-------------|------------------------|
| **Beskedhistorik** | Husk samtaler selv efter sideopdatering | Arbejde med localStorage, JSON-h√•ndtering |
| **Skriveindikatorer** | Vis "AI skriver..." mens du venter p√• svar | CSS-animationer, asynkron programmering |
| **Besked-tidsstempler** | Vis, hvorn√•r hver besked blev sendt | Dato/tid-formattering, UX-design |
| **Eksport af chat** | Lad brugere downloade deres samtale | Filh√•ndtering, dataeksport |
| **Tema-skift** | Skift mellem lys/m√∏rk tilstand | CSS-variabler, brugerpr√¶ferencer |
| **Steminput** | Tilf√∏j tale-til-tekst funktionalitet | Web-API'er, tilg√¶ngelighed |

### Test og dokumentation

**Kvalitetssikring:**
- **Test** din applikation med forskellige inputtyper og kanttilf√¶lde
- **Bekr√¶ft** responsivt design fungerer p√• forskellige sk√¶rmst√∏rrelser
- **Tjek** tilg√¶ngelighed med tastaturnavigation og sk√¶rml√¶sere
- **Valider** HTML og CSS for standardoverholdelse

**Dokumentationskrav:**
- **Skriv** en README.md, der forklarer dit projekt og hvordan man k√∏rer det
- **Inkluder** sk√¶rmbilleder af din chatgr√¶nseflade i aktion
- **Dokumenter** eventuelle unikke funktioner eller tilpasninger, du har tilf√∏jet
- **Giv** klare installationsinstruktioner til andre udviklere

### Indsendelsesretningslinjer

**Projektleverancer:**
1. Komplet projektmappe med al kildekode
2. README.md med projektbeskrivelse og installationsinstruktioner
3. Sk√¶rmbilleder, der viser din chatassistent i aktion
4. Kort refleksion over, hvad du har l√¶rt, og hvilke udfordringer du har st√•et overfor

**Evalueringskriterier:**
- **Funktionalitet**: Fungerer chatassistenten som forventet?
- **Kodekvalitet**: Er koden velorganiseret, kommenteret og vedligeholdelsesvenlig?
- **Design**: Er gr√¶nsefladen visuelt tiltalende og brugervenlig?
- **Kreativitet**: Hvor unik og personlig er din implementering?
- **Dokumentation**: Er installationsinstruktionerne klare og komplette?

> üí° **Succes-tip**: Start med de grundl√¶ggende krav f√∏rst, og tilf√∏j forbedringer, n√•r alt fungerer. Fokuser p√• at skabe en poleret kerneoplevelse, f√∏r du tilf√∏jer avancerede funktioner.

## L√∏sning

[L√∏sning](./solution/README.md)

## Bonusudfordringer

Klar til at tage din AI-assistent til n√¶ste niveau? Pr√∏v disse avancerede udfordringer, der vil uddybe din forst√•else af AI-integration og webudvikling.

### Personlighedstilpasning

Den virkelige magi sker, n√•r du giver din AI-assistent en unik personlighed. Eksperimenter med forskellige systemprompter for at skabe specialiserede assistenter:

**Eksempel p√• professionel assistent:**
```python
call_llm(message, "You are a professional business consultant with 20 years of experience. Provide structured, actionable advice with specific steps and considerations.")
```

**Eksempel p√• kreativ skrivehj√¶lper:**
```python
call_llm(message, "You are an enthusiastic creative writing coach. Help users develop their storytelling skills with imaginative prompts and constructive feedback.")
```

**Eksempel p√• teknisk mentor:**
```python
call_llm(message, "You are a patient senior developer who explains complex programming concepts using simple analogies and practical examples.")
```

### Frontend-forbedringer

Transform√©r din chatgr√¶nseflade med disse visuelle og funktionelle forbedringer:

**Avancerede CSS-funktioner:**
- **Implementer** glidende beskedsanimationer og overgange
- **Tilf√∏j** brugerdefinerede chatboble-designs med CSS-former og gradienter
- **Skab** en skriveindikator-animation til, n√•r AI'en "t√¶nker"
- **Design** emoji-reaktioner eller et beskedvurderingssystem

**JavaScript-forbedringer:**
- **Tilf√∏j** tastaturgenveje (Ctrl+Enter for at sende, Escape for at rydde input)
- **Implementer** beskeds√∏gning og filtreringsfunktionalitet
- **Skab** en samtaleeksportfunktion (download som tekst eller JSON)
- **Tilf√∏j** automatisk lagring til localStorage for at forhindre tab af beskeder

### Avanceret AI-integration

**Flere AI-personligheder:**
- **Skab** en dropdown-menu til at skifte mellem forskellige AI-personligheder
- **Gem** brugerens foretrukne personlighed i localStorage
- **Implementer** kontekstskift, der opretholder samtaleflowet

**Smart svarfunktioner:**
- **Tilf√∏j** samtalekontekstbevidsthed (AI husker tidligere beskeder)
- **Implementer** smarte forslag baseret p√• samtaleemne
- **Skab** hurtige svarknapper til almindelige sp√∏rgsm√•l

> üéØ **L√¶ringsm√•l**: Disse bonusudfordringer hj√¶lper dig med at forst√• avancerede webudviklingsm√∏nstre og AI-integrationsteknikker, der bruges i produktionsapplikationer.

## Opsummering og n√¶ste skridt

Tillykke! Du har med succes bygget en komplet AI-drevet chatassistent fra bunden. Dette projekt har givet dig praktisk erfaring med moderne webudviklingsteknologier og AI-integration ‚Äì f√¶rdigheder, der er stadig mere v√¶rdifulde i dagens teknologilandskab.

### Hvad du har opn√•et

Gennem denne lektion har du mestret flere n√∏gleteknologier og -koncepter:

**Backend-udvikling:**
- **Integreret** med GitHub Models API for AI-funktionalitet
- **Bygget** en RESTful API med Flask med korrekt fejlh√•ndtering
- **Implementeret** sikker autentificering ved hj√¶lp af milj√∏variabler
- **Konfigureret** CORS for cross-origin-anmodninger mellem frontend og backend

**Frontend-udvikling:**
- **Skabt** en responsiv chatgr√¶nseflade med semantisk HTML
- **Implementeret** moderne JavaScript med async/await og klassebaseret arkitektur
- **Designet** en engagerende brugergr√¶nseflade med CSS Grid, Flexbox og animationer
- **Tilf√∏jet** tilg√¶ngelighedsfunktioner og principper for responsivt design

**Full-stack integration:**
- **Forbundet** frontend og backend gennem HTTP API-anmodninger
- **H√•ndteret** realtidsbrugerinteraktioner og asynkron dataflow
- **Implementeret** fejlh√•ndtering og brugerfeedback i hele applikationen
- **Testet** den komplette applikationsarbejdsgang fra brugerinput til AI-svar

### Vigtige l√¶ringsresultater

```mermaid
mindmap
  root((AI Chat App Skills))
    API Integration
      Authentication
      Error Handling
      Async Programming
    Web Development
      HTML5 Semantics
      Modern CSS
      ES6+ JavaScript
    User Experience
      Responsive Design
      Accessibility
      Real-time Interaction
    AI Understanding
      Prompt Engineering
      Model Parameters
      Conversation Flow
```

Dette projekt har introduceret dig til fundamentet for at bygge AI-drevne applikationer, som repr√¶senterer fremtiden for webudvikling. Du forst√•r nu, hvordan man integrerer AI-funktioner i traditionelle webapplikationer og skaber engagerende brugeroplevelser, der f√∏les intelligente og responsive.

### Professionelle anvendelser

De f√¶rdigheder, du har udviklet i denne lektion, er direkte anvendelige i moderne softwareudviklingskarrierer:

- **Full-stack webudvikling** med moderne frameworks og API'er
- **AI-integration** i webapplikationer og mobilapps
- **API-design og udvikling** til mikroservice-arkitekturer
- **Udvikling af brugergr√¶nseflader** med fokus p√• tilg√¶ngelighed og responsivt design
- **DevOps-praksis** inklusive milj√∏konfiguration og deployment

### Forts√¶t din AI-udviklingsrejse

**N√¶ste l√¶ringstrin:**
- **Udforsk** mere avancerede AI-modeller og API'er (GPT-4, Claude, Gemini)
- **L√¶r** om prompt engineering-teknikker for bedre AI-svar
- **Stud√©r** samtaledesign og chatbot-brugeroplevelsesprincipper
- **Unders√∏g** AI-sikkerhed, etik og ansvarlig AI-udviklingspraksis
- **Byg** mere komplekse applikationer med samtalehukommelse og kontekstbevidsthed

**Avancerede projektid√©er:**
- Multi-bruger chatrum med AI-moderation
- AI-drevne kundeservice-chatbots
- Uddannelsesm√¶ssige tutorassistenter med personlig l√¶ring
- Kreative skrivepartnere med forskellige AI-personligheder
- Teknisk dokumentationsassistenter for udviklere

## Kom i gang med GitHub Codespaces

Vil du pr√∏ve dette projekt i et cloud-udviklingsmilj√∏? GitHub Codespaces tilbyder et komplet udviklingssetup i din browser, perfekt til at eksperimentere med AI-applikationer uden lokale ops√¶tningskrav.

### Ops√¶tning af dit udviklingsmilj√∏

**Trin 1: Opret fra skabelon**
- **Naviger** til [Web Dev For Beginners repository](https://github.com/microsoft/Web-Dev-For-Beginners)
- **Klik** p√• "Use this template" √∏verst til h√∏jre (s√∏rg for, at du er logget ind p√• GitHub)

![Opret fra skabelon interface, der viser den gr√∏nne "Use this template"-knap](../../../translated_images/template.67ad477109d29a2b04599a83c964c87fcde041256d4f04d3589cbb00c696f76c.da.png)

**Trin 2: Start Codespaces**
- **√Öbn** dit nyoprettede repository
- **Klik** p√• den gr√∏nne "Code"-knap og v√¶lg "Codespaces"
- **V√¶lg** "Create codespace on main" for at starte dit udviklingsmilj√∏

![Opret codespace interface med muligheder for at starte cloud-udviklingsmilj√∏](../../../translated_images/codespace.bcecbdf5d2747d3d17da67a78ad911c8853d68102e34748ec372cde1e9236e1d.da.png)

**Trin 3: Milj√∏konfiguration**
N√•r din Codespace er indl√¶st, har du adgang til:
- **Forudinstalleret** Python, Node.js og alle n√∏dvendige udviklingsv√¶rkt√∏jer
- **VS Code interface** med udvidelser til webudvikling
- **Terminaladgang** til at k√∏re backend- og frontend-servere
- **Port forwarding** til test af dine applikationer

**Hvad Codespaces tilbyder:**
- **Eliminerer** problemer med ops√¶tning og konfiguration af lokale milj√∏er
- **Giver** et ensartet udviklingsmilj√∏ p√• tv√¶rs af forskellige enheder
- **Indeholder** forudkonfigurerede v√¶rkt√∏jer og udvidelser til webudvikling
- **Tilbyder** problemfri integration med GitHub til versionskontrol og samarbejde

> üöÄ **Pro Tip**: Codespaces er perfekt til at l√¶re og prototypere AI-applikationer, da det automatisk h√•ndterer al den komplekse milj√∏ops√¶tning, s√• du kan fokusere p√• at bygge og l√¶re i stedet for at l√∏se konfigurationsproblemer.

---

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hj√¶lp af AI-overs√¶ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr√¶ber os p√• n√∏jagtighed, skal du v√¶re opm√¶rksom p√•, at automatiserede overs√¶ttelser kan indeholde fejl eller un√∏jagtigheder. Det originale dokument p√• dets oprindelige sprog b√∏r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs√¶ttelse. Vi er ikke ansvarlige for eventuelle misforst√•elser eller fejltolkninger, der opst√•r som f√∏lge af brugen af denne overs√¶ttelse.