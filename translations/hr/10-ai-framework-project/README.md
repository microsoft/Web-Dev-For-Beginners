<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2c4ae5688e34b4b8b09d52aec56c79e",
  "translation_date": "2025-10-24T23:57:01+00:00",
  "source_file": "10-ai-framework-project/README.md",
  "language_code": "hr"
}
-->
# AI Framework

Jeste li se ikada osje캖ali preplavljeno poku코avaju캖i izgraditi AI aplikacije od nule? Niste jedini! AI okviri su poput 코vicarskog no쬴캖a za razvoj umjetne inteligencije - mo캖ni alati koji vam mogu u코tedjeti vrijeme i glavobolje pri izradi inteligentnih aplikacija. Zamislite AI okvir kao dobro organiziranu knji쬹icu: pru쬬 unaprijed izgra캠ene komponente, standardizirane API-je i pametne apstrakcije kako biste se mogli usredoto캜iti na rje코avanje problema umjesto na borbu s detaljima implementacije.

U ovoj lekciji istra쬴t 캖emo kako okviri poput LangChain-a mogu pretvoriti nekada slo쬰ne zadatke integracije AI-a u 캜ist i 캜itljiv kod. Otkrit 캖ete kako se nositi s izazovima iz stvarnog svijeta, poput pra캖enja razgovora, implementacije poziva alata i upravljanja razli캜itim AI modelima putem jednog ujedinjenog su캜elja.

Do kraja lekcije znat 캖ete kada posegnuti za okvirima umjesto za sirovim API pozivima, kako u캜inkovito koristiti njihove apstrakcije i kako izgraditi AI aplikacije spremne za stvarnu upotrebu. Istra쬴mo 코to AI okviri mogu u캜initi za va코e projekte.

## Za코to odabrati okvir?

Spremni ste za izradu AI aplikacije - sjajno! Ali evo u 캜emu je stvar: imate nekoliko razli캜itih puteva koje mo쬰te odabrati, a svaki od njih ima svoje prednosti i nedostatke. To je pomalo kao biranje izme캠u hodanja, vo쬹je biciklom ili autom kako biste stigli negdje - svi 캖e vas odvesti na odredi코te, ali iskustvo (i trud) bit 캖e potpuno razli캜iti.

Razmotrimo tri glavna na캜ina na koja mo쬰te integrirati AI u svoje projekte:

| Pristup | Prednosti | Najbolje za | Razmatranja |
|----------|------------|----------|--------------|
| **Izravni HTTP zahtjevi** | Potpuna kontrola, bez ovisnosti | Jednostavni upiti, u캜enje osnova | Vi코e opse쬬n kod, ru캜no rukovanje gre코kama |
| **SDK integracija** | Manje boilerplate koda, optimizacija specifi캜na za model | Aplikacije s jednim modelom | Ograni캜eno na specifi캜ne pru쬬telje usluga |
| **AI okviri** | Ujedinjeni API, ugra캠ene apstrakcije | Aplikacije s vi코e modela, slo쬰ni tijekovi rada | Krivulja u캜enja, potencijalna prekomjerna apstrakcija |

### Prednosti okvira u praksi

```mermaid
graph TD
    A[Your Application] --> B[AI Framework]
    B --> C[OpenAI GPT]
    B --> D[Anthropic Claude]
    B --> E[GitHub Models]
    B --> F[Local Models]
    
    B --> G[Built-in Tools]
    G --> H[Memory Management]
    G --> I[Conversation History]
    G --> J[Function Calling]
    G --> K[Error Handling]
```

**Za코to su okviri va쬹i:**
- **Ujedinjuju** vi코e AI pru쬬telja usluga pod jednim su캜eljem
- **Automatski upravljaju** memorijom razgovora
- **Pru쬬ju** gotove alate za uobi캜ajene zadatke poput ugra캠ivanja i poziva funkcija
- **Upravljaju** rukovanjem gre코kama i logikom ponovnog poku코aja
- **Pretvaraju** slo쬰ne tijekove rada u 캜itljive metode poziva

> 游눠 **Savjet stru캜njaka**: Koristite okvire kada prelazite izme캠u razli캜itih AI modela ili gradite slo쬰ne zna캜ajke poput agenata, memorije ili poziva alata. Dr쬴te se izravnih API-ja kada u캜ite osnove ili gradite jednostavne, fokusirane aplikacije.

**Zaklju캜ak**: Kao i kod odabira izme캠u specijaliziranih alata majstora i kompletne radionice, sve ovisi o prilagodbi alata zadatku. Okviri su izvrsni za slo쬰ne, bogate zna캜ajkama aplikacije, dok izravni API-ji dobro funkcioniraju za jednostavne slu캜ajeve upotrebe.

## Uvod

U ovoj lekciji nau캜it 캖emo:

- Kako koristiti uobi캜ajeni AI okvir.
- Kako rije코iti uobi캜ajene probleme poput razgovora, kori코tenja alata, memorije i konteksta.
- Kako to iskoristiti za izradu AI aplikacija.

## Va코 prvi AI upit

Zapo캜nimo s osnovama stvaranjem va코e prve AI aplikacije koja 코alje pitanje i dobiva odgovor. Kao 코to je Arhimed otkrio princip istiskivanja u svojoj kadi, ponekad najjednostavnija opa쬬nja vode do najmo캖nijih uvida - a okviri 캜ine te uvide dostupnima.

### Postavljanje LangChain-a s GitHub modelima

Koristit 캖emo LangChain za povezivanje s GitHub modelima, 코to je prili캜no sjajno jer vam omogu캖uje besplatan pristup raznim AI modelima. Najbolji dio? Trebate samo nekoliko jednostavnih parametara konfiguracije da biste zapo캜eli:

```python
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

# Send a simple prompt
response = llm.invoke("What's the capital of France?")
print(response.content)
```

**Razlo쬴mo 코to se ovdje doga캠a:**
- **Stvara** LangChain klijent koriste캖i klasu `ChatOpenAI` - ovo je va코 ulaz u AI!
- **Konfigurira** vezu s GitHub modelima pomo캖u va코eg autentifikacijskog tokena
- **Odre캠uje** koji AI model koristiti (`gpt-4o-mini`) - zamislite to kao odabir va코eg AI asistenta
- **마lje** va코e pitanje koriste캖i metodu `invoke()` - ovdje se doga캠a magija
- **Izvla캜i** i prikazuje odgovor - i voil, razgovarate s AI-jem!

> 游댢 **Napomena o postavljanju**: Ako koristite GitHub Codespaces, imate sre캖e - `GITHUB_TOKEN` je ve캖 postavljen za vas! Radite lokalno? Bez brige, samo trebate stvoriti osobni pristupni token s odgovaraju캖im dozvolama.

**O캜ekivani izlaz:**
```text
The capital of France is Paris.
```

```mermaid
sequenceDiagram
    participant App as Your Python App
    participant LC as LangChain
    participant GM as GitHub Models
    participant AI as GPT-4o-mini
    
    App->>LC: llm.invoke("What's the capital of France?")
    LC->>GM: HTTP request with prompt
    GM->>AI: Process prompt
    AI->>GM: Generated response
    GM->>LC: Return response
    LC->>App: response.content
```

## Izrada konverzacijskog AI-a

Prvi primjer pokazuje osnove, ali to je samo jedna razmjena - postavite pitanje, dobijete odgovor i to je to. U stvarnim aplikacijama 쬰lite da va코 AI zapamti o 캜emu ste razgovarali, poput na캜ina na koji su Watson i Holmes gradili svoje istra쬴va캜ke razgovore tijekom vremena.

Tu LangChain postaje posebno koristan. Pru쬬 razli캜ite vrste poruka koje poma쬿 u strukturiranju razgovora i omogu캖uju vam da svom AI-ju date osobnost. Gradit 캖ete iskustva razgovora koja odr쬬vaju kontekst i karakter.

### Razumijevanje vrsta poruka

Zamislite ove vrste poruka kao razli캜ite "kape" koje sudionici nose u razgovoru. LangChain koristi razli캜ite klase poruka za pra캖enje tko 코to govori:

| Vrsta poruke | Svrha | Primjer upotrebe |
|--------------|---------|------------------|
| `SystemMessage` | Definira osobnost i pona코anje AI-ja | "Vi ste korisni asistent za kodiranje" |
| `HumanMessage` | Predstavlja unos korisnika | "Objasnite kako funkcije rade" |
| `AIMessage` | Pohranjuje odgovore AI-ja | Prethodni odgovori AI-ja u razgovoru |

### Stvaranje va코eg prvog razgovora

Stvorimo razgovor u kojem na코 AI preuzima odre캠enu ulogu. Neka utjelovi kapetana Picarda - lika poznatog po svojoj diplomatskoj mudrosti i vodstvu:

```python
messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]
```

**Razlaganje postavke ovog razgovora:**
- **Uspostavlja** ulogu i osobnost AI-ja putem `SystemMessage`
- **Pru쬬** po캜etni upit korisnika putem `HumanMessage`
- **Stvara** temelj za razgovor u vi코e koraka

Cijeli kod za ovaj primjer izgleda ovako:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]


# works
response  = llm.invoke(messages)
print(response.content)
```

Trebali biste vidjeti ishod sli캜an:

```text
I am Captain Jean-Luc Picard, the commanding officer of the USS Enterprise (NCC-1701-D), a starship in the United Federation of Planets. My primary mission is to explore new worlds, seek out new life and new civilizations, and boldly go where no one has gone before. 

I believe in the importance of diplomacy, reason, and the pursuit of knowledge. My crew is diverse and skilled, and we often face challenges that test our resolve, ethics, and ingenuity. Throughout my career, I have encountered numerous species, grappled with complex moral dilemmas, and have consistently sought peaceful solutions to conflicts.

I hold the ideals of the Federation close to my heart, believing in the importance of cooperation, understanding, and respect for all sentient beings. My experiences have shaped my leadership style, and I strive to be a thoughtful and just captain. How may I assist you further?
```

Kako biste odr쬬li kontinuitet razgovora (umjesto da svaki put resetirate kontekst), trebate nastaviti dodavati odgovore na svoj popis poruka. Kao usmena tradicija koja je o캜uvala pri캜e kroz generacije, ovaj pristup gradi trajnu memoriju:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]


# works
response  = llm.invoke(messages)

print(response.content)

print("---- Next ----")

messages.append(response)
messages.append(HumanMessage(content="Now that I know about you, I'm Chris, can I be in your crew?"))

response  = llm.invoke(messages)

print(response.content)

```

Prili캜no zgodno, zar ne? Ono 코to se ovdje doga캠a jest da pozivamo LLM dvaput - prvo samo s na코im po캜etnim dvjema porukama, a zatim ponovno s cijelom povije코캖u razgovora. Kao da AI zapravo prati na코 razgovor!

Kada pokrenete ovaj kod, dobit 캖ete drugi odgovor koji zvu캜i otprilike ovako:

```text
Welcome aboard, Chris! It's always a pleasure to meet those who share a passion for exploration and discovery. While I cannot formally offer you a position on the Enterprise right now, I encourage you to pursue your aspirations. We are always in need of talented individuals with diverse skills and backgrounds. 

If you are interested in space exploration, consider education and training in the sciences, engineering, or diplomacy. The values of curiosity, resilience, and teamwork are crucial in Starfleet. Should you ever find yourself on a starship, remember to uphold the principles of the Federation: peace, understanding, and respect for all beings. Your journey can lead you to remarkable adventures, whether in the stars or on the ground. Engage!
```

Uzeti 캖u to kao mo쬯a ;)

## Streaming odgovora

Jeste li ikada primijetili kako ChatGPT "tipka" svoje odgovore u stvarnom vremenu? To je streaming u akciji. Kao gledanje vje코tog kaligrafa na djelu - vidjeti kako se znakovi pojavljuju potez po potez umjesto da se materijaliziraju trenutno - streaming 캜ini interakciju prirodnijom i pru쬬 trenutne povratne informacije.

### Implementacija streaminga s LangChain-om

```python
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
    streaming=True
)

# Stream the response
for chunk in llm.stream("Write a short story about a robot learning to code"):
    print(chunk.content, end="", flush=True)
```

**Za코to je streaming sjajan:**
- **Prikazuje** sadr쬬j dok se stvara - nema vi코e neugodnog 캜ekanja!
- **캛ini** da se korisnici osje캖aju kao da se ne코to stvarno doga캠a
- **Djeluje** br쬰, 캜ak i kad tehni캜ki nije
- **Omogu캖uje** korisnicima da po캜nu 캜itati dok AI jo코 "razmi코lja"

> 游눠 **Savjet za korisni캜ko iskustvo**: Streaming se zaista isti캜e kada se bavite duljim odgovorima poput obja코njenja koda, kreativnog pisanja ili detaljnih tutorijala. Va코i korisnici 캖e voljeti vidjeti napredak umjesto da zure u prazan ekran!

## Predlo코ci upita

Predlo코ci upita funkcioniraju poput retori캜kih struktura kori코tenih u klasi캜noj oratoriji - razmislite o tome kako bi Ciceron prilagodio svoje obrasce govora za razli캜itu publiku, dok bi zadr쬬o isti uvjerljivi okvir. Omogu캖uju vam stvaranje ponovljivih upita gdje mo쬰te zamijeniti razli캜ite dijelove informacija bez ponovnog pisanja svega. Jednom kada postavite predlo쬬k, samo popunite varijable s potrebnim vrijednostima.

### Stvaranje ponovljivih upita

```python
from langchain_core.prompts import ChatPromptTemplate

# Define a template for code explanations
template = ChatPromptTemplate.from_messages([
    ("system", "You are an expert programming instructor. Explain concepts clearly with examples."),
    ("human", "Explain {concept} in {language} with a practical example for {skill_level} developers")
])

# Use the template with different values
questions = [
    {"concept": "functions", "language": "JavaScript", "skill_level": "beginner"},
    {"concept": "classes", "language": "Python", "skill_level": "intermediate"},
    {"concept": "async/await", "language": "JavaScript", "skill_level": "advanced"}
]

for question in questions:
    prompt = template.format_messages(**question)
    response = llm.invoke(prompt)
    print(f"Topic: {question['concept']}\n{response.content}\n---\n")
```

**Za코to 캖ete voljeti koristiti predlo코ke:**
- **Odr쬬va** va코e upite dosljednima u cijeloj aplikaciji
- **Nema vi코e** neurednog spajanja stringova - samo 캜iste, jednostavne varijable
- **Va코 AI** se pona코a predvidljivo jer struktura ostaje ista
- **A쬿riranja** su jednostavna - promijenite predlo쬬k jednom i svugdje je a쬿riran

## Strukturirani izlaz

Jeste li ikada bili frustrirani poku코avaju캖i analizirati AI odgovore koji se vra캖aju kao nestrukturirani tekst? Strukturirani izlaz je poput podu캜avanja va코eg AI-ja da slijedi sustavni pristup koji je Linnaeus koristio za biolo코ku klasifikaciju - organiziran, predvidljiv i jednostavan za rad. Mo쬰te zatra쬴ti JSON, specifi캜ne podatkovne strukture ili bilo koji format koji vam je potreban.

### Definiranje shema izlaza

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel, Field

class CodeReview(BaseModel):
    score: int = Field(description="Code quality score from 1-10")
    strengths: list[str] = Field(description="List of code strengths")
    improvements: list[str] = Field(description="List of suggested improvements")
    overall_feedback: str = Field(description="Summary feedback")

# Set up the parser
parser = JsonOutputParser(pydantic_object=CodeReview)

# Create prompt with format instructions
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a code reviewer. {format_instructions}"),
    ("human", "Review this code: {code}")
])

# Format the prompt with instructions
chain = prompt | llm | parser

# Get structured response
code_sample = """
def calculate_average(numbers):
    return sum(numbers) / len(numbers)
"""

result = chain.invoke({
    "code": code_sample,
    "format_instructions": parser.get_format_instructions()
})

print(f"Score: {result['score']}")
print(f"Strengths: {', '.join(result['strengths'])}")
```

**Za코to je strukturirani izlaz revolucionaran:**
- **Nema vi코e** naga캠anja u kojem formatu 캖ete dobiti odgovor - uvijek je dosljedan
- **Izravno se povezuje** s va코im bazama podataka i API-jima bez dodatnog rada
- **Hvata** 캜udne AI odgovore prije nego 코to pokvare va코u aplikaciju
- **캛ini** va코 kod 캜i코캖im jer to캜no znate s 캜ime radite

## Pozivanje alata

Sada dolazimo do jedne od najmo캖nijih zna캜ajki: alata. Ovo je na캜in na koji svom AI-ju dajete prakti캜ne sposobnosti izvan razgovora. Kao 코to su srednjovjekovni cehovi razvili specijalizirane alate za odre캠ene zanate, mo쬰te opremiti svoj AI fokusiranim instrumentima. Opisujete koji su alati dostupni, a kada netko zatra쬴 ne코to 코to odgovara, va코 AI mo쬰 poduzeti akciju.

### Kori코tenje Pythona

Dodajmo nekoliko alata ovako:

```python
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

tools = [add]

functions = {
    "add": lambda a, b: a + b
}
```

맚o se ovdje doga캠a? Stvaramo nacrt za alat nazvan `add`. Naslje캠ivanjem iz `TypedDict` i kori코tenjem tih naprednih `Annotated` tipova za `a` i `b`, dajemo LLM-u jasnu sliku o tome 코to ovaj alat radi i 코to mu je potrebno. Rje캜nik `functions` je poput na코eg alata - govori na코em kodu to캜no 코to u캜initi kada AI odlu캜i koristiti odre캠eni alat.

Pogledajmo kako sljede캖e pozivamo LLM s ovim alatom:

```python
llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)
```

Ovdje pozivamo `bind_tools` s na코im nizom `tools`, 캜ime LLM `llm_with_tools` sada ima znanje o ovom alatu.

Da bismo koristili ovaj novi LLM, mo쬰mo upisati sljede캖i kod:

```python
query = "What is 3 + 12?"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

Sada kada pozivamo `invoke` na ovom novom LLM-u, koji ima alate, mo쬯a 캖e svojstvo `tool_calls` biti popunjeno. Ako je tako, bilo koji identificirani alat ima svojstvo `name` i `args` koje identificira koji alat treba pozvati i s argumentima. Cijeli kod izgleda ovako:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

tools = [add]

functions = {
    "add": lambda a, b: a + b
}

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)

query = "What is 3 + 12?"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

Pokretanjem ovog koda trebali biste vidjeti izlaz sli캜an:

```text
TOOL CALL:  15
CONTENT: 
```

AI je analizirao "맚o je 3 + 12" i prepoznao ovo kao zadatak za alat `add`. Kao 코to vje코t knji쬹i캜ar zna na koji izvor se obratiti na temelju vrste postavljenog pitanja, AI je to zaklju캜io iz naziva alata, opisa i specifikacija polja. Rezultat od 15 dolazi iz na코eg rje캜nika `functions` koji izvr코ava alat:

```python
print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
```

### Zanimljiviji alat koji poziva web API

Dodavanje brojeva demonstrira koncept, ali stvarni alati obi캜no obavljaju slo쬰nije operacije, poput pozivanja web API-ja. Pro코irimo na코 primjer kako bismo omogu캖ili AI-ju da dohva캖a sadr쬬j s interneta - sli캜no kao 코to su telegrafisti nekada povezivali udaljene lokacije:

```python
class joke(TypedDict):
    """Tell a joke."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    category: Annotated[str, ..., "The joke category"]

def get_joke(category: str) -> str:
    response = requests.get(f"https://api.chucknorris.io/jokes/random?category={category}", headers={"Accept": "application/json"})
    if response.status_code == 200:
        return response.json().get("value", f"Here's a {category} joke!")
    return f"Here's a {category} joke!"

functions = {
    "add": lambda a, b: a + b,
    "joke": lambda category: get_joke(category)
}

query = "Tell me a joke about animals"

# the rest of the code is the same
```

Sada, ako pokrenete ovaj kod, dobit 캖ete odgovor koji ka쬰 ne코to poput:

```text
TOOL CALL:  Chuck Norris once rode a nine foot grizzly bear through an automatic car wash, instead of taking a shower.
CONTENT:  
```

Evo cijelog koda:

```python
from langchain_openai import ChatOpenAI
import requests
import os
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

class joke(TypedDict):
    """Tell a joke."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    category: Annotated[str, ..., "The joke category"]

tools = [add, joke]

def get_joke(category: str) -> str:
    response = requests.get(f"https://api.chucknorris.io/jokes/random?category={category}", headers={"Accept": "application/json"})
    if response.status_code == 200:
        return response.json().get("value", f"Here's a {category} joke!")
    return f"Here's a {category} joke!"

functions = {
    "add": lambda a, b: a + b,
    "joke": lambda category: get_joke(category)
}

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)

query = "Tell me a joke about animals"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        # print("TOOL CALL: ", tool)
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

## Ugra캠ivanja i obrada dokumenata

Ugra캠ivanja predstavljaju jedno od najelegantnijih rje코enja u modernom AI-ju. Zamislite da mo쬰te uzeti bilo koji tekst i pretvoriti ga u numeri캜ke koordinate koje hvataju njegovo zna캜enje. To je upravo ono 코to ugra캠ivanja rade - transformiraju tekst u to캜ke u vi코edimenzionalnom prostoru gdje se sli캜ni koncepti grupiraju. To je poput koordinatnog sustava za ideje, nalik na na캜in na koji je Mendeljejev organizirao periodni sustav prema atomskim svojstvima.

### Stvaranje i kori코tenje ugra캠ivanja

```python
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter

# Initialize embeddings
embeddings = OpenAIEmbeddings(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="text-embedding-3-small"
)

# Load and split documents
loader = TextLoader("documentation.txt")
documents = loader.load()

text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(documents)

# Create vector store
vectorstore = FAISS.from_documents(texts, embeddings)

# Perform similarity search
query = "How do I handle user authentication?"
similar_docs = vectorstore.similarity_search(query, k=3)

for doc in similar_docs:
    print(f"Relevant content: {doc.page_content[:200]}...")
```

### U캜itavanje dokumenata u razli캜itim formatima

```python
from langchain_community.document_loaders import (
    PyPDFLoader,
    CSVLoader,
    JSONLoader,
    WebBaseLoader
)

# Load different document types
pdf_loader = PyPDFLoader("manual.pdf")
csv_loader = CSVLoader("data.csv")
json_loader = JSONLoader("config.json")
web_loader = WebBaseLoader("https://example.com/docs")

# Process all documents
all_documents = []
for loader in [pdf_loader, csv_loader, json_loader, web_loader]:
    docs = loader.load()
    all_documents.extend(docs)
```

**맚o mo쬰te u캜initi s ugra캠ivanjima:**
- **Izgraditi** pretra쬴vanje koje zaista razumije 코to mislite, a ne samo podudaranje klju캜nih rije캜i
- **Stvoriti** AI koji mo쬰 odgovarati na pitanja o va코im dokumentima
- **Napraviti** sustave preporuka koji predla쬿 zaista relevantan sadr쬬j
- **Automatski** organizirati i kategorizirati va코 sadr쬬j

## Izrada kompletne AI aplikacije

Sada 캖emo integrirati sve 코to ste nau캜ili u sveobuhvatnu aplikaciju - asistenta za kodiranje koji mo쬰 odgovarati na pitanja, koristiti alate i odr쬬vati memoriju razgovora. Kao 코to je tiskarski stroj kombinirao postoje캖e tehnologije (pomicanje slova, tinta, papir i pritisak) u ne코to transformativno, kombinirat 캖emo na코e AI komponente u ne코to prakti캜no i korisno.

### Primjer kompletne aplikacije

```python
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_community.vectorstores import FAISS
from typing_extensions import Annotated, TypedDict
import os
import requests

class CodingAssistant:
    def __init__(self):
        self.llm = ChatOpenAI(
            api_key=os.environ["GITHUB_TOKEN"],
            base_url="https://models.github.ai/inference",
            model="openai/gpt-4o-mini"
        )
        
        self.conversation_history = [
            SystemMessage(content="""You are an expert coding assistant. 
            Help users learn programming concepts, debug code, and write better software.
            Use tools when needed and maintain a helpful, encouraging tone.""")
        ]
        
        # Define tools
        self.setup_tools()
    
    def setup_tools(self):
        class web_search(TypedDict):
            """Search for programming documentation or examples."""
            query: Annotated[str, "Search query for programming help"]
        
        class code_formatter(TypedDict):
            """Format and validate code snippets."""
            code: Annotated[str, "Code to format"]
            language: Annotated[str, "Programming language"]
        
        self.tools = [web_search, code_formatter]
        self.llm_with_tools = self.llm.bind_tools(self.tools)
    
    def chat(self, user_input: str):
        # Add user message to conversation
        self.conversation_history.append(HumanMessage(content=user_input))
        
        # Get AI response
        response = self.llm_with_tools.invoke(self.conversation_history)
        
        # Handle tool calls if any
        if response.tool_calls:
            for tool_call in response.tool_calls:
                tool_result = self.execute_tool(tool_call)
                print(f"游댢 Tool used: {tool_call['name']}")
                print(f"游늵 Result: {tool_result}")
        
        # Add AI response to conversation
        self.conversation_history.append(response)
        
        return response.content
    
    def execute_tool(self, tool_call):
        tool_name = tool_call['name']
        args = tool_call['args']
        
        if tool_name == 'web_search':
            return f"Found documentation for: {args['query']}"
        elif tool_name == 'code_formatter':
            return f"Formatted {args['language']} code: {args['code'][:50]}..."
        
        return "Tool execution completed"

# Usage example
assistant = CodingAssistant()

print("游뱄 Coding Assistant Ready! Type 'quit' to exit.\n")

while True:
    user_input = input("You: ")
    if user_input.lower() == 'quit':
        break
    
    response = assistant.chat(user_input)
    print(f"游뱄 Assistant: {response}\n")
```

**Arhitektura aplikacije:**

```mermaid
graph TD
    A[User Input] --> B[Coding Assistant]
    B --> C[Conversation Memory]
    B --> D[Tool Detection]
    B --> E[LLM Processing]
    
    D --> F[Web Search Tool]
    D --> G[Code Formatter Tool]
    
    E --> H[Response Generation]
    F --> H
    G --> H
    
    H --> I[User Interface]
    H --> C
```

**Klju캜ne zna캜ajke koje smo implementirali:**
- **Pamti** cijeli va코 razgovor za kontinuitet konteksta
- **Izvr코ava radnje** putem poziva alata, ne samo razgovora
- **Prati** predvidljive obrasce interakcije
- **Automatski upravlja** rukovanjem gre코kama i slo쬰nim tijekovima rada

## Zadatak: Izradite vlastitog AI asistenta za u캜enje

**Cilj**: Stvorite AI aplikaciju koja poma쬰 studentima u u캜enju programskih koncepata pru쬬njem obja코njenja, primjera koda i interaktivnih kvizova.

### Zahtjevi

**Osnovne zna캜ajke (obavezno):**
1. **Razgovorno su캜elje**: Implementirajte sustav za chat koji odr쬬va kontekst kroz vi코e pitanja
2. **Obrazovni alati**: Stvorite barem dva alata koja poma쬿 u u캜enju:
   - Alat za obja코njenje koda
   - Generator kvizova za koncepte
3. **Personalizirano u캜enje**: Koristite sistemske poruke za prilagodbu odgovora razli캜itim razinama vje코tina  
4. **Formatiranje odgovora**: Implementirajte strukturirani izlaz za pitanja kviza  

### Koraci implementacije  

**Korak 1: Postavljanje okru쬰nja**  
```bash
pip install langchain langchain-openai
```
  
**Korak 2: Osnovna funkcionalnost razgovora**  
- Kreirajte klasu `StudyAssistant`  
- Implementirajte memoriju razgovora  
- Dodajte konfiguraciju osobnosti za edukativnu podr코ku  

**Korak 3: Dodavanje edukativnih alata**  
- **Obja코njenje koda**: Razla쬰 kod na razumljive dijelove  
- **Generator kvizova**: Stvara pitanja o konceptima programiranja  
- **Pra캖enje napretka**: Prati teme koje su obra캠ene  

**Korak 4: Napredne zna캜ajke (opcionalno)**  
- Implementirajte streaming odgovore za bolje korisni캜ko iskustvo  
- Dodajte u캜itavanje dokumenata za uklju캜ivanje materijala s te캜aja  
- Kreirajte ugra캠ene elemente za pretra쬴vanje sadr쬬ja na temelju sli캜nosti  

### Kriteriji evaluacije  

| Zna캜ajka | Izvrsno (4) | Dobro (3) | Zadovoljavaju캖e (2) | Potrebno pobolj코anje (1) |  
|----------|-------------|-----------|---------------------|--------------------------|  
| **Tijek razgovora** | Prirodni, kontekstualno svjesni odgovori | Dobro zadr쬬vanje konteksta | Osnovni razgovor | Nema memorije izme캠u razmjena |  
| **Integracija alata** | Vi코e korisnih alata koji besprijekorno rade | 2+ alata ispravno implementirana | 1-2 osnovna alata | Alati ne funkcioniraju |  
| **Kvaliteta koda** | 캛ist, dobro dokumentiran, rukovanje gre코kama | Dobra struktura, neka dokumentacija | Osnovna funkcionalnost radi | Lo코a struktura, bez rukovanja gre코kama |  
| **Edukativna vrijednost** | Zaista korisno za u캜enje, prilagodljivo | Dobra podr코ka za u캜enje | Osnovna obja코njenja | Ograni캜ena edukativna korist |  

### Primjer strukture koda  

```python
class StudyAssistant:
    def __init__(self, skill_level="beginner"):
        # Initialize LLM, tools, and conversation memory
        pass
    
    def explain_code(self, code, language):
        # Tool: Explain how code works
        pass
    
    def generate_quiz(self, topic, difficulty):
        # Tool: Create practice questions
        pass
    
    def chat(self, user_input):
        # Main conversation interface
        pass

# Example usage
assistant = StudyAssistant(skill_level="intermediate")
response = assistant.chat("Explain how Python functions work")
```
  
**Bonus izazovi:**  
- Dodajte mogu캖nosti glasovnog unosa/izlaza  
- Implementirajte web su캜elje koriste캖i Streamlit ili Flask  
- Kreirajte bazu znanja iz materijala s te캜aja koriste캖i ugra캠ene elemente  
- Dodajte pra캖enje napretka i personalizirane putanje u캜enja  

## Sa쬰tak  

游꿀 Sada ste savladali osnove razvoja AI okvira i nau캜ili kako izgraditi sofisticirane AI aplikacije koriste캖i LangChain. Kao da ste zavr코ili sveobuhvatno naukovanje, stekli ste zna캜ajan set vje코tina. Pogledajmo 코to ste postigli.  

### 맚o ste nau캜ili  

**Osnovni koncepti okvira:**  
- **Prednosti okvira**: Razumijevanje kada odabrati okvire umjesto izravnih API poziva  
- **Osnove LangChain-a**: Postavljanje i konfiguriranje AI modela  
- **Vrste poruka**: Kori코tenje `SystemMessage`, `HumanMessage` i `AIMessage` za strukturirane razgovore  

**Napredne zna캜ajke:**  
- **Pozivanje alata**: Kreiranje i integracija prilago캠enih alata za pobolj코ane AI mogu캖nosti  
- **Memorija razgovora**: Odr쬬vanje konteksta kroz vi코e izmjena u razgovoru  
- **Streaming odgovori**: Implementacija isporuke odgovora u stvarnom vremenu  
- **Predlo코ci upita**: Izrada ponovljivih, dinami캜nih upita  
- **Strukturirani izlaz**: Osiguravanje dosljednih, lako 캜itljivih AI odgovora  
- **Ugra캠eni elementi**: Kreiranje semanti캜kog pretra쬴vanja i mogu캖nosti obrade dokumenata  

**Prakti캜ne primjene:**  
- **Izrada kompletnih aplikacija**: Kombiniranje vi코e zna캜ajki u aplikacije spremne za proizvodnju  
- **Rukovanje gre코kama**: Implementacija robusnog upravljanja gre코kama i validacije  
- **Integracija alata**: Kreiranje prilago캠enih alata koji pro코iruju AI mogu캖nosti  

### Klju캜ne lekcije  

> 游꿢 **Zapamtite**: AI okviri poput LangChain-a su u osnovi va코i najbolji prijatelji za skrivanje slo쬰nosti i pru쬬nje bogatih zna캜ajki. Savr코eni su kada trebate memoriju razgovora, pozivanje alata ili 쬰lite raditi s vi코e AI modela bez gubitka razuma.  

**Okvir za dono코enje odluka o integraciji AI-a:**  

```mermaid
flowchart TD
    A[AI Integration Need] --> B{Simple single query?}
    B -->|Yes| C[Direct API calls]
    B -->|No| D{Need conversation memory?}
    D -->|No| E[SDK Integration]
    D -->|Yes| F{Need tools or complex features?}
    F -->|No| G[Framework with basic setup]
    F -->|Yes| H[Full framework implementation]
    
    C --> I[HTTP requests, minimal dependencies]
    E --> J[Provider SDK, model-specific]
    G --> K[LangChain basic chat]
    H --> L[LangChain with tools, memory, agents]
```
  
### 맚o dalje?  

**Po캜nite graditi odmah:**  
- Iskoristite ove koncepte i izgradite ne코to 코to vas uzbu캠uje!  
- Eksperimentirajte s razli캜itim AI modelima kroz LangChain - to je kao igrali코te za AI modele  
- Kreirajte alate koji rje코avaju stvarne probleme s kojima se suo캜avate u svom radu ili projektima  

**Spremni za sljede캖u razinu?**  
- **AI agenti**: Izradite AI sustave koji mogu planirati i izvr코avati slo쬰ne zadatke samostalno  
- **RAG (Generacija uz pro코ireno pretra쬴vanje)**: Kombinirajte AI s vlastitim bazama znanja za aplikacije s pove캖anim mogu캖nostima  
- **Multimodalni AI**: Radite s tekstom, slikama i zvukom zajedno - mogu캖nosti su beskrajne!  
- **Implementacija u produkciju**: Nau캜ite kako skalirati svoje AI aplikacije i pratiti ih u stvarnom svijetu  

**Pridru쬴te se zajednici:**  
- Zajednica LangChain-a je fantasti캜na za pra캖enje novosti i u캜enje najboljih praksi  
- GitHub Models vam pru쬬 pristup najnovijim AI mogu캖nostima - savr코eno za eksperimentiranje  
- Nastavite vje쬭ati s razli캜itim slu캜ajevima upotrebe - svaki projekt 캖e vas nau캜iti ne코to novo  

Sada imate znanje za izradu inteligentnih, konverzacijskih aplikacija koje mogu pomo캖i ljudima u rje코avanju stvarnih problema. Kao renesansni majstori koji su kombinirali umjetni캜ku viziju s tehni캜kom vje코tinom, sada mo쬰te spojiti AI mogu캖nosti s prakti캜nom primjenom. Pitanje je: 코to 캖ete stvoriti? 游  

## Izazov GitHub Copilot Agenta 游  

Koristite Agent na캜in rada za dovr코avanje sljede캖eg izazova:  

**Opis:** Izradite naprednog AI asistenta za pregled koda koji kombinira vi코e zna캜ajki LangChain-a, uklju캜uju캖i pozivanje alata, strukturirani izlaz i memoriju razgovora, kako bi pru쬴o sveobuhvatne povratne informacije o predaji koda.  

**Upit:** Kreirajte klasu CodeReviewAssistant koja implementira:  
1. Alat za analizu slo쬰nosti koda i predlaganje pobolj코anja  
2. Alat za provjeru koda prema najboljim praksama  
3. Strukturirani izlaz koriste캖i Pydantic modele za dosljedan format pregleda  
4. Memoriju razgovora za pra캖enje sesija pregleda  
5. Glavno su캜elje za razgovor koje mo쬰 obra캠ivati predaju koda i pru쬴ti detaljne, korisne povratne informacije  

Asistent bi trebao mo캖i pregledavati kod na vi코e programskih jezika, odr쬬vati kontekst kroz vi코e predaja koda u jednoj sesiji i pru쬴ti i sa쬰tke ocjena i detaljne prijedloge za pobolj코anje.  

Saznajte vi코e o [agent na캜inu rada](https://code.visualstudio.com/blogs/2025/02/24/introducing-copilot-agent-mode) ovdje.  

---

**Izjava o odricanju odgovornosti**:  
Ovaj dokument je preveden pomo캖u AI usluge za prevo캠enje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo osigurati to캜nost, imajte na umu da automatski prijevodi mogu sadr쬬vati pogre코ke ili neto캜nosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za klju캜ne informacije preporu캜uje se profesionalni prijevod od strane ljudskog prevoditelja. Ne preuzimamo odgovornost za nesporazume ili pogre코na tuma캜enja koja proizlaze iz kori코tenja ovog prijevoda.