<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3925b6a1c31c60755eaae4d578232c25",
  "translation_date": "2026-01-07T05:23:15+00:00",
  "source_file": "10-ai-framework-project/README.md",
  "language_code": "ro"
}
-->
# Cadru AI

Èši s-a Ã®ntÃ¢mplat vreodatÄƒ sÄƒ te simÈ›i copleÈ™it Ã®ncercÃ¢nd sÄƒ construieÈ™ti aplicaÈ›ii AI de la zero? Nu eÈ™ti singur! Cadrele AI sunt ca un cuÈ›it elveÈ›ian pentru dezvoltarea AI-ului - sunt instrumente puternice care Ã®È›i pot economisi timp È™i dureri de cap cÃ¢nd construieÈ™ti aplicaÈ›ii inteligente. GÃ¢ndeÈ™te-te la un cadru AI ca la o bibliotecÄƒ bine organizatÄƒ: oferÄƒ componente pre-construite, API-uri standardizate È™i abstracÈ›ii inteligente, astfel Ã®ncÃ¢t sÄƒ te poÈ›i concentra pe rezolvarea problemelor Ã®n loc sÄƒ te lupÈ›i cu detaliile implementÄƒrii.

Ãn aceastÄƒ lecÈ›ie, vom explora cum cadre ca LangChain pot transforma ceea ce Ã®nainte erau sarcini complexe de integrare AI Ã®n cod curat È™i uÈ™or de citit. Vei descoperi cum sÄƒ abordezi provocÄƒri reale, cum ar fi menÈ›inerea urmÄƒririi conversaÈ›iilor, implementarea apelÄƒrii de instrumente È™i gestionarea diferitelor modele AI printr-o interfaÈ›Äƒ unificatÄƒ.

PÃ¢nÄƒ la final, vei È™ti cÃ¢nd sÄƒ foloseÈ™ti cadre Ã®n loc de apeluri API brute, cum sÄƒ foloseÈ™ti efectiv abstracÈ›iile lor È™i cum sÄƒ construieÈ™ti aplicaÈ›ii AI pregÄƒtite pentru utilizare Ã®n lumea realÄƒ. Hai sÄƒ explorÄƒm ce pot face cadrele AI pentru proiectele tale.

## âš¡ Ce poÈ›i face Ã®n urmÄƒtoarele 5 minute

**Ghid rapid pentru dezvoltatori ocupaÈ›i**

```mermaid
flowchart LR
    A[âš¡ 5 minute] --> B[InstaleazÄƒ LangChain]
    B --> C[CreazÄƒ client ChatOpenAI]
    C --> D[Trimite prima comandÄƒ]
    D --> E[Vezi puterea cadrului]
```
- **Minutul 1**: InstaleazÄƒ LangChain: `pip install langchain langchain-openai`
- **Minutul 2**: ConfigureazÄƒ token-ul GitHub È™i importÄƒ clientul ChatOpenAI
- **Minutul 3**: CreeazÄƒ o conversaÈ›ie simplÄƒ cu mesaje sistem È™i umane
- **Minutul 4**: AdaugÄƒ un instrument de bazÄƒ (ca o funcÈ›ie add) È™i vezi cum AI apeleazÄƒ instrumentele
- **Minutul 5**: ExperimenteazÄƒ diferenÈ›a dintre apeluri API brute È™i abstracÈ›ia cadrului

**Cod test rapid**:
```python
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini"
)

response = llm.invoke([
    SystemMessage(content="You are a helpful coding assistant"),
    HumanMessage(content="Explain Python functions briefly")
])
print(response.content)
```

**De ce conteazÄƒ asta**: Ãn 5 minute, vei vedea cum cadrele AI transformÄƒ integrarea complexÄƒ AI Ã®n apeluri simple de metode. Aceasta este fundaÈ›ia pentru aplicaÈ›iile AI de producÈ›ie.

## De ce sÄƒ alegi un cadru?

Deci eÈ™ti gata sÄƒ construieÈ™ti o aplicaÈ›ie AI - grozav! Dar iatÄƒ chestia: ai mai multe cÄƒi pe care le poÈ›i urma, È™i fiecare are avantajele È™i dezavantajele ei. E ca atunci cÃ¢nd alegi Ã®ntre a merge pe jos, cu bicicleta sau cu maÈ™ina - toate te duc la destinaÈ›ie, dar experienÈ›a (È™i efortul) sunt complet diferite.

Hai sÄƒ descompunem cele trei metode principale prin care poÈ›i integra AI Ã®n proiectele tale:

| Abordare | Avantaje | Cel mai potrivit pentru | ConsideraÈ›ii |
|----------|------------|----------|--------------|
| **SolicitÄƒri HTTP directe** | Control total, fÄƒrÄƒ dependenÈ›e | InterogÄƒri simple, Ã®nvÄƒÈ›area elementelor de bazÄƒ | Cod mai detaliat, gestionare manualÄƒ a erorilor |
| **Integrare SDK** | Mai puÈ›in cod de rutinÄƒ, optimizare specificÄƒ modelului | AplicaÈ›ii cu un singur model | Limitat la furnizori specifici |
| **Cadre AI** | API unificat, abstracÈ›ii Ã®ncorporate | AplicaÈ›ii multi-model, fluxuri de lucru complexe | Curba de Ã®nvÄƒÈ›are, posibilÄƒ supra-abstracÈ›ie |

### Beneficiile cadrului Ã®n practicÄƒ

```mermaid
graph TD
    A[AplicaÈ›ia Ta] --> B[Cadrul AI]
    B --> C[OpenAI GPT]
    B --> D[Anthropic Claude]
    B --> E[Modele GitHub]
    B --> F[Modele Locale]
    
    B --> G[Instrumente Incorporate]
    G --> H[Gestionarea Memoriei]
    G --> I[Istoric ConversaÈ›ii]
    G --> J[Apelarea FuncÈ›iilor]
    G --> K[Gestionarea Erorilor]
```
**De ce sunt importante cadrele:**
- **UnificÄƒ** mai mulÈ›i furnizori AI sub o singurÄƒ interfaÈ›Äƒ
- **GestioneazÄƒ** automat memoria conversaÈ›iei
- **OferÄƒ** instrumente gata fÄƒcute pentru sarcini comune precum embeddings È™i apelarea funcÈ›iilor
- **AdministreazÄƒ** gestionarea erorilor È™i logica de reÃ®ncercare
- **TransformÄƒ** fluxurile complexe Ã®n apeluri de metode uÈ™or de citit

> ğŸ’¡ **Sfat util**: FoloseÈ™te cadrele cÃ¢nd schimbi Ã®ntre diferite modele AI sau construieÈ™ti funcÈ›ii complexe precum agenÈ›i, memorie sau apelarea instrumentelor. FoloseÈ™te API-uri directe cÃ¢nd Ã®nveÈ›i noÈ›iunile de bazÄƒ sau construieÈ™ti aplicaÈ›ii simple, concentrate.

**Concluzie**: Ca atunci cÃ¢nd alegi Ã®ntre instrumentele specializate ale unui meÈ™ter È™i un atelier complet, este vorba de potrivirea instrumentului cu sarcina. Cadrele exceleazÄƒ pentru aplicaÈ›ii complexe, bogate Ã®n funcÈ›ii, Ã®n timp ce API-urile directe funcÈ›ioneazÄƒ bine pentru cazuri simple.

## ğŸ—ºï¸ CÄƒlÄƒtoria ta de Ã®nvÄƒÈ›are prin stÄƒpÃ¢nirea cadrelor AI

```mermaid
journey
    title De la API-uri brute la aplicaÈ›ii AI Ã®n producÈ›ie
    section Fundamentele cadrului
      ÃnÈ›elege beneficiile abstracÈ›iei: 4: You
      StÄƒpÃ¢neÈ™te elementele de bazÄƒ LangChain: 6: You
      ComparÄƒ abordÄƒrile: 7: You
    section Sisteme de conversaÈ›ie
      ConstruieÈ™te interfeÈ›e de chat: 5: You
      ImplementeazÄƒ modele de memorie: 7: You
      GestioneazÄƒ rÄƒspunsuri Ã®n streaming: 8: You
    section FuncÈ›ii avansate
      CreeazÄƒ unelte personalizate: 6: You
      StÄƒpÃ¢neÈ™te output structurat: 8: You
      ConstruieÈ™te sisteme de documente: 8: You
    section AplicaÈ›ii Ã®n producÈ›ie
      CombinÄƒ toate funcÈ›iile: 7: You
      GestioneazÄƒ scenarii de eroare: 8: You
      Deploiaza sisteme complete: 9: You
```
**DestinaÈ›ia cÄƒlÄƒtoriei tale**: La finalul acestei lecÈ›ii, vei fi stÄƒpÃ¢nit dezvoltarea cu cadre AI È™i vei putea construi aplicaÈ›ii AI sofisticate, pregÄƒtite pentru producÈ›ie, care concureazÄƒ cu asistenÈ›ii AI comerciali.

## Introducere

Ãn aceastÄƒ lecÈ›ie vom Ã®nvÄƒÈ›a sÄƒ:

- Folosim un cadru comun AI.
- AbordÄƒm probleme comune cum ar fi conversaÈ›iile de chat, utilizarea instrumentelor, memorie È™i context.
- Folosim tot acest lucru pentru a construi aplicaÈ›ii AI.

## ğŸ§  Ecosistemul dezvoltÄƒrii cadrelor AI

```mermaid
mindmap
  root((Cadre AI))
    Beneficii AbstracÈ›ie
      Simplificarea Codului
        API-uri Unificate
        Gestionare Erori ÃncorporatÄƒ
        Modele Consistente
        Boilerplate Redus
      Suport Multi-Model
        Agnostic FaÈ›Äƒ de Furnizor
        Comutare UÈ™oarÄƒ
        OpÈ›iuni de RezervÄƒ
        Optimizare Costuri
    Componente Principale
      Gestionarea ConversaÈ›iei
        Tipuri de Mesaje
        Sisteme de Memorie
        UrmÄƒrirea Contextului
        PersistenÈ›a Istoricului
      Integrarea Uneltelor
        Apeluri de FuncÈ›ii
        Conexiuni API
        Unelte Personalizate
        Automatizarea Fluxului de Lucru
    Caracteristici Avansate
      IeÈ™ire StructuratÄƒ
        Modele Pydantic
        Scheme JSON
        SiguranÈ›a Tipurilor
        Reguli de Validare
      Procesarea Documentelor
        Embeddinguri
        Magazine Vectoriale
        CÄƒutare dupÄƒ Similaritate
        Sisteme RAG
    Modele de ProducÈ›ie
      Arhitectura AplicaÈ›iei
        Design Modular
        LimitÄƒri de Eroare
        OperaÈ›iuni Async
        Gestionarea StÄƒrii
      Strategii de Implementare
        Scalabilitate
        Monitorizare
        PerformanÈ›Äƒ
        Securitate
```
**Principiul de bazÄƒ**: Cadrele AI abstractizeazÄƒ complexitatea Ã®n timp ce oferÄƒ abstracÈ›ii puternice pentru gestionarea conversaÈ›iilor, integrarea instrumentelor È™i procesarea documentelor, permiÈ›Ã¢nd dezvoltatorilor sÄƒ construiascÄƒ aplicaÈ›ii AI sofisticate cu cod curat È™i Ã®ntreÈ›inut.

## Prima ta solicitare AI

SÄƒ Ã®ncepem cu elementele fundamentale creÃ¢nd prima ta aplicaÈ›ie AI care trimite o Ã®ntrebare È™i primeÈ™te un rÄƒspuns. Ca Arhimede descoperind principiul deplasÄƒrii Ã®n cada lui, uneori cele mai simple observaÈ›ii conduc la cele mai puternice insight-uri - iar cadrele fac aceste insight-uri accesibile.

### Setarea LangChain cu modelele GitHub

Vom folosi LangChain pentru a ne conecta la modelele GitHub, ceea ce este foarte tare pentru cÄƒ Ã®È›i oferÄƒ acces gratuit la diferite modele AI. Partea cea mai bunÄƒ? Ai nevoie doar de cÃ¢È›iva parametri simpli de configurare pentru a Ã®ncepe:

```python
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

# Trimite un mesaj simplu
response = llm.invoke("What's the capital of France?")
print(response.content)
```

**SÄƒ descompunem ce se Ã®ntÃ¢mplÄƒ aici:**
- **CreeazÄƒ** un client LangChain folosind clasa `ChatOpenAI` - aceasta este poarta ta cÄƒtre AI!
- **ConfigureazÄƒ** conexiunea la Modelele GitHub cu token-ul tÄƒu de autentificare
- **Specifica** modelul AI de folosit (`gpt-4o-mini`) - gÃ¢ndeÈ™te-te la asta ca alegerea asistentului AI
- **Trimite** Ã®ntrebarea ta folosind metoda `invoke()` - aici se Ã®ntÃ¢mplÄƒ magia
- **Extrage** È™i afiÈ™eazÄƒ rÄƒspunsul - È™i voila, vorbeÈ™ti cu AI!

> ğŸ”§ **NotÄƒ de configurare**: DacÄƒ foloseÈ™ti GitHub Codespaces, eÈ™ti norocos - `GITHUB_TOKEN` este deja configurat pentru tine! Lucrezi local? Nicio problemÄƒ, trebuie doar sÄƒ creezi un token personal de acces cu permisiunile necesare.

**Rezultat aÈ™teptat:**
```text
The capital of France is Paris.
```

```mermaid
sequenceDiagram
    participant App as AplicaÈ›ia ta Python
    participant LC as LangChain
    participant GM as Modele GitHub
    participant AI as GPT-4o-mini
    
    App->>LC: llm.invoke("Care este capitala FranÈ›ei?")
    LC->>GM: Cerere HTTP cu prompt
    GM->>AI: ProceseazÄƒ promptul
    AI->>GM: RÄƒspuns generat
    GM->>LC: ReturneazÄƒ rÄƒspunsul
    LC->>App: response.content
```
## Construirea AI-ului conversaÈ›ional

Primul exemplu demonstreazÄƒ elementele de bazÄƒ, dar este doar un schimb simplu - pui o Ã®ntrebare, primeÈ™ti un rÄƒspuns È™i gata. Ãn aplicaÈ›iile reale, vrei ca AI-ul tÄƒu sÄƒ-È™i aminteascÄƒ despre ce aÈ›i discutat, aÈ™a cum Watson È™i Holmes È™i-au construit conversaÈ›iile investigative Ã®n timp.

Aici LangChain devine cu adevÄƒrat util. OferÄƒ tipuri diferite de mesaje care ajutÄƒ la structurarea conversaÈ›iilor È™i Ã®È›i permit sÄƒ dai AI-ului o personalitate. Vei construi experienÈ›e de chat care menÈ›in contextul È™i caracterul.

### ÃnÈ›elegerea tipurilor de mesaje

GÃ¢ndeÈ™te-te la aceste tipuri de mesaje ca la â€pÄƒlÄƒriileâ€ diferite pe care participanÈ›ii le poartÄƒ Ã®ntr-o conversaÈ›ie. LangChain foloseÈ™te clase diferite de mesaje pentru a È›ine evidenÈ›a cine spune ce:

| Tip mesaj | Scop | Exemplu de utilizare |
|--------------|---------|------------------|
| `SystemMessage` | DefineÈ™te personalitatea È™i comportamentul AI-ului | "EÈ™ti un asistent de programare util" |
| `HumanMessage` | ReprezintÄƒ input-ul utilizatorului | "ExplicÄƒ cum funcÈ›ioneazÄƒ funcÈ›iile" |
| `AIMessage` | StocheazÄƒ rÄƒspunsurile AI | RÄƒspunsuri AI anterioare Ã®n conversaÈ›ie |

### Crearea primei conversaÈ›ii

SÄƒ creÄƒm o conversaÈ›ie Ã®n care AI-ul nostru Ã®È™i asumÄƒ un rol specific. Ãl vom face sÄƒ Ã®ntruchipeze pe CÄƒpitanul Picard - un personaj cunoscut pentru Ã®nÈ›elepciunea sa diplomaticÄƒ È™i leadership:

```python
messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]
```

**Descompunerea acestei configuraÈ›ii a conversaÈ›iei:**
- **StabileÈ™te** rolul È™i personalitatea AI-ului prin `SystemMessage`
- **OferÄƒ** interogarea iniÈ›ialÄƒ a utilizatorului prin `HumanMessage`
- **CreeazÄƒ** o bazÄƒ pentru conversaÈ›ii cu mai multe replici

Codul complet pentru acest exemplu aratÄƒ astfel:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]


# funcÈ›ioneazÄƒ
response  = llm.invoke(messages)
print(response.content)
```

Ar trebui sÄƒ vezi un rezultat similar cu:

```text
I am Captain Jean-Luc Picard, the commanding officer of the USS Enterprise (NCC-1701-D), a starship in the United Federation of Planets. My primary mission is to explore new worlds, seek out new life and new civilizations, and boldly go where no one has gone before. 

I believe in the importance of diplomacy, reason, and the pursuit of knowledge. My crew is diverse and skilled, and we often face challenges that test our resolve, ethics, and ingenuity. Throughout my career, I have encountered numerous species, grappled with complex moral dilemmas, and have consistently sought peaceful solutions to conflicts.

I hold the ideals of the Federation close to my heart, believing in the importance of cooperation, understanding, and respect for all sentient beings. My experiences have shaped my leadership style, and I strive to be a thoughtful and just captain. How may I assist you further?
```

Pentru a menÈ›ine continuitatea conversaÈ›iei (Ã®n loc sÄƒ resetezi contextul de fiecare datÄƒ), trebuie sÄƒ continui sÄƒ adaugi rÄƒspunsurile Ã®n lista ta de mesaje. La fel ca tradiÈ›iile orale care au pÄƒstrat poveÈ™ti de-a lungul generaÈ›iilor, aceastÄƒ abordare construieÈ™te o memorie de duratÄƒ:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]


# funcÈ›ioneazÄƒ
response  = llm.invoke(messages)

print(response.content)

print("---- Next ----")

messages.append(response)
messages.append(HumanMessage(content="Now that I know about you, I'm Chris, can I be in your crew?"))

response  = llm.invoke(messages)

print(response.content)

```

Destul de tare, nu-i aÈ™a? Ce se Ã®ntÃ¢mplÄƒ aici este cÄƒ apelÄƒm LLM-ul de douÄƒ ori - mai Ã®ntÃ¢i cu doar primele douÄƒ mesaje, apoi din nou cu istoricul complet al conversaÈ›iei. E ca È™i cum AI-ul chiar ar urmÄƒri discuÈ›ia noastrÄƒ!

CÃ¢nd rulezi acest cod, vei primi un al doilea rÄƒspuns care sunÄƒ cam aÈ™a:

```text
Welcome aboard, Chris! It's always a pleasure to meet those who share a passion for exploration and discovery. While I cannot formally offer you a position on the Enterprise right now, I encourage you to pursue your aspirations. We are always in need of talented individuals with diverse skills and backgrounds. 

If you are interested in space exploration, consider education and training in the sciences, engineering, or diplomacy. The values of curiosity, resilience, and teamwork are crucial in Starfleet. Should you ever find yourself on a starship, remember to uphold the principles of the Federation: peace, understanding, and respect for all beings. Your journey can lead you to remarkable adventures, whether in the stars or on the ground. Engage!
```

```mermaid
sequenceDiagram
    participant User
    participant App
    participant LangChain
    participant AI
    
    User->>App: "Spune-mi despre tine"
    App->>LangChain: [SystemMessage, HumanMessage]
    LangChain->>AI: ConversaÈ›ie formatatÄƒ
    AI->>LangChain: RÄƒspunsul cÄƒpitanului Picard
    LangChain->>App: Obiect AIMessage
    App->>User: AfiÈ™eazÄƒ rÄƒspunsul
    
    Note over App: AdaugÄƒ AIMessage Ã®n conversaÈ›ie
    
    User->>App: "Pot sÄƒ mÄƒ alÄƒtur echipajului tÄƒu?"
    App->>LangChain: [SystemMessage, HumanMessage, AIMessage, HumanMessage]
    LangChain->>AI: Context complet al conversaÈ›iei
    AI->>LangChain: RÄƒspuns contextual
    LangChain->>App: Nou AIMessage
    App->>User: AfiÈ™eazÄƒ rÄƒspunsul contextual
```
Ia sÄƒ zicem cÄƒ asta e un â€poateâ€ ;)

## RÄƒspunsuri Ã®n streaming

Ai observat vreodatÄƒ cum ChatGPT pare sÄƒ â€tastezeâ€ rÄƒspunsurile Ã®n timp real? Asta este streaming Ã®n acÈ›iune. Ca atunci cÃ¢nd urmÄƒreÈ™ti un caligraf priceput lucrÃ¢nd - vezi caracterele apÄƒrÃ¢nd trÄƒsÄƒturÄƒ cu trÄƒsÄƒturÄƒ, nu instantaneu - streaming-ul face ca interacÈ›iunea sÄƒ parÄƒ mai naturalÄƒ È™i oferÄƒ feedback imediat.

### Implementarea streaming-ului cu LangChain

```python
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
    streaming=True
)

# Transmite rÄƒspunsul Ã®n flux
for chunk in llm.stream("Write a short story about a robot learning to code"):
    print(chunk.content, end="", flush=True)
```

**De ce este grozav streaming-ul:**
- **AratÄƒ** conÈ›inutul Ã®n timp ce e creat - gata cu aÈ™teptarea incomodÄƒ!
- **Face** utilizatorii sÄƒ simtÄƒ cÄƒ ceva chiar se Ã®ntÃ¢mplÄƒ
- **Pare** mai rapid, chiar dacÄƒ tehnic poate nu este
- **Permite** utilizatorilor sÄƒ Ã®nceapÄƒ sÄƒ citeascÄƒ Ã®n timp ce AI-ul Ã®ncÄƒ â€gÃ¢ndeÈ™teâ€

> ğŸ’¡ **Sfat UX**: Streaming-ul strÄƒluceÈ™te cu adevÄƒrat cÃ¢nd ai de-a face cu rÄƒspunsuri mai lungi, ca explicaÈ›ii de cod, scriere creativÄƒ sau tutoriale detaliate. Utilizatorii tÄƒi vor iubi sÄƒ vadÄƒ progresul Ã®n loc sÄƒ se uite la un ecran gol!

### ğŸ¯ Verificare pedagogicÄƒ: Beneficiile abstracÈ›iei Ã®n cadrul AI

**PauzÄƒ È™i ReflecÈ›ie**: Tocmai ai experimentat puterea abstracÈ›iilor cadrului AI. ComparÄƒ ce ai Ã®nvÄƒÈ›at cu apelurile API brute din lecÈ›iile anterioare.

**Autoevaluare rapidÄƒ:**
- PoÈ›i explica cum LangChain simplificÄƒ gestionarea conversaÈ›iilor comparativ cu urmÄƒrirea manualÄƒ a mesajelor?
- Care este diferenÈ›a dintre metodele `invoke()` È™i `stream()`, È™i cÃ¢nd ai folosi fiecare?
- Cum Ã®mbunÄƒtÄƒÈ›eÈ™te sistemul de tipuri de mesaje al cadrului organizarea codului?

**Conexiune cu lumea realÄƒ**: Modelele de abstractizare pe care le-ai Ã®nvÄƒÈ›at (tipuri de mesaje, interfeÈ›e streaming, memorie conversaÈ›ionalÄƒ) sunt folosite Ã®n fiecare aplicaÈ›ie majorÄƒ AI - de la interfaÈ›a ChatGPT la asistenÈ›a de cod GitHub Copilot. StÄƒpÃ¢neÈ™ti aceleaÈ™i modele arhitecturale folosite de echipele profesionale de dezvoltare AI.

**Ãntrebare provocatoare**: Cum ai proiecta o abstracÈ›ie de cadru pentru gestionarea diferiÈ›ilor furnizori de modele AI (OpenAI, Anthropic, Google) cu o singurÄƒ interfaÈ›Äƒ? Ia Ã®n considerare avantajele È™i compromisurile.

## È˜abloane de prompturi

È˜abloanele de prompturi funcÈ›ioneazÄƒ ca structurile retorice folosite Ã®n oratoria clasicÄƒ - gÃ¢ndeÈ™te-te cum Cicero Ã®È™i adapta tiparele discursului pentru audienÈ›e diferite pÄƒstrÃ¢nd acelaÈ™i cadru persuasiv. Ele Ã®È›i permit sÄƒ creezi prompturi reutilizabile unde poÈ›i Ã®nlocui diferite bucÄƒÈ›i de informaÈ›ie fÄƒrÄƒ sÄƒ rescrii totul de la zero. OdatÄƒ configurat È™ablonul, completezi doar variabilele cu valorile de care ai nevoie.

### Crearea prompturilor reutilizabile

```python
from langchain_core.prompts import ChatPromptTemplate

# DefineÈ™te un È™ablon pentru explicaÈ›iile codului
template = ChatPromptTemplate.from_messages([
    ("system", "You are an expert programming instructor. Explain concepts clearly with examples."),
    ("human", "Explain {concept} in {language} with a practical example for {skill_level} developers")
])

# FoloseÈ™te È™ablonul cu valori diferite
questions = [
    {"concept": "functions", "language": "JavaScript", "skill_level": "beginner"},
    {"concept": "classes", "language": "Python", "skill_level": "intermediate"},
    {"concept": "async/await", "language": "JavaScript", "skill_level": "advanced"}
]

for question in questions:
    prompt = template.format_messages(**question)
    response = llm.invoke(prompt)
    print(f"Topic: {question['concept']}\n{response.content}\n---\n")
```

**De ce o sÄƒ-È›i placÄƒ sÄƒ foloseÈ™ti È™abloane:**
- **PÄƒstreazÄƒ** prompturile constante Ã®n Ã®ntreaga aplicaÈ›ie
- **FÄƒrÄƒ** concatenÄƒri haotice de È™iruri - doar variabile curate È™i simple
- **AI-ul** tÄƒu se comportÄƒ previzibil pentru cÄƒ structura rÄƒmÃ¢ne aceeaÈ™i
- **ActualizÄƒrile** sunt floare la ureche - schimbi È™ablonul o singurÄƒ datÄƒ, È™i e corect peste tot

## IeÈ™ire structuratÄƒ

Te-ai enervat vreodatÄƒ Ã®ncercÃ¢nd sÄƒ parsezi rÄƒspunsuri AI care vin ca text neformatat? IeÈ™irea structuratÄƒ e ca È™i cum ai Ã®nvÄƒÈ›a AI-ul tÄƒu sÄƒ urmeze metoda sistematicÄƒ folositÄƒ de Linnaeus pentru clasificarea biologicÄƒ - organizatÄƒ, previzibilÄƒ È™i uÈ™or de folosit. PoÈ›i cere JSON, structuri de date specifice sau orice format ai nevoie.

### Definirea schemelor de ieÈ™ire

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel, Field

class CodeReview(BaseModel):
    score: int = Field(description="Code quality score from 1-10")
    strengths: list[str] = Field(description="List of code strengths")
    improvements: list[str] = Field(description="List of suggested improvements")
    overall_feedback: str = Field(description="Summary feedback")

# ConfigureazÄƒ parser-ul
parser = JsonOutputParser(pydantic_object=CodeReview)

# CreeazÄƒ promptul cu instrucÈ›iuni de format
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a code reviewer. {format_instructions}"),
    ("human", "Review this code: {code}")
])

# FormateazÄƒ promptul cu instrucÈ›iunile
chain = prompt | llm | parser

# ObÈ›ine rÄƒspunsul structurat
code_sample = """
def calculate_average(numbers):
    return sum(numbers) / len(numbers)
"""

result = chain.invoke({
    "code": code_sample,
    "format_instructions": parser.get_format_instructions()
})

print(f"Score: {result['score']}")
print(f"Strengths: {', '.join(result['strengths'])}")
```

**De ce ieÈ™irea structuratÄƒ schimbÄƒ regulile jocului:**
- **FÄƒrÄƒ** ghicit ce format vei primi Ã®napoi - e constant de fiecare datÄƒ
- **Se integreazÄƒ** direct Ã®n baze de date È™i API-uri fÄƒrÄƒ efort suplimentar
- **Prinde** rÄƒspunsuri AI ciudate Ã®nainte sÄƒ strice aplicaÈ›ia
- **Face** codul mai curat deoarece È™tii exact cu ce lucrezi

## Apelarea instrumentelor

Ajungem acum la una dintre cele mai puternice caracteristici: instrumentele. AÈ™a Ã®È›i oferi AI-ului tÄƒu capacitÄƒÈ›i practice dincolo de conversaÈ›ie. La fel cum breaslele medievale dezvoltau unelte specializate pentru meÈ™teÈ™uguri anume, poÈ›i echipa AI-ul cu instrumente concentrate. Descrii ce instrumente sunt disponibile, iar cÃ¢nd cineva solicitÄƒ ceva care se potriveÈ™te, AI-ul tÄƒu poate acÈ›iona.

### Folosind Python

SÄƒ adÄƒugÄƒm cÃ¢teva instrumente astfel:

```python
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # AnotÄƒrile trebuie sÄƒ aibÄƒ tipul È™i pot include opÈ›ional o valoare implicitÄƒ È™i o descriere (Ã®n aceastÄƒ ordine).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

tools = [add]

functions = {
    "add": lambda a, b: a + b
}
```

Deci ce se Ã®ntÃ¢mplÄƒ aici? CreÄƒm un È™ablon pentru un instrument numit `add`. Prin moÈ™tenirea de la `TypedDict` È™i folosirea aceloraÈ™i tipuri `Annotated` pentru `a` È™i `b`, Ã®i oferim LLM-ului o imagine clarÄƒ despre ce face acest instrument È™i ce are nevoie. DicÈ›ionarul `functions` este ca trusa noastrÄƒ de unelte - spune codului nostru exact ce sÄƒ facÄƒ cÃ¢nd AI-ul decide sÄƒ foloseascÄƒ un anumit instrument.

Hai sÄƒ vedem cum apelÄƒm LLM-ul cu acest instrument urmÄƒtor:

```python
llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)
```

Aici apelÄƒm `bind_tools` cu array-ul nostru de `tools` È™i astfel LLM-ul `llm_with_tools` are acum cunoÈ™tinÈ›a acestui instrument.

Ca sÄƒ folosim acest nou LLM, putem tasta urmÄƒtorul cod:

```python
query = "What is 3 + 12?"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

Acum cÄƒ apelÄƒm `invoke` pe acest nou llm, care are instrumente, este posibil sÄƒ avem proprietatea `tool_calls` populatÄƒ. DacÄƒ da, orice instrument identificat are o proprietate `name` È™i `args` care indicÄƒ ce instrument trebuie apelat È™i cu ce argumente. Codul complet aratÄƒ astfel:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # AnotÄƒrile trebuie sÄƒ aibÄƒ tipul È™i pot include opÈ›ional o valoare implicitÄƒ È™i o descriere (Ã®n aceastÄƒ ordine).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

tools = [add]

functions = {
    "add": lambda a, b: a + b
}

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)

query = "What is 3 + 12?"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

RulÃ¢nd acest cod, ar trebui sÄƒ vezi un output similar cu:

```text
TOOL CALL:  15
CONTENT: 
```

AI-ul a analizat â€Ce este 3 + 12â€ È™i a recunoscut aceasta ca o sarcinÄƒ pentru instrumentul `add`. AÈ™a cum un bibliotecar abil È™tie ce referinÈ›Äƒ sÄƒ consulte Ã®n funcÈ›ie de tipul Ã®ntrebÄƒrii, a fÄƒcut aceastÄƒ determinare pe baza numelui instrumentului, descrierii È™i specificaÈ›iilor cÃ¢mpului. Rezultatul de 15 vine din execuÈ›ia instrumentului prin dicÈ›ionarul nostru `functions`:

```python
print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
```

### Un instrument mai interesant care apeleazÄƒ o API web


AdÄƒugarea numerelor demonstreazÄƒ conceptul, dar uneltele reale efectueazÄƒ de obicei operaÈ›ii mai complexe, cum ar fi apelarea API-urilor web. SÄƒ extindem exemplul nostru astfel Ã®ncÃ¢t AI-ul sÄƒ preia conÈ›inut de pe internet - similar cu modul Ã®n care operatorii de telegraf conectau odinioarÄƒ locaÈ›ii Ã®ndepÄƒrtate:

```python
class joke(TypedDict):
    """Tell a joke."""

    # AnotÄƒrile trebuie sÄƒ aibÄƒ tipul È™i pot include opÈ›ional o valoare implicitÄƒ È™i o descriere (Ã®n aceastÄƒ ordine).
    category: Annotated[str, ..., "The joke category"]

def get_joke(category: str) -> str:
    response = requests.get(f"https://api.chucknorris.io/jokes/random?category={category}", headers={"Accept": "application/json"})
    if response.status_code == 200:
        return response.json().get("value", f"Here's a {category} joke!")
    return f"Here's a {category} joke!"

functions = {
    "add": lambda a, b: a + b,
    "joke": lambda category: get_joke(category)
}

query = "Tell me a joke about animals"

# restul codului este la fel
```

Acum, dacÄƒ vei rula acest cod, vei primi un rÄƒspuns care spune ceva de genul:

```text
TOOL CALL:  Chuck Norris once rode a nine foot grizzly bear through an automatic car wash, instead of taking a shower.
CONTENT:  
```

```mermaid
flowchart TD
    A[Interogare utilizator: "Spune-mi o glumÄƒ despre animale"] --> B[AnalizÄƒ LangChain]
    B --> C{Instrument disponibil?}
    C -->|Da| D[SelecteazÄƒ instrumentul pentru glume]
    C -->|Nu| E[GenereazÄƒ rÄƒspuns direct]
    
    D --> F[Extrage parametrii]
    F --> G[ApeleazÄƒ gluma(categorie="animale")]
    G --> H[Cerere API cÄƒtre chucknorris.io]
    H --> I[ReturneazÄƒ conÈ›inutul glumei]
    I --> J[AfiÈ™eazÄƒ utilizatorului]
    
    E --> K[RÄƒspuns generat de AI]
    K --> J
    
    subgraph "Stratul de definiÈ›ie al instrumentului"
        L[Schema TypedDict]
        M[Implementarea funcÈ›iei]
        N[Validarea parametrilor]
    end
    
    D --> L
    F --> N
    G --> M
```
IatÄƒ codul Ã®n Ã®ntregime:

```python
from langchain_openai import ChatOpenAI
import requests
import os
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # AnotaÈ›iile trebuie sÄƒ aibÄƒ tipul È™i pot include opÈ›ional o valoare implicitÄƒ È™i o descriere (Ã®n aceastÄƒ ordine).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

class joke(TypedDict):
    """Tell a joke."""

    # AnotaÈ›iile trebuie sÄƒ aibÄƒ tipul È™i pot include opÈ›ional o valoare implicitÄƒ È™i o descriere (Ã®n aceastÄƒ ordine).
    category: Annotated[str, ..., "The joke category"]

tools = [add, joke]

def get_joke(category: str) -> str:
    response = requests.get(f"https://api.chucknorris.io/jokes/random?category={category}", headers={"Accept": "application/json"})
    if response.status_code == 200:
        return response.json().get("value", f"Here's a {category} joke!")
    return f"Here's a {category} joke!"

functions = {
    "add": lambda a, b: a + b,
    "joke": lambda category: get_joke(category)
}

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)

query = "Tell me a joke about animals"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        # print("APEL INSTRUMENT: ", tool)
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

## Embeddings È™i procesarea documentelor

Embeddings reprezintÄƒ una dintre cele mai elegante soluÈ›ii din AI-ul modern. ImagineazÄƒ-È›i cÄƒ ai putea lua orice fragment de text È™i sÄƒ Ã®l converteÈ™ti Ã®n coordonate numerice care captureazÄƒ semnificaÈ›ia sa. Exact asta fac embeddings - transformÄƒ textul Ã®n puncte Ã®ntr-un spaÈ›iu multidimensional unde conceptele similare se grupeazÄƒ Ã®mpreunÄƒ. E ca È™i cum ai avea un sistem de coordonate pentru idei, asemÄƒnÄƒtor modului Ã®n care Mendeleev a organizat tabelul periodic dupÄƒ proprietÄƒÈ›i atomice.

### Crearea È™i utilizarea embeddings

```python
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter

# IniÈ›ializeazÄƒ Ã®ncorporÄƒrile
embeddings = OpenAIEmbeddings(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="text-embedding-3-small"
)

# ÃncarcÄƒ È™i Ã®mparte documentele
loader = TextLoader("documentation.txt")
documents = loader.load()

text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(documents)

# CreeazÄƒ un depozit vectorial
vectorstore = FAISS.from_documents(texts, embeddings)

# EfectueazÄƒ cÄƒutare dupÄƒ similaritate
query = "How do I handle user authentication?"
similar_docs = vectorstore.similarity_search(query, k=3)

for doc in similar_docs:
    print(f"Relevant content: {doc.page_content[:200]}...")
```

### Loader-e de documente pentru diverse formate

```python
from langchain_community.document_loaders import (
    PyPDFLoader,
    CSVLoader,
    JSONLoader,
    WebBaseLoader
)

# ÃncarcÄƒ diferite tipuri de documente
pdf_loader = PyPDFLoader("manual.pdf")
csv_loader = CSVLoader("data.csv")
json_loader = JSONLoader("config.json")
web_loader = WebBaseLoader("https://example.com/docs")

# ProceseazÄƒ toate documentele
all_documents = []
for loader in [pdf_loader, csv_loader, json_loader, web_loader]:
    docs = loader.load()
    all_documents.extend(docs)
```

**Ce poÈ›i face cu embeddings:**
- **Construi** cÄƒutÄƒri care Ã®nÈ›eleg cu adevÄƒrat ce vrei sÄƒ spui, nu doar potrivire de cuvinte-cheie
- **Crea** AI care poate rÄƒspunde la Ã®ntrebÄƒri despre documentele tale
- **Realiza** sisteme de recomandÄƒri care sugereazÄƒ conÈ›inut cu adevÄƒrat relevant
- **Organiza** È™i **categoria** automat conÈ›inutul tÄƒu

```mermaid
flowchart LR
    A[Documente] --> B[Segmentator de text]
    B --> C[Creare de Ã®ncorporÄƒri]
    C --> D[Magazin vectorial]
    
    E[Interogare utilizator] --> F[Ãncorporare interogare]
    F --> G[CÄƒutare similaritate]
    G --> D
    D --> H[Documente relevante]
    H --> I[RÄƒspuns AI]
    
    subgraph "SpaÈ›iu vectorial"
        J[Document A: [0.1, 0.8, 0.3...]]
        K[Document B: [0.2, 0.7, 0.4...]]
        L[Interogare: [0.15, 0.75, 0.35...]]
    end
    
    C --> J
    C --> K
    F --> L
    G --> J
    G --> K
```
## Construirea unei aplicaÈ›ii AI complete

Acum vom integra tot ce ai Ã®nvÄƒÈ›at Ã®ntr-o aplicaÈ›ie cuprinzÄƒtoare - un asistent de programare care poate rÄƒspunde la Ã®ntrebÄƒri, foloseÈ™te unelte È™i pÄƒstreazÄƒ memoria conversaÈ›iei. Asemenea felului Ã®n care presa de tipar a combinat tehnologii existente (tipar mobil, cernealÄƒ, hÃ¢rtie È™i presiune) Ã®ntr-un ceva transformator, vom combina componentele noastre AI Ã®ntr-un ceva practic È™i util.

### Exemplu de aplicaÈ›ie completÄƒ

```python
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_community.vectorstores import FAISS
from typing_extensions import Annotated, TypedDict
import os
import requests

class CodingAssistant:
    def __init__(self):
        self.llm = ChatOpenAI(
            api_key=os.environ["GITHUB_TOKEN"],
            base_url="https://models.github.ai/inference",
            model="openai/gpt-4o-mini"
        )
        
        self.conversation_history = [
            SystemMessage(content="""You are an expert coding assistant. 
            Help users learn programming concepts, debug code, and write better software.
            Use tools when needed and maintain a helpful, encouraging tone.""")
        ]
        
        # DefineÈ™te uneltele
        self.setup_tools()
    
    def setup_tools(self):
        class web_search(TypedDict):
            """Search for programming documentation or examples."""
            query: Annotated[str, "Search query for programming help"]
        
        class code_formatter(TypedDict):
            """Format and validate code snippets."""
            code: Annotated[str, "Code to format"]
            language: Annotated[str, "Programming language"]
        
        self.tools = [web_search, code_formatter]
        self.llm_with_tools = self.llm.bind_tools(self.tools)
    
    def chat(self, user_input: str):
        # AdaugÄƒ mesajul utilizatorului la conversaÈ›ie
        self.conversation_history.append(HumanMessage(content=user_input))
        
        # ObÈ›ine rÄƒspunsul AI
        response = self.llm_with_tools.invoke(self.conversation_history)
        
        # GestioneazÄƒ apelurile instrumentelor, dacÄƒ existÄƒ
        if response.tool_calls:
            for tool_call in response.tool_calls:
                tool_result = self.execute_tool(tool_call)
                print(f"ğŸ”§ Tool used: {tool_call['name']}")
                print(f"ğŸ“Š Result: {tool_result}")
        
        # AdaugÄƒ rÄƒspunsul AI la conversaÈ›ie
        self.conversation_history.append(response)
        
        return response.content
    
    def execute_tool(self, tool_call):
        tool_name = tool_call['name']
        args = tool_call['args']
        
        if tool_name == 'web_search':
            return f"Found documentation for: {args['query']}"
        elif tool_name == 'code_formatter':
            return f"Formatted {args['language']} code: {args['code'][:50]}..."
        
        return "Tool execution completed"

# Exemplu de utilizare
assistant = CodingAssistant()

print("ğŸ¤– Coding Assistant Ready! Type 'quit' to exit.\n")

while True:
    user_input = input("You: ")
    if user_input.lower() == 'quit':
        break
    
    response = assistant.chat(user_input)
    print(f"ğŸ¤– Assistant: {response}\n")
```

**Arhitectura aplicaÈ›iei:**

```mermaid
graph TD
    A[Intrare Utilizator] --> B[Asistent Programare]
    B --> C[Memorie ConversaÈ›ie]
    B --> D[Detectare UnealtÄƒ]
    B --> E[Procesare LLM]
    
    D --> F[UnealtÄƒ CÄƒutare Web]
    D --> G[UnealtÄƒ Formatare Cod]
    
    E --> H[Generare RÄƒspuns]
    F --> H
    G --> H
    
    H --> I[InterfaÈ›Äƒ Utilizator]
    H --> C
```
**Caracteristici cheie implementate:**
- **PÄƒstreazÄƒ** Ã®ntreaga conversaÈ›ie pentru continuitatea contextului
- **ExecutÄƒ acÈ›iuni** prin apelarea uneltelor, nu doar conversaÈ›ie
- **UrmÄƒreÈ™te** tipare previzibile de interacÈ›iune
- **GestioneazÄƒ** automat tratarea erorilor È™i fluxuri de lucru complexe

### ğŸ¯ Verificare pedagogicÄƒ: Arhitectura AI de producÈ›ie

**ÃnÈ›elegerea arhitecturii**: Ai construit o aplicaÈ›ie AI completÄƒ care combinÄƒ managementul conversaÈ›iei, apelarea uneltelor È™i fluxuri de lucru structurate. Aceasta reprezintÄƒ dezvoltarea unei aplicaÈ›ii AI la nivel de producÈ›ie.

**Concepte cheie stÄƒpÃ¢nite**:
- **ArhitecturÄƒ bazatÄƒ pe clase**: structurÄƒ organizatÄƒ È™i uÈ™or de Ã®ntreÈ›inut pentru aplicaÈ›ii AI
- **Integrarea uneltelor**: funcÈ›ionalitate personalizatÄƒ dincolo de conversaÈ›ie
- **Managementul memoriei**: context persistent al conversaÈ›iei
- **Tratamentul erorilor**: comportament robust al aplicaÈ›iei

**Conexiune cu industria**: Modelele arhitecturale pe care le-ai implementat (clase de conversaÈ›ie, sisteme de unelte, managementul memoriei) sunt aceleaÈ™i utilizate Ã®n aplicaÈ›iile AI ale corporaÈ›iilor precum asistentul AI Slack, GitHub Copilot È™i Microsoft Copilot. ConstruieÈ™ti cu o gÃ¢ndire arhitecturalÄƒ profesionalÄƒ.

**Ãntrebare de reflecÈ›ie**: Cum ai extinde aceastÄƒ aplicaÈ›ie pentru a gestiona utilizatori multipli, stocare persistentÄƒ sau integrare cu baze de date externe? Ia Ã®n considerare provocÄƒrile scalabilitÄƒÈ›ii È™i gestionÄƒrii stÄƒrii.

## Tema: ConstruieÈ™te-È›i propriul asistent de studiu alimentat de AI

**Obiectiv**: CreeazÄƒ o aplicaÈ›ie AI care sÄƒ ajute studenÈ›ii sÄƒ Ã®nveÈ›e concepte de programare oferind explicaÈ›ii, exemple de cod È™i quiz-uri interactive.

### CerinÈ›e

**FuncÈ›ionalitÄƒÈ›i de bazÄƒ (obligatorii):**
1. **InterfaÈ›Äƒ conversaÈ›ionalÄƒ**: implementeazÄƒ un sistem de chat care pÄƒstreazÄƒ contextul pe mai multe Ã®ntrebÄƒri
2. **Unelte educaÈ›ionale**: creeazÄƒ cel puÈ›in douÄƒ unelte care ajutÄƒ la Ã®nvÄƒÈ›are:
   - unealtÄƒ de explicare a codului
   - generator de quiz-uri despre concepte
3. **ÃnvÄƒÈ›are personalizatÄƒ**: foloseÈ™te mesaje de sistem pentru a adapta rÄƒspunsurile la niveluri diferite de abilitate
4. **Formatare a rÄƒspunsului**: implementeazÄƒ un output structurat pentru Ã®ntrebÄƒrile de quiz

### PaÈ™i pentru implementare

**Pasul 1: Configurarea mediului**
```bash
pip install langchain langchain-openai
```

**Pasul 2: FuncÈ›ionalitate de bazÄƒ chat**
- CreeazÄƒ o clasÄƒ `StudyAssistant`
- ImplementeazÄƒ memoria conversaÈ›iei
- AdaugÄƒ configurare de personalitate pentru suport educaÈ›ional

**Pasul 3: AdaugÄƒ unelte educaÈ›ionale**
- **Explicator de cod**: descompune codul Ã®n pÄƒrÈ›i uÈ™or de Ã®nÈ›eles
- **Generator de quiz**: creeazÄƒ Ã®ntrebÄƒri despre concepte de programare
- **UrmÄƒritor de progres**: È›ine evidenÈ›a subiectelor abordate

**Pasul 4: FuncÈ›ionalitÄƒÈ›i Ã®mbunÄƒtÄƒÈ›ite (opÈ›ional)**
- ImplementeazÄƒ streaming al rÄƒspunsurilor pentru o experienÈ›Äƒ mai bunÄƒ
- AdaugÄƒ Ã®ncÄƒrcarea documentelor pentru a integra materiale de curs
- CreeazÄƒ embeddings pentru recuperarea conÈ›inutului bazatÄƒ pe similaritate

### Criterii de evaluare

| FuncÈ›ionalitate | Excelent (4) | Bun (3) | SatisfÄƒcÄƒtor (2) | NecesitÄƒ Ã®mbunÄƒtÄƒÈ›iri (1) |
|-----------------|--------------|---------|------------------|---------------------------|
| **Flux conversaÈ›ional** | RÄƒspunsuri naturale, conÈ™tiente de context | PÄƒstreazÄƒ bine contextul | ConversaÈ›ie de bazÄƒ | FÄƒrÄƒ memorie Ã®ntre schimburi |
| **Integrare unelte** | Multe unelte utile care funcÈ›ioneazÄƒ perfect | 2+ unelte implementate corect | 1-2 unelte de bazÄƒ | Uneltele nu funcÈ›ioneazÄƒ |
| **Calitatea codului** | Curat, bine documentat, tratare erori | StructurÄƒ bunÄƒ, ceva documentaÈ›ie | FuncÈ›ionalitate de bazÄƒ | StructurÄƒ slabÄƒ, fÄƒrÄƒ tratare erori |
| **Valoare educaÈ›ionalÄƒ** | Cu adevÄƒrat util pentru Ã®nvÄƒÈ›are, adaptiv | Suport bun pentru Ã®nvÄƒÈ›are | ExplicaÈ›ii de bazÄƒ | Beneficiu educaÈ›ional limitat |

### StructurÄƒ exemplu de cod

```python
class StudyAssistant:
    def __init__(self, skill_level="beginner"):
        # IniÈ›ializeazÄƒ LLM, uneltele È™i memoria conversaÈ›iei
        pass
    
    def explain_code(self, code, language):
        # UnealtÄƒ: ExplicÄƒ cum funcÈ›ioneazÄƒ codul
        pass
    
    def generate_quiz(self, topic, difficulty):
        # UnealtÄƒ: CreeazÄƒ Ã®ntrebÄƒri de practicÄƒ
        pass
    
    def chat(self, user_input):
        # InterfaÈ›a principalÄƒ a conversaÈ›iei
        pass

# Exemplu de utilizare
assistant = StudyAssistant(skill_level="intermediate")
response = assistant.chat("Explain how Python functions work")
```

**ProvocÄƒri bonus:**
- AdaugÄƒ capabilitÄƒÈ›i voce input/output
- ImplementeazÄƒ o interfaÈ›Äƒ web folosind Streamlit sau Flask
- CreeazÄƒ o bazÄƒ de cunoÈ™tinÈ›e din materiale de curs cu embeddings
- AdaugÄƒ urmÄƒrirea progresului È™i cÄƒi personalizate de Ã®nvÄƒÈ›are

## ğŸ“ˆ Cronologia stÄƒpÃ¢nirii dezvoltÄƒrii framework-ului AI

```mermaid
timeline
    title CÄƒlÄƒtoria DezvoltÄƒrii Cadrului AI pentru ProducÈ›ie
    
    section Fundamentele Cadrului
        ÃnÈ›elegerea AbstractizÄƒrilor
            : Decizii Master framework vs API
            : ÃnvÄƒÈ›area conceptelor de bazÄƒ LangChain
            : Implementarea sistemelor de tipuri de mesaje
        
        Integrare de BazÄƒ
            : Conectare la furnizori AI
            : Gestionarea autentificÄƒrii
            : Administrarea configuraÈ›iei
    
    section Sisteme de Convorbire
        Managementul Memoriei
            : Construirea istoricului conversaÈ›iilor
            : Implementarea urmÄƒririi contextului
            : Gestionarea persistenÈ›ei sesiunii
        
        InteracÈ›iuni Avansate
            : StÄƒpÃ¢nirea rÄƒspunsurilor Ã®n streaming
            : Crearea È™abloanelor de prompturi
            : Implementarea ieÈ™irii structurate
    
    section Integrarea Uneltelor
        Dezvoltarea Uneltelor Personalizate
            : Proiectarea schemelor uneltelor
            : Implementarea apelÄƒrii funcÈ›iilor
            : Gestionarea API-urilor externe
        
        Automatizarea Fluxurilor de Lucru
            : LanÈ›uirea mai multor unelte
            : Crearea arborilor decizionali
            : Construirea comportamentelor agenÈ›ilor
    
    section AplicaÈ›ii de ProducÈ›ie
        Arhitectura CompletÄƒ a Sistemului
            : Combinarea tuturor funcÈ›iilor cadrului
            : Implementarea limitÄƒrilor erorilor
            : Crearea codului uÈ™or de Ã®ntreÈ›inut
        
        PregÄƒtirea pentru Ãntreprinderi
            : Gestionarea preocupÄƒrilor privind scalabilitatea
            : Implementarea monitorizÄƒrii
            : Construirea strategiilor de implementare
```
**ğŸ“ Punct de absolvire**: Ai stÄƒpÃ¢nit cu succes dezvoltarea framework-ului AI folosind aceleaÈ™i unelte È™i modele care animÄƒ aplicaÈ›iile AI moderne. Aceste competenÈ›e reprezintÄƒ vÃ¢rful dezvoltÄƒrii aplicaÈ›iilor AI È™i te pregÄƒtesc pentru a construi sisteme inteligente la nivel enterprise.

**ğŸ”„ CapacitÄƒÈ›i urmÄƒtor nivel**:
- EÈ™ti gata sÄƒ explorezi arhitecturi AI avansate (agenÈ›i, sisteme multi-agent)
- PregÄƒtit sÄƒ construieÈ™ti sisteme RAG cu baze de date vectoriale
- Echipat sÄƒ creezi aplicaÈ›ii AI multimodale
- Fundament pus pentru scalarea È™i optimizarea aplicaÈ›iilor AI

## Rezumat

ğŸ‰ Acum ai stÄƒpÃ¢nit fundamentele dezvoltÄƒrii framework-ului AI È™i ai Ã®nvÄƒÈ›at sÄƒ construieÈ™ti aplicaÈ›ii AI sofisticate folosind LangChain. Ca È™i cum ai termina un stagiu complet, ai dobÃ¢ndit o trusÄƒ de unelte substanÈ›ialÄƒ. SÄƒ recapitulezi ce ai realizat.

### Ce ai Ã®nvÄƒÈ›at

**Concepte fundamentale ale framework-ului:**
- **Avantajele framework-urilor**: cÃ¢nd sÄƒ alegi framework-uri Ã®n locul apelurilor directe la API-uri
- **Bazele LangChain**: configurarea È™i conectarea modelelor AI
- **Tipuri de mesaje**: folosirea `SystemMessage`, `HumanMessage` È™i `AIMessage` pentru conversaÈ›ii structurate

**FuncÈ›ionalitÄƒÈ›i avansate:**
- **Apelarea uneltelor**: crearea È™i integrarea uneltelor personalizate pentru capabilitÄƒÈ›i AI extinse
- **Memoria conversaÈ›iei**: menÈ›inerea contextului pe mai multe schimburi de conversaÈ›ie
- **RÄƒspunsuri Ã®n streaming**: implementarea livrÄƒrii rÄƒspunsurilor Ã®n timp real
- **È˜abloane de prompturi**: construirea prompturilor reutilizabile È™i dinamice
- **Output structurat**: asigurarea unor rÄƒspunsuri AI consistente È™i parsabile
- **Embeddings**: crearea de capacitÄƒÈ›i de cÄƒutare semanticÄƒ È™i procesare documentarÄƒ

**AplicaÈ›ii practice:**
- **Construirea aplicaÈ›iilor complete**: combinarea mai multor funcÈ›iile pentru aplicaÈ›ii gata de producÈ›ie
- **Gestionarea erorilor**: implementarea unui management robust al erorilor È™i validÄƒrii
- **Integrarea uneltelor**: crearea de unelte personalizate care extind capabilitÄƒÈ›ile AI

### Concluzii cheie

> ğŸ¯ **AminteÈ™te-È›i**: Framework-urile AI precum LangChain sunt practic prietenii tÄƒi cei mai buni care ascund complexitatea È™i oferÄƒ multe funcÈ›ionalitÄƒÈ›i. Sunt perfecte cÃ¢nd ai nevoie de memorie a conversaÈ›iei, apelarea uneltelor sau vrei sÄƒ lucrezi cu mai multe modele AI fÄƒrÄƒ sÄƒ Ã®È›i pierzi minÈ›ile.

**Cadru decizional pentru integrarea AI:**

```mermaid
flowchart TD
    A[Necesitate integrare AI] --> B{Interogare simplÄƒ unicÄƒ?}
    B -->|Da| C[Apeluri API directe]
    B -->|Nu| D{Este nevoie de memorie pentru conversaÈ›ie?}
    D -->|Nu| E[Integrare SDK]
    D -->|Da| F{Sunt necesare unelte sau funcÈ›ii complexe?}
    F -->|Nu| G[Cadru cu setup de bazÄƒ]
    F -->|Da| H[Implementare completÄƒ a cadrului]
    
    C --> I[Cereri HTTP, dependenÈ›e minime]
    E --> J[SDK furnizor, specific model]
    G --> K[Chat de bazÄƒ LangChain]
    H --> L[LangChain cu unelte, memorie, agenÈ›i]
```
### Ce urmeazÄƒ?

**Ãncepe sÄƒ construieÈ™ti acum:**
- Ia aceste concepte È™i construieÈ™te ceva ce te entuziasmeazÄƒ PE TINE!
- ExperimenteazÄƒ cu diverse modele AI prin LangChain - e ca È™i cum ai avea un teren de joacÄƒ pentru modele AI
- CreeazÄƒ unelte care rezolvÄƒ probleme reale cu care te confrunÈ›i Ã®n munca sau proiectele tale

**PregÄƒtit pentru urmÄƒtorul nivel?**
- **AgenÈ›i AI**: ConstruieÈ™te sisteme AI care pot planifica È™i executa sarcini complexe singure
- **RAG (Generare AugmentatÄƒ cu Recuperare)**: CombinÄƒ AI cu bazele tale de cunoÈ™tinÈ›e pentru aplicaÈ›ii superputernice
- **AI multimodal**: LucreazÄƒ cu text, imagini È™i audio Ã®mpreunÄƒ - posibilitÄƒÈ›ile sunt nelimitate!
- **Implementare Ã®n producÈ›ie**: ÃnvaÈ›Äƒ cum sÄƒ scalezi aplicaÈ›iile tale AI È™i sÄƒ le monitorizezi Ã®n lumea realÄƒ

**AlÄƒturÄƒ-te comunitÄƒÈ›ii:**
- Comunitatea LangChain este excelentÄƒ pentru a rÄƒmÃ¢ne la curent È™i a Ã®nvÄƒÈ›a cele mai bune practici
- GitHub Models Ã®È›i oferÄƒ acces la capabilitÄƒÈ›i AI de ultimÄƒ orÄƒ - perfect pentru experimentare
- ContinuÄƒ sÄƒ exersezi cu diferite cazuri de utilizare - fiecare proiect Ã®È›i va Ã®nvÄƒÈ›a ceva nou

Acum ai cunoÈ™tinÈ›ele necesare sÄƒ construieÈ™ti aplicaÈ›ii inteligente, conversaÈ›ionale care pot ajuta oamenii sÄƒ rezolve probleme reale. Ca meÈ™terii RenaÈ™terii care Ã®mbinau viziunea artisticÄƒ cu priceperea tehnicÄƒ, poÈ›i acum sÄƒ combini capabilitÄƒÈ›ile AI cu aplicabilitatea practicÄƒ. Ãntrebarea este: ce vei crea? ğŸš€

## Provocarea Agentului GitHub Copilot ğŸš€

FoloseÈ™te modul Agent pentru a finaliza urmÄƒtoarea provocare:

**Descriere:** ConstruieÈ™te un asistent avansat de revizuire de cod alimentat de AI care combinÄƒ multiple funcÈ›ionalitÄƒÈ›i LangChain, inclusiv apelarea uneltelor, output structurat È™i memorie conversaÈ›ionalÄƒ pentru a oferi feedback detaliat asupra trimiterilor de cod.

**Prompt:** CreeazÄƒ o clasÄƒ CodeReviewAssistant care implementeazÄƒ:
1. O unealtÄƒ pentru analizarea complexitÄƒÈ›ii codului È™i sugestii de Ã®mbunÄƒtÄƒÈ›iri
2. O unealtÄƒ pentru verificarea codului Ã®n raport cu cele mai bune practici
3. Output structurat folosind modele Pydantic pentru un format de revizuire consistent
4. Memorie conversaÈ›ionalÄƒ pentru urmÄƒrirea sesiunilor de revizuire
5. O interfaÈ›Äƒ principalÄƒ de chat care poate prelua trimiteri de cod È™i oferÄƒ feedback detaliat, acÈ›ionabil

Asistentul trebuie sÄƒ poatÄƒ revizui cod Ã®n mai multe limbaje de programare, sÄƒ pÄƒstreze contextul pe mai multe trimiteri de cod Ã®ntr-o sesiune È™i sÄƒ ofere atÃ¢t scoruri sumare, cÃ¢t È™i sugestii detaliate de Ã®mbunÄƒtÄƒÈ›ire.

AflÄƒ mai multe despre [agent mode](https://code.visualstudio.com/blogs/2025/02/24/introducing-copilot-agent-mode) aici.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Declinarea rÄƒspunderii**:  
Acest document a fost tradus folosind serviciul de traducere automatÄƒ AI [Co-op Translator](https://github.com/Azure/co-op-translator). DeÈ™i ne strÄƒduim pentru acurateÈ›e, vÄƒ rugÄƒm sÄƒ aveÈ›i Ã®n vedere cÄƒ traducerile automate pot conÈ›ine erori sau inexactitÄƒÈ›i. Documentul original, Ã®n limba sa nativÄƒ, trebuie considerat sursa autoritarÄƒ. Pentru informaÈ›ii critice, se recomandÄƒ o traducere profesionalÄƒ realizatÄƒ de un traducÄƒtor uman. Nu ne asumÄƒm responsabilitatea pentru eventualele neÃ®nÈ›elegeri sau interpretÄƒri greÈ™ite ce pot rezulta din utilizarea acestei traduceri.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->