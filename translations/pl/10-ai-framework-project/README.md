<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3925b6a1c31c60755eaae4d578232c25",
  "translation_date": "2026-01-06T18:43:07+00:00",
  "source_file": "10-ai-framework-project/README.md",
  "language_code": "pl"
}
-->
# AI Framework

Czy kiedykolwiek czuÅ‚eÅ› siÄ™ przytÅ‚oczony, prÃ³bujÄ…c budowaÄ‡ aplikacje AI od podstaw? Nie jesteÅ› sam! Frameworki AI to jak szwajcarski scyzoryk dla programistÃ³w AI â€“ to potÄ™Å¼ne narzÄ™dzia, ktÃ³re mogÄ… zaoszczÄ™dziÄ‡ Ci czas i bÃ³le gÅ‚owy podczas tworzenia inteligentnych aplikacji. PomyÅ›l o frameworku AI jak o dobrze zorganizowanej bibliotece: zapewnia gotowe komponenty, ustandaryzowane API i sprytne abstrakcje, dziÄ™ki czemu moÅ¼esz skupiÄ‡ siÄ™ na rozwiÄ…zywaniu problemÃ³w zamiast zmagaÄ‡ siÄ™ ze szczegÃ³Å‚ami implementacji.

W tej lekcji odkryjemy, jak frameworki takie jak LangChain mogÄ… zamieniÄ‡ kiedyÅ› skomplikowane zadania integracji AI w czysty, czytelny kod. Dowiesz siÄ™, jak radziÄ‡ sobie z rzeczywistymi wyzwaniami, takimi jak Å›ledzenie rozmÃ³w, implementacja wywoÅ‚ywania narzÄ™dzi i zarzÄ…dzanie rÃ³Å¼nymi modelami AI za pomocÄ… jednego zunifikowanego interfejsu.

Po ukoÅ„czeniu dowiesz siÄ™, kiedy siÄ™gnÄ…Ä‡ po frameworki zamiast surowych wywoÅ‚aÅ„ API, jak efektywnie korzystaÄ‡ z ich abstrakcji i jak budowaÄ‡ aplikacje AI gotowe na rzeczywiste zastosowania. Poznajmy, co frameworki AI mogÄ… zrobiÄ‡ dla Twoich projektÃ³w.

## âš¡ Co moÅ¼esz zrobiÄ‡ w nastÄ™pnych 5 minut

**Szybki start dla zapracowanych programistÃ³w**

```mermaid
flowchart LR
    A[âš¡ 5 minut] --> B[Zainstaluj LangChain]
    B --> C[UtwÃ³rz klienta ChatOpenAI]
    C --> D[WyÅ›lij pierwsze zapytanie]
    D --> E[Zobacz moc frameworka]
```
- **Minuta 1**: Zainstaluj LangChain: `pip install langchain langchain-openai`
- **Minuta 2**: Skonfiguruj swÃ³j token GitHub i zaimportuj klienta ChatOpenAI
- **Minuta 3**: StwÃ³rz prostÄ… rozmowÄ™ z wiadomoÅ›ciami systemowymi i od czÅ‚owieka
- **Minuta 4**: Dodaj podstawowe narzÄ™dzie (np. funkcjÄ™ dodawania) i zobacz wywoÅ‚ywanie narzÄ™dzi AI
- **Minuta 5**: DoÅ›wiadcz rÃ³Å¼nicy miÄ™dzy surowymi wywoÅ‚aniami API a abstrakcjÄ… frameworku

**Szybki test kodu**:
```python
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini"
)

response = llm.invoke([
    SystemMessage(content="You are a helpful coding assistant"),
    HumanMessage(content="Explain Python functions briefly")
])
print(response.content)
```

**Dlaczego to waÅ¼ne**: W ciÄ…gu 5 minut zobaczysz, jak frameworki AI przeksztaÅ‚cajÄ… skomplikowanÄ… integracjÄ™ AI w proste wywoÅ‚ania metod. To fundament, ktÃ³ry napÄ™dza produkcyjne aplikacje AI.

## Dlaczego warto wybraÄ‡ framework?

JesteÅ› gotowy, aby zbudowaÄ‡ aplikacjÄ™ AI â€“ super! Ale sprawa wyglÄ…da tak: masz kilka rÃ³Å¼nych Å›cieÅ¼ek do wyboru, a kaÅ¼da z nich ma swoje plusy i minusy. To trochÄ™ jak wybÃ³r miÄ™dzy chodzeniem, jazdÄ… na rowerze lub autem, Å¼eby gdzieÅ› dotrzeÄ‡ â€“ wszystkie sposoby doprowadzÄ… CiÄ™ do celu, ale doÅ›wiadczenie (i wysiÅ‚ek) bÄ™dÄ… zupeÅ‚nie inne.

RozÅ‚oÅ¼ymy na czynniki pierwsze trzy gÅ‚Ã³wne sposoby integracji AI w Twoich projektach:

| PodejÅ›cie | Zalety | Najlepsze do | Uwagi |
|----------|------------|----------|--------------|
| **BezpoÅ›rednie Å¼Ä…dania HTTP** | PeÅ‚na kontrola, brak zaleÅ¼noÅ›ci | Proste zapytania, nauka podstaw | Bardziej rozbudowany kod, rÄ™czne obsÅ‚ugiwanie bÅ‚Ä™dÃ³w |
| **Integracja SDK** | Mniej boilerplateâ€™u, optymalizacje specyficzne dla modelu | Aplikacje z jednym modelem | Ograniczone do konkretnych dostawcÃ³w |
| **Frameworki AI** | Zunifikowane API, wbudowane abstrakcje | Aplikacje wielomodelowe, zÅ‚oÅ¼one przepÅ‚ywy | Krzywa nauki, moÅ¼liwoÅ›Ä‡ nadmiernej abstrakcji |

### KorzyÅ›ci z frameworkÃ³w w praktyce

```mermaid
graph TD
    A[Twoja Aplikacja] --> B[Framework AI]
    B --> C[OpenAI GPT]
    B --> D[Anthropic Claude]
    B --> E[Modele GitHub]
    B --> F[Modele Lokalnie]
    
    B --> G[NarzÄ™dzia Wbudowane]
    G --> H[ZarzÄ…dzanie PamiÄ™ciÄ…]
    G --> I[Historia Konwersacji]
    G --> J[WywoÅ‚ywanie Funkcji]
    G --> K[ObsÅ‚uga BÅ‚Ä™dÃ³w]
```
**Dlaczego frameworki sÄ… waÅ¼ne:**
- **IntegrujÄ…** wielu dostawcÃ³w AI pod jednym interfejsem
- **ObsÅ‚ugujÄ…** pamiÄ™Ä‡ rozmowy automatycznie
- **DostarczajÄ…** gotowe narzÄ™dzia do typowych zadaÅ„ jak embeddingi i wywoÅ‚ywanie funkcji
- **ZarzÄ…dzajÄ…** obsÅ‚ugÄ… bÅ‚Ä™dÃ³w i logikÄ… ponowieÅ„
- **PrzeksztaÅ‚cajÄ…** skomplikowane przepÅ‚ywy w czytelne wywoÅ‚ania metod

> ğŸ’¡ **Profesjonalna wskazÃ³wka**: UÅ¼ywaj frameworkÃ³w, gdy przeÅ‚Ä…czasz siÄ™ miÄ™dzy rÃ³Å¼nymi modelami AI lub budujesz zÅ‚oÅ¼one funkcje, takie jak agenci, pamiÄ™Ä‡ czy wywoÅ‚ywanie narzÄ™dzi. Stosuj bezpoÅ›rednie API, gdy uczysz siÄ™ podstaw lub tworzysz proste, skoncentrowane aplikacje.

**PodsumowujÄ…c**: Podobnie jak wybÃ³r miÄ™dzy wyspecjalizowanymi narzÄ™dziami rzemieÅ›lnika a kompletnym warsztatem, chodzi o dopasowanie narzÄ™dzia do zadania. Frameworki sprawdzajÄ… siÄ™ Å›wietnie w zÅ‚oÅ¼onych, bogatych funkcjach aplikacjach, podczas gdy bezpoÅ›rednie API dobrze dziaÅ‚ajÄ… w prostych zastosowaniach.

## ğŸ—ºï¸ Twoja podrÃ³Å¼ naukowa przez mistrzostwo frameworkÃ³w AI

```mermaid
journey
    title Od surowych API do produkcyjnych aplikacji AI
    section Podstawy frameworka
      Zrozum korzyÅ›ci abstrakcji: 4: You
      Opanuj podstawy LangChain: 6: You
      PorÃ³wnaj podejÅ›cia: 7: You
    section Systemy konwersacyjne
      Buduj interfejsy czatu: 5: You
      Zaimplementuj wzorce pamiÄ™ci: 7: You
      ObsÅ‚uguj odpowiedzi strumieniowe: 8: You
    section Zaawansowane funkcje
      TwÃ³rz niestandardowe narzÄ™dzia: 6: You
      Opanuj zorganizowany output: 8: You
      Buduj systemy dokumentÃ³w: 8: You
    section Aplikacje produkcyjne
      PoÅ‚Ä…cz wszystkie funkcje: 7: You
      ObsÅ‚uguj scenariusze bÅ‚Ä™dÃ³w: 8: You
      WdraÅ¼aj kompletne systemy: 9: You
```
**Cel Twojej podrÃ³Å¼y**: Pod koniec tej lekcji opanujesz rozwÃ³j w frameworkach AI i bÄ™dziesz w stanie tworzyÄ‡ zaawansowane, gotowe do produkcji aplikacje AI, ktÃ³re konkurujÄ… z komercyjnymi asystentami AI.

## Wprowadzenie

W tej lekcji nauczysz siÄ™:

- KorzystaÄ‡ z popularnego frameworku AI.
- RozwiÄ…zywaÄ‡ typowe problemy, takie jak rozmowy czatowe, uÅ¼ycie narzÄ™dzi, pamiÄ™Ä‡ i kontekst.
- WykorzystywaÄ‡ to do budowania aplikacji AI.

## ğŸ§  Ekosystem rozwoju frameworkÃ³w AI

```mermaid
mindmap
  root((Ramki AI))
    Abstraction Benefits
      Code Simplification
        Unified APIs
        Built-in Error Handling
        Consistent Patterns
        Reduced Boilerplate
      Multi-Model Support
        Provider Agnostic
        Easy Switching
        Fallback Options
        Cost Optimization
    Core Components
      Conversation Management
        Message Types
        Memory Systems
        Context Tracking
        History Persistence
      Tool Integration
        Function Calling
        API Connections
        Custom Tools
        Workflow Automation
    Advanced Features
      Structured Output
        Pydantic Models
        JSON Schemas
        Type Safety
        Validation Rules
      Document Processing
        Embeddings
        Vector Stores
        Similarity Search
        RAG Systems
    Production Patterns
      Application Architecture
        Modular Design
        Error Boundaries
        Async Operations
        State Management
      Deployment Strategies
        Scalability
        Monitoring
        Performance
        Security
```
**GÅ‚Ã³wna zasada**: Frameworki AI upraszczajÄ… zÅ‚oÅ¼onoÅ›Ä‡, oferujÄ…c potÄ™Å¼ne abstrakcje do zarzÄ…dzania rozmowami, integracji narzÄ™dzi i przetwarzania dokumentÃ³w, umoÅ¼liwiajÄ…c programistom tworzenie zaawansowanych aplikacji AI z czystym i Å‚atwym w utrzymaniu kodem.

## TwÃ³j pierwszy prompt AI

Zacznijmy od podstaw, tworzÄ…c pierwszÄ… aplikacjÄ™ AI, ktÃ³ra wysyÅ‚a pytanie i otrzymuje odpowiedÅº. Podobnie jak Archimedes odkrywajÄ…cy zasadÄ™ wyporu w swojej kÄ…pieli, czasem najprostsze obserwacje prowadzÄ… do najpotÄ™Å¼niejszych wnioskÃ³w â€“ a frameworki udostÄ™pniajÄ… te wnioski.

### Konfiguracja LangChain z modelami GitHub

UÅ¼yjemy LangChain do poÅ‚Ä…czenia siÄ™ z modelami GitHub, co jest caÅ‚kiem fajne, poniewaÅ¼ daje darmowy dostÄ™p do rÃ³Å¼nych modeli AI. Najlepsza czÄ™Å›Ä‡? Potrzebujesz tylko kilku prostych parametrÃ³w konfiguracyjnych, aby zaczÄ…Ä‡:

```python
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

# WyÅ›lij proste polecenie
response = llm.invoke("What's the capital of France?")
print(response.content)
```

**Oto co siÄ™ tutaj dzieje:**
- **Tworzy** klienta LangChain za pomocÄ… klasy `ChatOpenAI` â€“ to twÃ³j wstÄ™p do AI!
- **Konfiguruje** poÅ‚Ä…czenie do modeli GitHub z Twoim tokenem uwierzytelniajÄ…cym
- **OkreÅ›la**, ktÃ³rego modelu AI uÅ¼ywaÄ‡ (`gpt-4o-mini`) â€“ pomyÅ›l o tym jak o wyborze asystenta AI
- **WysyÅ‚a** pytanie metodÄ… `invoke()` â€“ tutaj dzieje siÄ™ magia
- **WyciÄ…ga** i wyÅ›wietla odpowiedÅº â€“ voilÃ , rozmawiasz z AI!

> ğŸ”§ **Notatka**: JeÅ›li korzystasz z GitHub Codespaces, masz szczÄ™Å›cie â€“ `GITHUB_TOKEN` jest juÅ¼ skonfigurowany! Pracujesz lokalnie? Spokojnie, bÄ™dziesz musiaÅ‚ stworzyÄ‡ token dostÄ™pu osobistego z odpowiednimi uprawnieniami.

**Oczekiwany wynik:**
```text
The capital of France is Paris.
```

```mermaid
sequenceDiagram
    participant App as Twoja aplikacja Python
    participant LC as LangChain
    participant GM as Modele GitHub
    participant AI as GPT-4o-mini
    
    App->>LC: llm.invoke("Jaka jest stolica Francji?")
    LC->>GM: Å»Ä…danie HTTP z podpowiedziÄ…
    GM->>AI: PrzetwÃ³rz podpowiedÅº
    AI->>GM: Wygenerowana odpowiedÅº
    GM->>LC: ZwrÃ³Ä‡ odpowiedÅº
    LC->>App: response.content
```
## Budowanie konwersacyjnej AI

Ten pierwszy przykÅ‚ad demonstruje podstawy, ale to tylko jedna wymiana â€“ zadajesz pytanie, dostajesz odpowiedÅº i to wszystko. W rzeczywistych aplikacjach chcesz, aby AI pamiÄ™taÅ‚o, o czym rozmawialiÅ›cie, tak jak Watson i Holmes budowali swoje Å›ledcze rozmowy na przestrzeni czasu.

Tu LangChain okazuje siÄ™ szczegÃ³lnie przydatne. UdostÄ™pnia rÃ³Å¼ne typy wiadomoÅ›ci, ktÃ³re pomagajÄ… strukturyzowaÄ‡ rozmowy i pozwalajÄ… nadaÄ‡ AI osobowoÅ›Ä‡. BÄ™dziesz tworzyÄ‡ czaty utrzymujÄ…ce kontekst i charakter.

### Zrozumienie typÃ³w wiadomoÅ›ci

PomyÅ›l o typach wiadomoÅ›ci jak o rÃ³Å¼nych â€kapeluszachâ€, ktÃ³re uczestnicy noszÄ… w rozmowie. LangChain uÅ¼ywa rÃ³Å¼nych klas wiadomoÅ›ci, by Å›ledziÄ‡, kto co mÃ³wi:

| Typ WiadomoÅ›ci | Cel | PrzykÅ‚ad Zastosowania |
|--------------|---------|------------------|
| `SystemMessage` | Definiuje osobowoÅ›Ä‡ i zachowanie AI | "JesteÅ› pomocnym asystentem programistycznym" |
| `HumanMessage` | Reprezentuje wejÅ›cie uÅ¼ytkownika | "WyjaÅ›nij, jak dziaÅ‚ajÄ… funkcje" |
| `AIMessage` | Przechowuje odpowiedzi AI | Poprzednie odpowiedzi AI w rozmowie |

### Tworzenie pierwszej rozmowy

StwÃ³rzmy rozmowÄ™, w ktÃ³rej AI przyjmuje konkretnÄ… rolÄ™. Niech bÄ™dzie Kapitanem Picardem â€“ postaciÄ… znanÄ… z dyplomatycznej mÄ…droÅ›ci i przywÃ³dztwa:

```python
messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]
```

**Co robi ta konfiguracja rozmowy:**
- **Ustala** rolÄ™ i osobowoÅ›Ä‡ AI przez `SystemMessage`
- **Dostarcza** wstÄ™pne zapytanie uÅ¼ytkownika za pomocÄ… `HumanMessage`
- **Tworzy** podstawÄ™ do rozmowy wieloetapowej

PeÅ‚ny kod tego przykÅ‚adu wyglÄ…da tak:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]


# dziaÅ‚a
response  = llm.invoke(messages)
print(response.content)
```

PowinieneÅ› zobaczyÄ‡ wynik podobny do:

```text
I am Captain Jean-Luc Picard, the commanding officer of the USS Enterprise (NCC-1701-D), a starship in the United Federation of Planets. My primary mission is to explore new worlds, seek out new life and new civilizations, and boldly go where no one has gone before. 

I believe in the importance of diplomacy, reason, and the pursuit of knowledge. My crew is diverse and skilled, and we often face challenges that test our resolve, ethics, and ingenuity. Throughout my career, I have encountered numerous species, grappled with complex moral dilemmas, and have consistently sought peaceful solutions to conflicts.

I hold the ideals of the Federation close to my heart, believing in the importance of cooperation, understanding, and respect for all sentient beings. My experiences have shaped my leadership style, and I strive to be a thoughtful and just captain. How may I assist you further?
```

Aby zachowaÄ‡ ciÄ…gÅ‚oÅ›Ä‡ rozmowy (zamiast resetowaÄ‡ kontekst za kaÅ¼dym razem), musisz ciÄ…gle dodawaÄ‡ odpowiedzi do listy wiadomoÅ›ci. Podobnie jak ustne tradycje przekazujÄ…ce historie z pokolenia na pokolenie, takie podejÅ›cie buduje trwaÅ‚Ä… pamiÄ™Ä‡:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]


# dziaÅ‚a
response  = llm.invoke(messages)

print(response.content)

print("---- Next ----")

messages.append(response)
messages.append(HumanMessage(content="Now that I know about you, I'm Chris, can I be in your crew?"))

response  = llm.invoke(messages)

print(response.content)

```

CaÅ‚kiem niezÅ‚e, prawda? Dzieje siÄ™ tu tak, Å¼e wywoÅ‚ujemy LLM dwukrotnie â€“ najpierw z dwoma poczÄ…tkowymi wiadomoÅ›ciami, a potem ponownie z peÅ‚nÄ… historiÄ… rozmowy. To tak, jakby AI naprawdÄ™ Å›ledziÅ‚o naszÄ… rozmowÄ™!

Kiedy uruchomisz ten kod, otrzymasz drugÄ… odpowiedÅº, ktÃ³ra moÅ¼e brzmieÄ‡ tak:

```text
Welcome aboard, Chris! It's always a pleasure to meet those who share a passion for exploration and discovery. While I cannot formally offer you a position on the Enterprise right now, I encourage you to pursue your aspirations. We are always in need of talented individuals with diverse skills and backgrounds. 

If you are interested in space exploration, consider education and training in the sciences, engineering, or diplomacy. The values of curiosity, resilience, and teamwork are crucial in Starfleet. Should you ever find yourself on a starship, remember to uphold the principles of the Federation: peace, understanding, and respect for all beings. Your journey can lead you to remarkable adventures, whether in the stars or on the ground. Engage!
```

```mermaid
sequenceDiagram
    participant User
    participant App
    participant LangChain
    participant AI
    
    User->>App: "Opowiedz mi o sobie"
    App->>LangChain: [SystemMessage, HumanMessage]
    LangChain->>AI: Sformatowana konwersacja
    AI->>LangChain: OdpowiedÅº Kapitana Picarda
    LangChain->>App: Obiekt AIMessage
    App->>User: WyÅ›wietl odpowiedÅº
    
    Note over App: Dodaj AIMessage do konwersacji
    
    User->>App: "Czy mogÄ™ doÅ‚Ä…czyÄ‡ do twojej zaÅ‚ogi?"
    App->>LangChain: [SystemMessage, HumanMessage, AIMessage, HumanMessage]
    LangChain->>AI: PeÅ‚ny kontekst rozmowy
    AI->>LangChain: OdpowiedÅº kontekstowa
    LangChain->>App: Nowy AIMessage
    App->>User: WyÅ›wietl odpowiedÅº kontekstowÄ…
```
WezmÄ™ to jako â€moÅ¼eâ€ ;)

## Streaming odpowiedzi

Czy zauwaÅ¼yÅ‚eÅ›, jak ChatGPT zdaje siÄ™ â€pisaÄ‡â€ odpowiedzi w czasie rzeczywistym? To wÅ‚aÅ›nie streaming w akcji. Podobnie jak obserwowanie zrÄ™cznego kaligrafa â€“ widzisz, jak pojawiajÄ… siÄ™ litery krok po kroku, zamiast natychmiast â€“ streaming sprawia, Å¼e interakcja jest bardziej naturalna i daje natychmiastowÄ… informacjÄ™ zwrotnÄ….

### Implementacja streamingu w LangChain

```python
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
    streaming=True
)

# Strumieniuj odpowiedÅº
for chunk in llm.stream("Write a short story about a robot learning to code"):
    print(chunk.content, end="", flush=True)
```

**Dlaczego streaming jest Å›wietny:**
- **Pokazuje** zawartoÅ›Ä‡, gdy jest tworzona â€“ koniec z niezrÄ™cznym czekaniem!
- **Sprawia**, Å¼e uÅ¼ytkownicy czujÄ…, iÅ¼ coÅ› siÄ™ faktycznie dzieje
- **Wydaje siÄ™** szybszy, nawet jeÅ›li technicznie taki nie jest
- **Pozwala** rozpoczÄ…Ä‡ czytanie, podczas gdy AI jeszcze â€myÅ›liâ€

> ğŸ’¡ **WskazÃ³wka dla UX**: Streaming szczegÃ³lnie bÅ‚yszczy przy dÅ‚uÅ¼szych odpowiedziach, takich jak wyjaÅ›nienia kodu, kreatywne pisanie czy szczegÃ³Å‚owe tutoriale. Twoi uÅ¼ytkownicy pokochajÄ… widzieÄ‡ postÄ™p zamiast patrzeÄ‡ na pusty ekran!

### ğŸ¯ Pedagogiczna chwila refleksji: KorzyÅ›ci abstrakcji frameworku

**Zatrzymaj siÄ™ i pomyÅ›l**: WÅ‚aÅ›nie doÅ›wiadczyÅ‚eÅ› mocy abstrakcji frameworkÃ³w AI. PorÃ³wnaj to, czego siÄ™ nauczyÅ‚eÅ›, z surowymi wywoÅ‚aniami API z poprzednich lekcji.

**Szybka autoocena**:
- Czy potrafisz wyjaÅ›niÄ‡, jak LangChain upraszcza zarzÄ…dzanie rozmowÄ… w porÃ³wnaniu z rÄ™cznym Å›ledzeniem wiadomoÅ›ci?
- Jaka jest rÃ³Å¼nica miÄ™dzy metodami `invoke()` a `stream()` i kiedy ich uÅ¼ywaÄ‡?
- Jak system typÃ³w wiadomoÅ›ci w frameworku poprawia organizacjÄ™ kodu?

**PoÅ‚Ä…czenie z rzeczywistoÅ›ciÄ…**: Schematy abstrakcji, ktÃ³re poznaÅ‚eÅ› (typy wiadomoÅ›ci, interfejsy strumieniowe, pamiÄ™Ä‡ rozmowy) sÄ… uÅ¼ywane w kaÅ¼dej duÅ¼ej aplikacji AI â€“ od interfejsu ChatGPT po pomoc kodowÄ… GitHub Copilot. Opanowujesz te same wzorce architektoniczne, ktÃ³re stosujÄ… profesjonalne zespoÅ‚y deweloperskie AI.

**Pytanie wyzwania**: Jak zaprojektowaÅ‚byÅ› abstrakcjÄ™ frameworku do obsÅ‚ugi rÃ³Å¼nych dostawcÃ³w modeli AI (OpenAI, Anthropic, Google) za pomocÄ… jednolitego interfejsu? RozwaÅ¼ korzyÅ›ci i kompromisy.

## Szablony promptÃ³w

Szablony promptÃ³w dziaÅ‚ajÄ… jak struktury retoryczne stosowane w klasycznej oratorii â€“ pomyÅ›l o tym, jak Cyceron dostosowywaÅ‚ swoje wzorce mowy do rÃ³Å¼nych odbiorcÃ³w, zachowujÄ…c tÄ™ samÄ… perswazyjnÄ… ramÄ™. PozwalajÄ… tworzyÄ‡ wielokrotnego uÅ¼ytku pytania, w ktÃ³rych moÅ¼na wymieniaÄ‡ rÃ³Å¼ne elementy bez przepisywania wszystkiego od nowa. Po skonfigurowaniu szablonu wystarczy wypeÅ‚niÄ‡ zmienne odpowiednimi wartoÅ›ciami.

### Tworzenie wielokrotnego uÅ¼ytku promptÃ³w

```python
from langchain_core.prompts import ChatPromptTemplate

# Zdefiniuj szablon do wyjaÅ›nieÅ„ kodu
template = ChatPromptTemplate.from_messages([
    ("system", "You are an expert programming instructor. Explain concepts clearly with examples."),
    ("human", "Explain {concept} in {language} with a practical example for {skill_level} developers")
])

# UÅ¼yj szablonu z rÃ³Å¼nymi wartoÅ›ciami
questions = [
    {"concept": "functions", "language": "JavaScript", "skill_level": "beginner"},
    {"concept": "classes", "language": "Python", "skill_level": "intermediate"},
    {"concept": "async/await", "language": "JavaScript", "skill_level": "advanced"}
]

for question in questions:
    prompt = template.format_messages(**question)
    response = llm.invoke(prompt)
    print(f"Topic: {question['concept']}\n{response.content}\n---\n")
```

**Dlaczego pokochasz szablony:**
- **UtrzymujÄ…** spÃ³jnoÅ›Ä‡ promptÃ³w w caÅ‚ej aplikacji
- **Koniec z** brzydkim Å‚Ä…czeniem stringÃ³w â€“ tylko czyste, proste zmienne
- **Twoje AI** zachowuje siÄ™ przewidywalnie, bo struktura pozostaje niezmienna
- **Aktualizacje** to pestka â€“ zmieniasz szablon raz i zmiana obowiÄ…zuje wszÄ™dzie

## Strukturalne outputy

Czy zdarzyÅ‚o Ci siÄ™ frustrowaÄ‡ podczas prÃ³by analizowania odpowiedzi AI, ktÃ³re wracajÄ… jako niestrukturalny tekst? Strukturalny output to jak nauczenie AI, aby stosowaÅ‚o systematyczne podejÅ›cie, ktÃ³re Linneusz uÅ¼ywaÅ‚ do klasyfikacji biologicznej â€“ uporzÄ…dkowane, przewidywalne i Å‚atwe w obsÅ‚udze. MoÅ¼esz Å¼Ä…daÄ‡ JSON, konkretnych struktur danych lub dowolnego formatu, ktÃ³rego potrzebujesz.

### Definiowanie schematÃ³w outputu

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel, Field

class CodeReview(BaseModel):
    score: int = Field(description="Code quality score from 1-10")
    strengths: list[str] = Field(description="List of code strengths")
    improvements: list[str] = Field(description="List of suggested improvements")
    overall_feedback: str = Field(description="Summary feedback")

# Skonfiguruj parser
parser = JsonOutputParser(pydantic_object=CodeReview)

# UtwÃ³rz prompt z instrukcjami formatowania
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a code reviewer. {format_instructions}"),
    ("human", "Review this code: {code}")
])

# Sformatuj prompt z instrukcjami
chain = prompt | llm | parser

# Pobierz uporzÄ…dkowanÄ… odpowiedÅº
code_sample = """
def calculate_average(numbers):
    return sum(numbers) / len(numbers)
"""

result = chain.invoke({
    "code": code_sample,
    "format_instructions": parser.get_format_instructions()
})

print(f"Score: {result['score']}")
print(f"Strengths: {', '.join(result['strengths'])}")
```

**Dlaczego strukturalny output zmienia zasady gry:**
- **Koniec z** zgadywaniem, jaki format dostaniesz â€“ jest zawsze spÃ³jny
- **PodÅ‚Ä…cza siÄ™** bezpoÅ›rednio do Twoich baz danych i API bez dodatkowej pracy
- **Wykrywa** dziwne odpowiedzi AI, zanim zepsujÄ… TwojÄ… aplikacjÄ™
- **Upraszcza** TwÃ³j kod, bo dokÅ‚adnie wiesz, z czym pracujesz

## WywoÅ‚ywanie narzÄ™dzi

Teraz docieramy do jednej z najbardziej potÄ™Å¼nych funkcji: narzÄ™dzi. To sposÃ³b, aby daÄ‡ Twojemu AI praktyczne zdolnoÅ›ci wykraczajÄ…ce poza samÄ… rozmowÄ™. Podobnie jak Å›redniowieczne gildie tworzyÅ‚y specjalistyczne narzÄ™dzia do konkretnych rzemiosÅ‚, moÅ¼esz wyposaÅ¼yÄ‡ AI w ukierunkowane instrumenty. Opisujesz dostÄ™pne narzÄ™dzia, a gdy ktoÅ› poprosi o coÅ›, co pasuje do ich zakresu, AI moÅ¼e podjÄ…Ä‡ dziaÅ‚anie.

### UÅ¼ywanie Pythona

Dodajmy kilka narzÄ™dzi w ten sposÃ³b:

```python
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Adnotacje muszÄ… mieÄ‡ typ i opcjonalnie mogÄ… zawieraÄ‡ wartoÅ›Ä‡ domyÅ›lnÄ… oraz opis (w tej kolejnoÅ›ci).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

tools = [add]

functions = {
    "add": lambda a, b: a + b
}
```

Co tu siÄ™ dzieje? Tworzymy szablon narzÄ™dzia o nazwie `add`. DziedziczÄ…c po `TypedDict` i uÅ¼ywajÄ…c tych fajnych typÃ³w `Annotated` dla `a` i `b`, dajemy LLM jasny obraz, co to narzÄ™dzie robi i czego potrzebuje. SÅ‚ownik `functions` jest jak nasza skrzynka narzÄ™dziowa â€“ mÃ³wi naszemu kodowi dokÅ‚adnie, co zrobiÄ‡, gdy AI zdecyduje siÄ™ uÅ¼yÄ‡ konkretnego narzÄ™dzia.

Zobaczmy, jak wywoÅ‚ujemy LLM z tym narzÄ™dziem:

```python
llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)
```

WywoÅ‚ujemy `bind_tools` z tablicÄ… `tools`, dziÄ™ki czemu nowy LLM `llm_with_tools` posiada wiedzÄ™ o tym narzÄ™dziu.

Aby uÅ¼yÄ‡ tego nowego LLM, moÅ¼emy wpisaÄ‡ nastÄ™pujÄ…cy kod:

```python
query = "What is 3 + 12?"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

Teraz, gdy wywoÅ‚ujemy `invoke` na tym nowym llm, ktÃ³re ma narzÄ™dzia, wÅ‚aÅ›ciwoÅ›Ä‡ `tool_calls` moÅ¼e zostaÄ‡ wypeÅ‚niona. JeÅ›li tak, kaÅ¼de zidentyfikowane narzÄ™dzie posiada wÅ‚aÅ›ciwoÅ›ci `name` i `args`, ktÃ³re okreÅ›lajÄ…, jakie narzÄ™dzie ma byÄ‡ wywoÅ‚ane i z jakimi argumentami. PeÅ‚ny kod wyglÄ…da tak:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Adnotacje muszÄ… mieÄ‡ typ i mogÄ… opcjonalnie zawieraÄ‡ wartoÅ›Ä‡ domyÅ›lnÄ… oraz opis (w tej kolejnoÅ›ci).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

tools = [add]

functions = {
    "add": lambda a, b: a + b
}

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)

query = "What is 3 + 12?"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

Po uruchomieniu kodu powinieneÅ› zobaczyÄ‡ wynik podobny do:

```text
TOOL CALL:  15
CONTENT: 
```

AI przeanalizowaÅ‚o pytanie "Co to jest 3 + 12" i rozpoznaÅ‚o to jako zadanie dla narzÄ™dzia `add`. Podobnie jak doÅ›wiadczony bibliotekarz wie, z ktÃ³rego ÅºrÃ³dÅ‚a korzystaÄ‡ w zaleÅ¼noÅ›ci od pytania, podjÄ™Å‚o tÄ™ decyzjÄ™ na podstawie nazwy narzÄ™dzia, opisu i specyfikacji pÃ³l. Wynik 15 pochodzi ze sÅ‚ownika `functions` wykonujÄ…cego narzÄ™dzie:

```python
print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
```

### Bardziej interesujÄ…ce narzÄ™dzie wywoÅ‚ujÄ…ce API sieciowe
Dodawanie liczb ilustruje koncept, ale prawdziwe narzÄ™dzia zazwyczaj wykonujÄ… bardziej zÅ‚oÅ¼one operacje, takie jak wywoÅ‚ywanie API internetowych. Rozszerzmy nasz przykÅ‚ad tak, aby AI pobieraÅ‚o zawartoÅ›Ä‡ z internetu â€“ podobnie jak operatorzy telegrafu kiedyÅ› Å‚Ä…czyli odlegÅ‚e lokalizacje:

```python
class joke(TypedDict):
    """Tell a joke."""

    # Adnotacje muszÄ… mieÄ‡ typ i mogÄ… opcjonalnie zawieraÄ‡ wartoÅ›Ä‡ domyÅ›lnÄ… oraz opis (w tej kolejnoÅ›ci).
    category: Annotated[str, ..., "The joke category"]

def get_joke(category: str) -> str:
    response = requests.get(f"https://api.chucknorris.io/jokes/random?category={category}", headers={"Accept": "application/json"})
    if response.status_code == 200:
        return response.json().get("value", f"Here's a {category} joke!")
    return f"Here's a {category} joke!"

functions = {
    "add": lambda a, b: a + b,
    "joke": lambda category: get_joke(category)
}

query = "Tell me a joke about animals"

# reszta kodu jest taka sama
```
  
Teraz, jeÅ›li uruchomisz ten kod, otrzymasz odpowiedÅº mÃ³wiÄ…cÄ… coÅ› w stylu:

```text
TOOL CALL:  Chuck Norris once rode a nine foot grizzly bear through an automatic car wash, instead of taking a shower.
CONTENT:  
```
  
```mermaid
flowchart TD
    A[Zapytanie uÅ¼ytkownika: "Opowiedz mi dowcip o zwierzÄ™tach"] --> B[Analiza LangChain]
    B --> C{Czy narzÄ™dzie jest dostÄ™pne?}
    C -->|Tak| D[Wybierz narzÄ™dzie do dowcipÃ³w]
    C -->|Nie| E[Wygeneruj bezpoÅ›redniÄ… odpowiedÅº]
    
    D --> F[WyodrÄ™bnij parametry]
    F --> G[WywoÅ‚aj dowcip(kategoria="zwierzÄ™ta")]
    G --> H[Å»Ä…danie API do chucknorris.io]
    H --> I[ZwrÃ³Ä‡ treÅ›Ä‡ dowcipu]
    I --> J[WyÅ›wietl uÅ¼ytkownikowi]
    
    E --> K[OdpowiedÅº wygenerowana przez AI]
    K --> J
    
    subgraph "Warstwa definicji narzÄ™dzi"
        L[Schemat TypedDict]
        M[Implementacja funkcji]
        N[Walidacja parametrÃ³w]
    end
    
    D --> L
    F --> N
    G --> M
```  
Oto kod w caÅ‚oÅ›ci:

```python
from langchain_openai import ChatOpenAI
import requests
import os
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Adnotacje muszÄ… mieÄ‡ typ i mogÄ… opcjonalnie zawieraÄ‡ wartoÅ›Ä‡ domyÅ›lnÄ… oraz opis (w tej kolejnoÅ›ci).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

class joke(TypedDict):
    """Tell a joke."""

    # Adnotacje muszÄ… mieÄ‡ typ i mogÄ… opcjonalnie zawieraÄ‡ wartoÅ›Ä‡ domyÅ›lnÄ… oraz opis (w tej kolejnoÅ›ci).
    category: Annotated[str, ..., "The joke category"]

tools = [add, joke]

def get_joke(category: str) -> str:
    response = requests.get(f"https://api.chucknorris.io/jokes/random?category={category}", headers={"Accept": "application/json"})
    if response.status_code == 200:
        return response.json().get("value", f"Here's a {category} joke!")
    return f"Here's a {category} joke!"

functions = {
    "add": lambda a, b: a + b,
    "joke": lambda category: get_joke(category)
}

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)

query = "Tell me a joke about animals"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        # print("WYWOÅANIE NARZÄ˜DZIA: ", tool)
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```
  
## Embeddingi i przetwarzanie dokumentÃ³w

Embeddingi to jedno z najpiÄ™kniejszych rozwiÄ…zaÅ„ we wspÃ³Å‚czesnej AI. WyobraÅº sobie, Å¼e moÅ¼esz wziÄ…Ä‡ dowolny kawaÅ‚ek tekstu i przeksztaÅ‚ciÄ‡ go w wspÃ³Å‚rzÄ™dne liczbowe, ktÃ³re uchwytujÄ… jego znaczenie. WÅ‚aÅ›nie to robiÄ… embeddingi â€“ przeksztaÅ‚cajÄ… tekst w punkty w przestrzeni wielowymiarowej, gdzie podobne koncepcje skupiajÄ… siÄ™ razem. To jak system wspÃ³Å‚rzÄ™dnych dla pomysÅ‚Ã³w, przypominajÄ…cy sposÃ³b, w jaki Mendelejew uporzÄ…dkowaÅ‚ ukÅ‚ad okresowy wedÅ‚ug wÅ‚aÅ›ciwoÅ›ci atomowych.

### Tworzenie i uÅ¼ywanie embeddingÃ³w

```python
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter

# Inicjalizuj osadzenia
embeddings = OpenAIEmbeddings(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="text-embedding-3-small"
)

# ZaÅ‚aduj i podziel dokumenty
loader = TextLoader("documentation.txt")
documents = loader.load()

text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(documents)

# UtwÃ³rz magazyn wektorÃ³w
vectorstore = FAISS.from_documents(texts, embeddings)

# Wykonaj wyszukiwanie podobieÅ„stwa
query = "How do I handle user authentication?"
similar_docs = vectorstore.similarity_search(query, k=3)

for doc in similar_docs:
    print(f"Relevant content: {doc.page_content[:200]}...")
```
  
### Åadowarki dokumentÃ³w dla rÃ³Å¼nych formatÃ³w

```python
from langchain_community.document_loaders import (
    PyPDFLoader,
    CSVLoader,
    JSONLoader,
    WebBaseLoader
)

# ZaÅ‚aduj rÃ³Å¼ne typy dokumentÃ³w
pdf_loader = PyPDFLoader("manual.pdf")
csv_loader = CSVLoader("data.csv")
json_loader = JSONLoader("config.json")
web_loader = WebBaseLoader("https://example.com/docs")

# PrzetwÃ³rz wszystkie dokumenty
all_documents = []
for loader in [pdf_loader, csv_loader, json_loader, web_loader]:
    docs = loader.load()
    all_documents.extend(docs)
```
  
**Co moÅ¼esz zrobiÄ‡ za pomocÄ… embeddingÃ³w:**
- **ZbudowaÄ‡** wyszukiwanie, ktÃ³re naprawdÄ™ rozumie, co masz na myÅ›li, a nie tylko dopasowanie sÅ‚Ã³w kluczowych
- **StworzyÄ‡** AI, ktÃ³re potrafi odpowiadaÄ‡ na pytania dotyczÄ…ce twoich dokumentÃ³w
- **WykonaÄ‡** systemy rekomendacji sugerujÄ…ce naprawdÄ™ istotne treÅ›ci
- **Automatycznie** organizowaÄ‡ i kategoryzowaÄ‡ twoje materiaÅ‚y

```mermaid
flowchart LR
    A[Dokumenty] --> B[PodziaÅ‚ Tekstu]
    B --> C[Tworzenie OsadzeÅ„]
    C --> D[Magazyn WektorÃ³w]
    
    E[Zapytanie UÅ¼ytkownika] --> F[Osadzenie Zapytania]
    F --> G[Wyszukiwanie PodobieÅ„stw]
    G --> D
    D --> H[Istotne Dokumenty]
    H --> I[OdpowiedÅº AI]
    
    subgraph "PrzestrzeÅ„ Wektorowa"
        J[Dokument A: [0.1, 0.8, 0.3...]]
        K[Dokument B: [0.2, 0.7, 0.4...]]
        L[Zapytanie: [0.15, 0.75, 0.35...]]
    end
    
    C --> J
    C --> K
    F --> L
    G --> J
    G --> K
```  
## Budowanie kompletnej aplikacji AI

Teraz zintegrujemy wszystko, czego siÄ™ nauczyÅ‚eÅ›, w kompleksowÄ… aplikacjÄ™ â€“ asystenta do programowania, ktÃ³ry potrafi odpowiadaÄ‡ na pytania, korzystaÄ‡ z narzÄ™dzi i utrzymywaÄ‡ pamiÄ™Ä‡ rozmowy. Podobnie jak druk Å‚Ä…czyÅ‚ istniejÄ…ce technologie (czcionki ruchome, tusz, papier i nacisk) w coÅ› przeÅ‚omowego, poÅ‚Ä…czymy nasze komponenty AI w coÅ› praktycznego i uÅ¼ytecznego.

### PrzykÅ‚ad kompletnej aplikacji

```python
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_community.vectorstores import FAISS
from typing_extensions import Annotated, TypedDict
import os
import requests

class CodingAssistant:
    def __init__(self):
        self.llm = ChatOpenAI(
            api_key=os.environ["GITHUB_TOKEN"],
            base_url="https://models.github.ai/inference",
            model="openai/gpt-4o-mini"
        )
        
        self.conversation_history = [
            SystemMessage(content="""You are an expert coding assistant. 
            Help users learn programming concepts, debug code, and write better software.
            Use tools when needed and maintain a helpful, encouraging tone.""")
        ]
        
        # Zdefiniuj narzÄ™dzia
        self.setup_tools()
    
    def setup_tools(self):
        class web_search(TypedDict):
            """Search for programming documentation or examples."""
            query: Annotated[str, "Search query for programming help"]
        
        class code_formatter(TypedDict):
            """Format and validate code snippets."""
            code: Annotated[str, "Code to format"]
            language: Annotated[str, "Programming language"]
        
        self.tools = [web_search, code_formatter]
        self.llm_with_tools = self.llm.bind_tools(self.tools)
    
    def chat(self, user_input: str):
        # Dodaj wiadomoÅ›Ä‡ uÅ¼ytkownika do rozmowy
        self.conversation_history.append(HumanMessage(content=user_input))
        
        # Pobierz odpowiedÅº AI
        response = self.llm_with_tools.invoke(self.conversation_history)
        
        # ObsÅ‚uÅ¼ wywoÅ‚ania narzÄ™dzi, jeÅ›li sÄ…
        if response.tool_calls:
            for tool_call in response.tool_calls:
                tool_result = self.execute_tool(tool_call)
                print(f"ğŸ”§ Tool used: {tool_call['name']}")
                print(f"ğŸ“Š Result: {tool_result}")
        
        # Dodaj odpowiedÅº AI do rozmowy
        self.conversation_history.append(response)
        
        return response.content
    
    def execute_tool(self, tool_call):
        tool_name = tool_call['name']
        args = tool_call['args']
        
        if tool_name == 'web_search':
            return f"Found documentation for: {args['query']}"
        elif tool_name == 'code_formatter':
            return f"Formatted {args['language']} code: {args['code'][:50]}..."
        
        return "Tool execution completed"

# PrzykÅ‚ad uÅ¼ycia
assistant = CodingAssistant()

print("ğŸ¤– Coding Assistant Ready! Type 'quit' to exit.\n")

while True:
    user_input = input("You: ")
    if user_input.lower() == 'quit':
        break
    
    response = assistant.chat(user_input)
    print(f"ğŸ¤– Assistant: {response}\n")
```
  
**Architektura aplikacji:**

```mermaid
graph TD
    A[WejÅ›cie uÅ¼ytkownika] --> B[Asystent kodowania]
    B --> C[PamiÄ™Ä‡ rozmowy]
    B --> D[Wykrywanie narzÄ™dzi]
    B --> E[Przetwarzanie LLM]
    
    D --> F[NarzÄ™dzie wyszukiwania w sieci]
    D --> G[NarzÄ™dzie formatowania kodu]
    
    E --> H[Generowanie odpowiedzi]
    F --> H
    G --> H
    
    H --> I[Interfejs uÅ¼ytkownika]
    H --> C
```  
**Kluczowe funkcje, ktÃ³re zaimplementowaliÅ›my:**
- **PamiÄ™ta** caÅ‚Ä… twojÄ… rozmowÄ™ dla ciÄ…gÅ‚oÅ›ci kontekstu
- **Wykonuje dziaÅ‚ania** poprzez wywoÅ‚ywanie narzÄ™dzi, nie tylko rozmowÄ™
- **PodÄ…Å¼a** za przewidywalnymi wzorcami interakcji
- **ZarzÄ…dza** obsÅ‚ugÄ… bÅ‚Ä™dÃ³w i zÅ‚oÅ¼onymi procesami automatycznie

### ğŸ¯ Pedagogiczne podsumowanie: Architektura AI produkcyjnego poziomu

**Zrozumienie architektury**: ZbudowaÅ‚eÅ› kompletnÄ… aplikacjÄ™ AI Å‚Ä…czÄ…cÄ… zarzÄ…dzanie rozmowÄ…, wywoÅ‚ywanie narzÄ™dzi oraz zorganizowane procesy. To reprezentuje rozwÃ³j aplikacji AI na poziomie produkcyjnym.

**Opanowane kluczowe koncepcje**:
- **Architektura oparta na klasach**: uporzÄ…dkowana, Å‚atwa do utrzymania struktura aplikacji AI
- **Integracja narzÄ™dzi**: funkcjonalnoÅ›Ä‡ niestandardowa wykraczajÄ…ca poza rozmowÄ™
- **ZarzÄ…dzanie pamiÄ™ciÄ…**: trwaÅ‚y kontekst konwersacji
- **ObsÅ‚uga bÅ‚Ä™dÃ³w**: solidne zachowanie aplikacji

**PowiÄ…zanie z branÅ¼Ä…**: Wzorce architektoniczne, ktÃ³re zaimplementowaÅ‚eÅ› (klasy rozmÃ³w, systemy narzÄ™dzi, zarzÄ…dzanie pamiÄ™ciÄ…) to te same wzorce uÅ¼ywane w korporacyjnych aplikacjach AI, takich jak asystent AI Slacka, GitHub Copilot czy Microsoft Copilot. Budujesz z myÅ›leniem na profesjonalnym poziomie.

**Pytanie do refleksji**: Jak rozwiniesz tÄ™ aplikacjÄ™, by obsÅ‚ugiwaÅ‚a wielu uÅ¼ytkownikÃ³w, trwaÅ‚Ä… pamiÄ™Ä‡ albo integracjÄ™ z zewnÄ™trznymi bazami danych? WeÅº pod uwagÄ™ wyzwania zwiÄ…zane ze skalowalnoÅ›ciÄ… i zarzÄ…dzaniem stanem.

## Zadanie: Zbuduj wÅ‚asnego asystenta naukowego zasilanego AI

**Cel**: StwÃ³rz aplikacjÄ™ AI, ktÃ³ra pomoÅ¼e studentom uczyÄ‡ siÄ™ programowania, dostarczajÄ…c wyjaÅ›nienia, przykÅ‚ady kodu oraz interaktywne quizy.

### Wymagania

**Podstawowe funkcje (wymagane):**
1. **Interfejs rozmowy**: Zaimplementuj system czatu, ktÃ³ry zachowuje kontekst przez wiele pytaÅ„
2. **NarzÄ™dzia edukacyjne**: StwÃ³rz co najmniej dwa narzÄ™dzia wspierajÄ…ce naukÄ™:
   - narzÄ™dzie do wyjaÅ›niania kodu
   - generator quizÃ³w koncepcyjnych
3. **Spersonalizowane uczenie**: Wykorzystaj komunikaty systemowe, by dostosowaÄ‡ odpowiedzi do rÃ³Å¼nych poziomÃ³w zaawansowania
4. **Formatowanie odpowiedzi**: Zaimplementuj ustrukturyzowane wyjÅ›cie dla pytaÅ„ quizowych

### Kroki wdroÅ¼enia

**Krok 1: Przygotuj Å›rodowisko**
```bash
pip install langchain langchain-openai
```
  
**Krok 2: Podstawowa funkcjonalnoÅ›Ä‡ czatu**
- StwÃ³rz klasÄ™ `StudyAssistant`
- Zaimplementuj pamiÄ™Ä‡ rozmowy
- Dodaj konfiguracjÄ™ osobowoÅ›ci dla wsparcia edukacyjnego

**Krok 3: Dodaj narzÄ™dzia edukacyjne**
- **WyjaÅ›niacz kodu**: rozkÅ‚ada kod na zrozumiaÅ‚e czÄ™Å›ci
- **Generator quizÃ³w**: tworzy pytania dotyczÄ…ce koncepcji programistycznych
- **Åšledzenie postÄ™pÃ³w**: monitoruje przerobione tematy

**Krok 4: Rozszerzone funkcje (opcjonalnie)**
- WdroÅ¼ odpowiedzi strumieniowe dla lepszego doÅ›wiadczenia uÅ¼ytkownika
- Dodaj Å‚adowanie dokumentÃ³w, aby uwzglÄ™dniÄ‡ materiaÅ‚y kursowe
- StwÃ³rz embeddingi do wyszukiwania semantycznego w materiaÅ‚ach

### Kryteria oceny

| Funkcja | DoskonaÅ‚a (4) | Dobra (3) | ZadowalajÄ…ca (2) | Wymaga pracy (1) |
|---------|----------------|----------|------------------|------------------|
| **Przebieg rozmowy** | Naturalne, Å›wiadome kontekstu odpowiedzi | Dobra pamiÄ™Ä‡ kontekstu | Podstawowa rozmowa | Brak pamiÄ™ci miÄ™dzy wymianami |
| **Integracja narzÄ™dzi** | Wiele uÅ¼ytecznych narzÄ™dzi dziaÅ‚a bezproblemowo | 2+ narzÄ™dzia poprawnie zaimplementowane | 1-2 narzÄ™dzia podstawowe | NarzÄ™dzia nie dziaÅ‚ajÄ… |
| **JakoÅ›Ä‡ kodu** | Czysty, dobrze udokumentowany, obsÅ‚uga bÅ‚Ä™dÃ³w | Dobra struktura, czÄ™Å›ciowa dokumentacja | Podstawowa funkcjonalnoÅ›Ä‡ dziaÅ‚a | SÅ‚aba struktura, brak obsÅ‚ugi bÅ‚Ä™dÃ³w |
| **WartoÅ›Ä‡ edukacyjna** | NaprawdÄ™ pomocne w nauce, adaptacyjne | Dobre wsparcie nauki | Podstawowe wyjaÅ›nienia | Ograniczona wartoÅ›Ä‡ edukacyjna |

### PrzykÅ‚adowa struktura kodu

```python
class StudyAssistant:
    def __init__(self, skill_level="beginner"):
        # Inicjalizuj LLM, narzÄ™dzia i pamiÄ™Ä‡ konwersacji
        pass
    
    def explain_code(self, code, language):
        # NarzÄ™dzie: WyjaÅ›nij, jak dziaÅ‚a kod
        pass
    
    def generate_quiz(self, topic, difficulty):
        # NarzÄ™dzie: TwÃ³rz pytania do Ä‡wiczeÅ„
        pass
    
    def chat(self, user_input):
        # GÅ‚Ã³wne interfejs konwersacji
        pass

# PrzykÅ‚adowe uÅ¼ycie
assistant = StudyAssistant(skill_level="intermediate")
response = assistant.chat("Explain how Python functions work")
```
  
**Dodatkowe wyzwania:**
- Dodaj obsÅ‚ugÄ™ wejÅ›cia/wyjÅ›cia gÅ‚osowego
- WdroÅ¼ interfejs webowy za pomocÄ… Streamlit lub Flask
- StwÃ³rz bazÄ™ wiedzy z materiaÅ‚Ã³w kursowych przy pomocy embeddingÃ³w
- Dodaj Å›ledzenie postÄ™pÃ³w i spersonalizowane Å›cieÅ¼ki nauki

## ğŸ“ˆ Twoja oÅ› mistrzostwa w rozwoju frameworkÃ³w AI

```mermaid
timeline
    title Droga Rozwoju Produkcyjnego Frameworka AI
    
    section Fundamenty Frameworka
        Zrozumienie Abstrakcji
            : Decyzje dotyczÄ…ce gÅ‚Ã³wnego frameworka vs API
            : Poznaj podstawowe koncepcje LangChain
            : Implementuj systemy typÃ³w wiadomoÅ›ci
        
        Podstawowa Integracja
            : PoÅ‚Ä…cz z dostawcami AI
            : ObsÅ‚uÅ¼ uwierzytelnianie
            : ZarzÄ…dzaj konfiguracjÄ…
    
    section Systemy Konwersacyjne
        ZarzÄ…dzanie PamiÄ™ciÄ…
            : Buduj historiÄ™ konwersacji
            : Implementuj Å›ledzenie kontekstu
            : ObsÅ‚uÅ¼ utrzymanie sesji
        
        Zaawansowane Interakcje
            : Opanuj strumieniowanie odpowiedzi
            : TwÃ³rz szablony promptÃ³w
            : Implementuj strukturalne wyniki
    
    section Integracja NarzÄ™dzi
        Tworzenie Niestandardowych NarzÄ™dzi
            : Projektuj schematy narzÄ™dzi
            : Implementuj wywoÅ‚ania funkcji
            : ObsÅ‚uÅ¼ zewnÄ™trzne API
        
        Automatyzacja ProcesÃ³w
            : ÅÄ…cz wiele narzÄ™dzi
            : TwÃ³rz drzewa decyzyjne
            : Buduj zachowania agentÃ³w
    
    section Aplikacje Produkcyjne
        KompletnÄ… ArchitekturÄ™ Systemu
            : PoÅ‚Ä…cz wszystkie funkcje frameworka
            : Implementuj granice bÅ‚Ä™dÃ³w
            : TwÃ³rz Å‚atwy do utrzymania kod
        
        GotowoÅ›Ä‡ PrzemysÅ‚owa
            : Zajmij siÄ™ problemami skalowalnoÅ›ci
            : Implementuj monitorowanie
            : Buduj strategie wdraÅ¼ania
```  
**ğŸ“ KamieÅ„ milowy ukoÅ„czenia**: OpanowaÅ‚eÅ› rozwÃ³j frameworkÃ³w AI uÅ¼ywajÄ…c tych samych narzÄ™dzi i wzorcÃ³w, ktÃ³re napÄ™dzajÄ… nowoczesne aplikacje AI. Te umiejÄ™tnoÅ›ci reprezentujÄ… najnowszy poziom rozwoju aplikacji AI i przygotowujÄ… ciÄ™ do budowy systemÃ³w inteligentnych na poziomie korporacyjnym.

**ğŸ”„ Kolejne poziomy moÅ¼liwoÅ›ci**:
- Gotowy do eksploracji zaawansowanych architektur AI (agenci, systemy multi-agentowe)
- Przygotowany do budowy systemÃ³w RAG z bazami wektorowymi
- WyposaÅ¼ony, by tworzyÄ‡ multimodalne aplikacje AI
- Fundament pod skalowanie i optymalizacjÄ™ aplikacji AI

## Podsumowanie

ğŸ‰ OpanowaÅ‚eÅ› podstawy rozwoju frameworkÃ³w AI i nauczyÅ‚eÅ› siÄ™, jak budowaÄ‡ zaawansowane aplikacje AI uÅ¼ywajÄ…c LangChain. To jak ukoÅ„czenie wszechstronnego praktykatu â€” zdobyÅ‚eÅ› solidny zestaw umiejÄ™tnoÅ›ci. Przejrzyjmy, co osiÄ…gnÄ…Å‚eÅ›.

### Czego siÄ™ nauczyÅ‚eÅ›

**Podstawowe koncepcje frameworku:**
- **KorzyÅ›ci z frameworkÃ³w**: kiedy wybieraÄ‡ frameworki zamiast bezpoÅ›rednich wywoÅ‚aÅ„ API
- **Podstawy LangChain**: konfiguracja i poÅ‚Ä…czenie z modelami AI
- **Rodzaje wiadomoÅ›ci**: stosowanie `SystemMessage`, `HumanMessage` i `AIMessage` dla uporzÄ…dkowanych rozmÃ³w

**Zaawansowane funkcje:**
- **WywoÅ‚ywanie narzÄ™dzi**: tworzenie i integracja niestandardowych narzÄ™dzi zwiÄ™kszajÄ…cych moÅ¼liwoÅ›ci AI
- **PamiÄ™Ä‡ rozmowy**: utrzymanie kontekstu przez wiele tur konwersacji
- **Streaming odpowiedzi**: implementacja dostarczania odpowiedzi w czasie rzeczywistym
- **Szablony promptÃ³w**: budowanie wielokrotnego uÅ¼ytku, dynamicznych promptÃ³w
- **Ustrukturyzowane wyjÅ›cie**: zapewnienie spÃ³jnych, Å‚atwych do przetwarzania odpowiedzi AI
- **Embeddingi**: tworzenie moÅ¼liwoÅ›ci wyszukiwania semantycznego i przetwarzania dokumentÃ³w

**Praktyczne zastosowania:**
- **Budowanie kompletnej aplikacji**: Å‚Ä…czenie wielu funkcji w gotowe do produkcji aplikacje
- **ObsÅ‚uga bÅ‚Ä™dÃ³w**: implementacja solidnego zarzÄ…dzania bÅ‚Ä™dami i walidacji
- **Integracja narzÄ™dzi**: tworzenie wÅ‚asnych narzÄ™dzi rozszerzajÄ…cych moÅ¼liwoÅ›ci AI

### Kluczowe wnioski

> ğŸ¯ **PamiÄ™taj**: Frameworki AI takie jak LangChain to twoi najlepsi przyjaciele ukrywajÄ…cy zÅ‚oÅ¼onoÅ›Ä‡ i oferujÄ…cy wiele funkcji. SÄ… idealne, gdy potrzebujesz pamiÄ™ci rozmowy, wywoÅ‚ywania narzÄ™dzi lub chcesz pracowaÄ‡ z wieloma modelami AI bez utraty zdrowia psychicznego.

**Ramowy schemat decyzji przy integracji AI:**

```mermaid
flowchart TD
    A[Potrzeba integracji AI] --> B{Proste pojedyncze zapytanie?}
    B -->|Tak| C[BezpoÅ›rednie wywoÅ‚ania API]
    B -->|Nie| D{Potrzebna pamiÄ™Ä‡ rozmowy?}
    D -->|Nie| E[Integracja SDK]
    D -->|Tak| F{Potrzebne narzÄ™dzia lub zaawansowane funkcje?}
    F -->|Nie| G[Framework z podstawowÄ… konfiguracjÄ…]
    F -->|Tak| H[PeÅ‚na implementacja frameworka]
    
    C --> I[Å»Ä…dania HTTP, minimalne zaleÅ¼noÅ›ci]
    E --> J[SDK dostawcy, specyficzne dla modelu]
    G --> K[Podstawowy czat LangChain]
    H --> L[LangChain z narzÄ™dziami, pamiÄ™ciÄ…, agentami]
```  
### Co dalej?

**Zacznij budowaÄ‡ juÅ¼ teraz:**
- WeÅº te koncepcje i stwÃ³rz coÅ›, co CIÄ˜ ekscytuje!
- Eksperymentuj z rÃ³Å¼nymi modelami AI przez LangChain â€“ to jak plac zabaw peÅ‚en modeli AI
- TwÃ³rz narzÄ™dzia rozwiÄ…zujÄ…ce rzeczywiste problemy, z ktÃ³rymi siÄ™ mierzasz w pracy lub projektach

**Gotowy na kolejny poziom?**
- **Agenci AI**: Buduj systemy AI, ktÃ³re potrafiÄ… samodzielnie planowaÄ‡ i wykonywaÄ‡ zÅ‚oÅ¼one zadania
- **RAG (retrieval-augmented generation)**: PoÅ‚Ä…cz AI z wÅ‚asnymi bazami wiedzy dla supermocy aplikacji
- **Multimodalne AI**: Pracuj jednoczeÅ›nie z tekstem, obrazami i dÅºwiÄ™kiem â€“ moÅ¼liwoÅ›ci sÄ… nieograniczone!
- **WdroÅ¼enie produkcyjne**: Naucz siÄ™ skalowaÄ‡ aplikacje AI i monitorowaÄ‡ je w rzeczywistym Å›wiecie

**DoÅ‚Ä…cz do spoÅ‚ecznoÅ›ci:**
- SpoÅ‚ecznoÅ›Ä‡ LangChain jest fantastyczna do pozostania na bieÅ¼Ä…co i nauki najlepszych praktyk
- GitHub Models daje dostÄ™p do najnowszych moÅ¼liwoÅ›ci AI â€“ idealne do eksperymentÃ³w
- Ä†wicz na rÃ³Å¼nych przypadkach uÅ¼ycia â€“ kaÅ¼dy projekt nauczy ciÄ™ czegoÅ› nowego

Masz teraz wiedzÄ™, by budowaÄ‡ inteligentne, konwersacyjne aplikacje, ktÃ³re pomagajÄ… ludziom rozwiÄ…zywaÄ‡ prawdziwe problemy. Jak rzemieÅ›lnicy renesansu Å‚Ä…czÄ…cy wizjÄ™ artystycznÄ… z umiejÄ™tnoÅ›ciami technicznymi, moÅ¼esz Å‚Ä…czyÄ‡ moÅ¼liwoÅ›ci AI z praktycznym zastosowaniem. Pytanie brzmi: co stworzysz? ğŸš€

## Wyzwanie GitHub Copilot Agent ğŸš€

UÅ¼yj trybu agenta, aby wykonaÄ‡ nastÄ™pujÄ…ce wyzwanie:

**Opis:** Zbuduj zaawansowanego asystenta przeglÄ…du kodu zasilanego AI, ktÃ³ry Å‚Ä…czy wiele funkcji LangChain, w tym wywoÅ‚ywanie narzÄ™dzi, ustrukturyzowane wyjÅ›cie i pamiÄ™Ä‡ rozmowy, by dostarczaÄ‡ kompleksowe opinie o przesÅ‚anych kodach.

**Prompt:** StwÃ³rz klasÄ™ CodeReviewAssistant, ktÃ³ra implementuje:
1. NarzÄ™dzie do analizy zÅ‚oÅ¼onoÅ›ci kodu i sugerowania ulepszeÅ„
2. NarzÄ™dzie do sprawdzania kodu wzglÄ™dem najlepszych praktyk
3. Ustrukturyzowane wyjÅ›cie za pomocÄ… modeli Pydantic dla spÃ³jnego formatu przeglÄ…du
4. PamiÄ™Ä‡ rozmowy do Å›ledzenia sesji przeglÄ…du
5. GÅ‚Ã³wny interfejs czatu obsÅ‚ugujÄ…cy przesyÅ‚anie kodu i dostarczajÄ…cy szczegÃ³Å‚owe, praktyczne uwagi

Asystent powinien potrafiÄ‡ recenzowaÄ‡ kod w wielu jÄ™zykach programowania, utrzymywaÄ‡ kontekst przez wiele przesÅ‚anych fragmentÃ³w w sesji oraz dostarczaÄ‡ zarÃ³wno podsumowujÄ…ce oceny, jak i szczegÃ³Å‚owe sugestie ulepszeÅ„.

Dowiedz siÄ™ wiÄ™cej o [trybie agenta](https://code.visualstudio.com/blogs/2025/02/24/introducing-copilot-agent-mode) tutaj.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**ZastrzeÅ¼enie**:
Niniejszy dokument zostaÅ‚ przetÅ‚umaczony za pomocÄ… automatycznej usÅ‚ugi tÅ‚umaczeniowej AI [Co-op Translator](https://github.com/Azure/co-op-translator). Mimo Å¼e dÄ…Å¼ymy do dokÅ‚adnoÅ›ci, prosimy mieÄ‡ na uwadze, Å¼e tÅ‚umaczenia automatyczne mogÄ… zawieraÄ‡ bÅ‚Ä™dy lub nieÅ›cisÅ‚oÅ›ci. Oryginalny dokument w jÄ™zyku ÅºrÃ³dÅ‚owym powinien byÄ‡ uznawany za wiarygodne ÅºrÃ³dÅ‚o. W przypadku informacji istotnych zalecane jest skorzystanie z profesjonalnego tÅ‚umaczenia wykonanego przez czÅ‚owieka. Nie ponosimy odpowiedzialnoÅ›ci za jakiekolwiek nieporozumienia lub bÅ‚Ä™dne interpretacje wynikajÄ…ce z korzystania z tego tÅ‚umaczenia.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->