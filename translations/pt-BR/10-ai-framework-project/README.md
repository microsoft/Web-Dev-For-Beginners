# Framework de IA

J√° se sentiu sobrecarregado ao tentar construir aplica√ß√µes de IA do zero? Voc√™ n√£o est√° sozinho! Frameworks de IA s√£o como um canivete su√≠√ßo para o desenvolvimento de IA - ferramentas poderosas que podem economizar tempo e evitar dores de cabe√ßa ao criar aplica√ß√µes inteligentes. Pense em um framework de IA como uma biblioteca bem organizada: ele fornece componentes pr√©-constru√≠dos, APIs padronizadas e abstra√ß√µes inteligentes para que voc√™ possa se concentrar em resolver problemas, em vez de lutar com detalhes de implementa√ß√£o.

Nesta li√ß√£o, vamos explorar como frameworks como o LangChain podem transformar tarefas complexas de integra√ß√£o de IA em c√≥digo limpo e leg√≠vel. Voc√™ descobrir√° como enfrentar desafios do mundo real, como acompanhar conversas, implementar chamadas de ferramentas e gerenciar diferentes modelos de IA por meio de uma interface unificada.

Ao final, voc√™ saber√° quando usar frameworks em vez de chamadas de API diretas, como utilizar suas abstra√ß√µes de forma eficaz e como construir aplica√ß√µes de IA prontas para uso no mundo real. Vamos explorar o que os frameworks de IA podem fazer pelos seus projetos.

## ‚ö° O que voc√™ pode fazer nos pr√≥ximos 5 minutos

**Caminho R√°pido para Desenvolvedores Ocupados**

```mermaid
flowchart LR
    A[‚ö° 5 minutes] --> B[Install LangChain]
    B --> C[Create ChatOpenAI client]
    C --> D[Send first prompt]
    D --> E[See framework power]
```

- **Minuto 1**: Instale o LangChain: `pip install langchain langchain-openai`
- **Minuto 2**: Configure seu token do GitHub e importe o cliente ChatOpenAI
- **Minuto 3**: Crie uma conversa simples com mensagens do sistema e do usu√°rio
- **Minuto 4**: Adicione uma ferramenta b√°sica (como uma fun√ß√£o de soma) e veja a chamada de ferramentas pela IA
- **Minuto 5**: Experimente a diferen√ßa entre chamadas de API diretas e abstra√ß√£o de frameworks

**C√≥digo de Teste R√°pido**:
```python
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini"
)

response = llm.invoke([
    SystemMessage(content="You are a helpful coding assistant"),
    HumanMessage(content="Explain Python functions briefly")
])
print(response.content)
```

**Por que isso importa**: Em 5 minutos, voc√™ experimentar√° como os frameworks de IA transformam integra√ß√µes complexas de IA em chamadas de m√©todo simples. Esta √© a base que alimenta aplica√ß√µes de IA em produ√ß√£o.

## Por que escolher um framework?

Ent√£o voc√™ est√° pronto para construir um aplicativo de IA - incr√≠vel! Mas aqui est√° o ponto: voc√™ tem v√°rios caminhos diferentes que pode seguir, e cada um tem seus pr√≥prios pr√≥s e contras. √â como escolher entre caminhar, andar de bicicleta ou dirigir para chegar a algum lugar - todos v√£o te levar l√°, mas a experi√™ncia (e o esfor√ßo) ser√° totalmente diferente.

Vamos dividir as tr√™s principais maneiras de integrar IA em seus projetos:

| Abordagem | Vantagens | Melhor Para | Considera√ß√µes |
|----------|------------|----------|--------------|
| **Requisi√ß√µes HTTP Diretas** | Controle total, sem depend√™ncias | Consultas simples, aprender fundamentos | C√≥digo mais verboso, tratamento de erros manual |
| **Integra√ß√£o com SDK** | Menos boilerplate, otimiza√ß√£o espec√≠fica do modelo | Aplica√ß√µes de modelo √∫nico | Limitado a provedores espec√≠ficos |
| **Frameworks de IA** | API unificada, abstra√ß√µes integradas | Aplica√ß√µes multi-modelo, fluxos de trabalho complexos | Curva de aprendizado, poss√≠vel superabstra√ß√£o |

### Benef√≠cios dos Frameworks na Pr√°tica

```mermaid
graph TD
    A[Your Application] --> B[AI Framework]
    B --> C[OpenAI GPT]
    B --> D[Anthropic Claude]
    B --> E[GitHub Models]
    B --> F[Local Models]
    
    B --> G[Built-in Tools]
    G --> H[Memory Management]
    G --> I[Conversation History]
    G --> J[Function Calling]
    G --> K[Error Handling]
```

**Por que os frameworks s√£o importantes:**
- **Unifica** v√°rios provedores de IA em uma √∫nica interface
- **Gerencia** mem√≥ria de conversa√ß√£o automaticamente
- **Fornece** ferramentas prontas para tarefas comuns como embeddings e chamadas de fun√ß√µes
- **Lida** com tratamento de erros e l√≥gica de repeti√ß√£o
- **Transforma** fluxos de trabalho complexos em chamadas de m√©todo leg√≠veis

> üí° **Dica Profissional**: Use frameworks ao alternar entre diferentes modelos de IA ou ao construir recursos complexos como agentes, mem√≥ria ou chamadas de ferramentas. Fique com APIs diretas ao aprender o b√°sico ou ao construir aplica√ß√µes simples e focadas.

**Conclus√£o**: Como escolher entre ferramentas especializadas de um artes√£o e uma oficina completa, trata-se de combinar a ferramenta com a tarefa. Frameworks s√£o excelentes para aplica√ß√µes complexas e ricas em recursos, enquanto APIs diretas funcionam bem para casos de uso simples.

## üó∫Ô∏è Sua Jornada de Aprendizado na Maestria de Frameworks de IA

```mermaid
journey
    title From Raw APIs to Production AI Applications
    section Framework Foundations
      Understand abstraction benefits: 4: You
      Master LangChain basics: 6: You
      Compare approaches: 7: You
    section Conversation Systems
      Build chat interfaces: 5: You
      Implement memory patterns: 7: You
      Handle streaming responses: 8: You
    section Advanced Features
      Create custom tools: 6: You
      Master structured output: 8: You
      Build document systems: 8: You
    section Production Applications
      Combine all features: 7: You
      Handle error scenarios: 8: You
      Deploy complete systems: 9: You
```

**Destino da sua Jornada**: Ao final desta li√ß√£o, voc√™ ter√° dominado o desenvolvimento de frameworks de IA e ser√° capaz de construir aplica√ß√µes de IA sofisticadas e prontas para produ√ß√£o que rivalizam com assistentes de IA comerciais.

## Introdu√ß√£o

Nesta li√ß√£o, vamos aprender a:

- Usar um framework de IA comum.
- Resolver problemas comuns como conversas de chat, uso de ferramentas, mem√≥ria e contexto.
- Aproveitar isso para construir aplicativos de IA.

## üß† Ecossistema de Desenvolvimento de Frameworks de IA

```mermaid
mindmap
  root((AI Frameworks))
    Abstraction Benefits
      Code Simplification
        Unified APIs
        Built-in Error Handling
        Consistent Patterns
        Reduced Boilerplate
      Multi-Model Support
        Provider Agnostic
        Easy Switching
        Fallback Options
        Cost Optimization
    Core Components
      Conversation Management
        Message Types
        Memory Systems
        Context Tracking
        History Persistence
      Tool Integration
        Function Calling
        API Connections
        Custom Tools
        Workflow Automation
    Advanced Features
      Structured Output
        Pydantic Models
        JSON Schemas
        Type Safety
        Validation Rules
      Document Processing
        Embeddings
        Vector Stores
        Similarity Search
        RAG Systems
    Production Patterns
      Application Architecture
        Modular Design
        Error Boundaries
        Async Operations
        State Management
      Deployment Strategies
        Scalability
        Monitoring
        Performance
        Security
```

**Princ√≠pio Central**: Frameworks de IA abstraem a complexidade enquanto fornecem abstra√ß√µes poderosas para gerenciamento de conversas, integra√ß√£o de ferramentas e processamento de documentos, permitindo que desenvolvedores construam aplica√ß√µes de IA sofisticadas com c√≥digo limpo e f√°cil de manter.

## Seu primeiro prompt de IA

Vamos come√ßar com os fundamentos criando sua primeira aplica√ß√£o de IA que envia uma pergunta e recebe uma resposta. Como Arquimedes descobrindo o princ√≠pio do deslocamento em seu banho, √†s vezes as observa√ß√µes mais simples levam aos insights mais poderosos - e os frameworks tornam esses insights acess√≠veis.

### Configurando LangChain com Modelos do GitHub

Vamos usar o LangChain para conectar aos Modelos do GitHub, o que √© muito interessante porque oferece acesso gratuito a v√°rios modelos de IA. A melhor parte? Voc√™ s√≥ precisa de alguns par√¢metros de configura√ß√£o simples para come√ßar:

```python
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

# Send a simple prompt
response = llm.invoke("What's the capital of France?")
print(response.content)
```

**Vamos detalhar o que est√° acontecendo aqui:**
- **Cria** um cliente LangChain usando a classe `ChatOpenAI` - este √© seu portal para a IA!
- **Configura** a conex√£o com os Modelos do GitHub com seu token de autentica√ß√£o
- **Especifica** qual modelo de IA usar (`gpt-4o-mini`) - pense nisso como escolher seu assistente de IA
- **Envia** sua pergunta usando o m√©todo `invoke()` - √© aqui que a m√°gica acontece
- **Extrai** e exibe a resposta - e voil√†, voc√™ est√° conversando com a IA!

> üîß **Nota de Configura√ß√£o**: Se voc√™ estiver usando o GitHub Codespaces, est√° com sorte - o `GITHUB_TOKEN` j√° est√° configurado para voc√™! Trabalhando localmente? Sem problemas, voc√™ s√≥ precisar√° criar um token de acesso pessoal com as permiss√µes corretas.

**Sa√≠da esperada:**
```text
The capital of France is Paris.
```

```mermaid
sequenceDiagram
    participant App as Your Python App
    participant LC as LangChain
    participant GM as GitHub Models
    participant AI as GPT-4o-mini
    
    App->>LC: llm.invoke("What's the capital of France?")
    LC->>GM: HTTP request with prompt
    GM->>AI: Process prompt
    AI->>GM: Generated response
    GM->>LC: Return response
    LC->>App: response.content
```

## Construindo IA conversacional

Esse primeiro exemplo demonstra o b√°sico, mas √© apenas uma troca √∫nica - voc√™ faz uma pergunta, recebe uma resposta e pronto. Em aplica√ß√µes reais, voc√™ quer que sua IA se lembre do que voc√™ est√° discutindo, como Watson e Holmes constru√≠ram suas conversas investigativas ao longo do tempo.

√â aqui que o LangChain se torna particularmente √∫til. Ele fornece diferentes tipos de mensagens que ajudam a estruturar conversas e permitem que voc√™ d√™ uma personalidade √† sua IA. Voc√™ estar√° construindo experi√™ncias de chat que mant√™m contexto e car√°ter.

### Entendendo os tipos de mensagens

Pense nesses tipos de mensagens como diferentes "pap√©is" que os participantes desempenham em uma conversa. O LangChain usa diferentes classes de mensagens para acompanhar quem est√° dizendo o qu√™:

| Tipo de Mensagem | Prop√≥sito | Exemplo de Caso de Uso |
|------------------|-----------|------------------------|
| `SystemMessage` | Define a personalidade e o comportamento da IA | "Voc√™ √© um assistente de codifica√ß√£o √∫til" |
| `HumanMessage` | Representa a entrada do usu√°rio | "Explique como fun√ß√µes funcionam" |
| `AIMessage` | Armazena respostas da IA | Respostas anteriores da IA na conversa |

### Criando sua primeira conversa

Vamos criar uma conversa onde nossa IA assume um papel espec√≠fico. Vamos faz√™-la incorporar o Capit√£o Picard - um personagem conhecido por sua sabedoria diplom√°tica e lideran√ßa:

```python
messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]
```

**Detalhando esta configura√ß√£o de conversa:**
- **Estabelece** o papel e a personalidade da IA por meio de `SystemMessage`
- **Fornece** a consulta inicial do usu√°rio via `HumanMessage`
- **Cria** uma base para conversas de m√∫ltiplas intera√ß√µes

O c√≥digo completo para este exemplo √© assim:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]


# works
response  = llm.invoke(messages)
print(response.content)
```

Voc√™ deve ver um resultado semelhante a:

```text
I am Captain Jean-Luc Picard, the commanding officer of the USS Enterprise (NCC-1701-D), a starship in the United Federation of Planets. My primary mission is to explore new worlds, seek out new life and new civilizations, and boldly go where no one has gone before. 

I believe in the importance of diplomacy, reason, and the pursuit of knowledge. My crew is diverse and skilled, and we often face challenges that test our resolve, ethics, and ingenuity. Throughout my career, I have encountered numerous species, grappled with complex moral dilemmas, and have consistently sought peaceful solutions to conflicts.

I hold the ideals of the Federation close to my heart, believing in the importance of cooperation, understanding, and respect for all sentient beings. My experiences have shaped my leadership style, and I strive to be a thoughtful and just captain. How may I assist you further?
```

Para manter a continuidade da conversa (em vez de redefinir o contexto a cada vez), voc√™ precisa continuar adicionando respostas √† sua lista de mensagens. Como as tradi√ß√µes orais que preservaram hist√≥rias ao longo de gera√ß√µes, essa abordagem constr√≥i uma mem√≥ria duradoura:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]


# works
response  = llm.invoke(messages)

print(response.content)

print("---- Next ----")

messages.append(response)
messages.append(HumanMessage(content="Now that I know about you, I'm Chris, can I be in your crew?"))

response  = llm.invoke(messages)

print(response.content)

```

Bem legal, certo? O que est√° acontecendo aqui √© que estamos chamando o LLM duas vezes - primeiro com apenas nossas duas mensagens iniciais, mas depois novamente com todo o hist√≥rico da conversa. √â como se a IA estivesse realmente acompanhando nosso bate-papo!

Quando voc√™ executar este c√≥digo, receber√° uma segunda resposta que soa algo como:

```text
Welcome aboard, Chris! It's always a pleasure to meet those who share a passion for exploration and discovery. While I cannot formally offer you a position on the Enterprise right now, I encourage you to pursue your aspirations. We are always in need of talented individuals with diverse skills and backgrounds. 

If you are interested in space exploration, consider education and training in the sciences, engineering, or diplomacy. The values of curiosity, resilience, and teamwork are crucial in Starfleet. Should you ever find yourself on a starship, remember to uphold the principles of the Federation: peace, understanding, and respect for all beings. Your journey can lead you to remarkable adventures, whether in the stars or on the ground. Engage!
```

```mermaid
sequenceDiagram
    participant User
    participant App
    participant LangChain
    participant AI
    
    User->>App: "Tell me about you"
    App->>LangChain: [SystemMessage, HumanMessage]
    LangChain->>AI: Formatted conversation
    AI->>LangChain: Captain Picard response
    LangChain->>App: AIMessage object
    App->>User: Display response
    
    Note over App: Add AIMessage to conversation
    
    User->>App: "Can I join your crew?"
    App->>LangChain: [SystemMessage, HumanMessage, AIMessage, HumanMessage]
    LangChain->>AI: Full conversation context
    AI->>LangChain: Contextual response
    LangChain->>App: New AIMessage
    App->>User: Display contextual response
```

Vou considerar isso como um "talvez" ;)

## Respostas em streaming

J√° reparou como o ChatGPT parece "digitar" suas respostas em tempo real? Isso √© streaming em a√ß√£o. Como assistir a um cal√≠grafo habilidoso trabalhando - vendo os caracteres aparecerem tra√ßo por tra√ßo em vez de materializarem instantaneamente - o streaming torna a intera√ß√£o mais natural e fornece feedback imediato.

### Implementando streaming com LangChain

```python
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
    streaming=True
)

# Stream the response
for chunk in llm.stream("Write a short story about a robot learning to code"):
    print(chunk.content, end="", flush=True)
```

**Por que o streaming √© incr√≠vel:**
- **Mostra** o conte√∫do enquanto est√° sendo criado - nada de espera constrangedora!
- **Faz** os usu√°rios sentirem que algo est√° realmente acontecendo
- **Parece** mais r√°pido, mesmo quando tecnicamente n√£o √©
- **Permite** que os usu√°rios comecem a ler enquanto a IA ainda est√° "pensando"

> üí° **Dica de Experi√™ncia do Usu√°rio**: O streaming realmente brilha quando voc√™ est√° lidando com respostas mais longas, como explica√ß√µes de c√≥digo, escrita criativa ou tutoriais detalhados. Seus usu√°rios v√£o adorar ver o progresso em vez de encarar uma tela em branco!

### üéØ Verifica√ß√£o Pedag√≥gica: Benef√≠cios da Abstra√ß√£o de Frameworks

**Pausa e Reflex√£o**: Voc√™ acabou de experimentar o poder das abstra√ß√µes de frameworks de IA. Compare o que aprendeu com chamadas de API diretas de li√ß√µes anteriores.

**Autoavalia√ß√£o R√°pida**:
- Voc√™ consegue explicar como o LangChain simplifica o gerenciamento de conversas em compara√ß√£o com o rastreamento manual de mensagens?
- Qual √© a diferen√ßa entre os m√©todos `invoke()` e `stream()`, e quando voc√™ usaria cada um?
- Como o sistema de tipos de mensagens do framework melhora a organiza√ß√£o do c√≥digo?

**Conex√£o com o Mundo Real**: Os padr√µes de abstra√ß√£o que voc√™ aprendeu (tipos de mensagens, interfaces de streaming, mem√≥ria de conversa√ß√£o) s√£o usados em todas as principais aplica√ß√µes de IA - desde a interface do ChatGPT at√© a assist√™ncia de c√≥digo do GitHub Copilot. Voc√™ est√° dominando os mesmos padr√µes arquitet√¥nicos usados por equipes profissionais de desenvolvimento de IA.

**Pergunta Desafiadora**: Como voc√™ projetaria uma abstra√ß√£o de framework para lidar com diferentes provedores de modelos de IA (OpenAI, Anthropic, Google) com uma √∫nica interface? Considere os benef√≠cios e as desvantagens.

## Templates de prompts

Templates de prompts funcionam como as estruturas ret√≥ricas usadas na orat√≥ria cl√°ssica - pense em como C√≠cero adaptaria seus padr√µes de discurso para diferentes p√∫blicos enquanto mantinha o mesmo framework persuasivo. Eles permitem criar prompts reutiliz√°veis onde voc√™ pode trocar diferentes partes de informa√ß√£o sem reescrever tudo do zero. Depois de configurar o template, basta preencher as vari√°veis com os valores necess√°rios.

### Criando prompts reutiliz√°veis

```python
from langchain_core.prompts import ChatPromptTemplate

# Define a template for code explanations
template = ChatPromptTemplate.from_messages([
    ("system", "You are an expert programming instructor. Explain concepts clearly with examples."),
    ("human", "Explain {concept} in {language} with a practical example for {skill_level} developers")
])

# Use the template with different values
questions = [
    {"concept": "functions", "language": "JavaScript", "skill_level": "beginner"},
    {"concept": "classes", "language": "Python", "skill_level": "intermediate"},
    {"concept": "async/await", "language": "JavaScript", "skill_level": "advanced"}
]

for question in questions:
    prompt = template.format_messages(**question)
    response = llm.invoke(prompt)
    print(f"Topic: {question['concept']}\n{response.content}\n---\n")
```

**Por que voc√™ vai adorar usar templates:**
- **Mant√©m** seus prompts consistentes em todo o aplicativo
- **Nada de** concatena√ß√£o de strings bagun√ßada - apenas vari√°veis limpas e simples
- **Sua IA** se comporta de forma previs√≠vel porque a estrutura permanece a mesma
- **Atualiza√ß√µes** s√£o f√°ceis - altere o template uma vez e estar√° corrigido em todos os lugares

## Sa√≠da estruturada

J√° ficou frustrado tentando analisar respostas de IA que chegam como texto n√£o estruturado? Sa√≠da estruturada √© como ensinar sua IA a seguir a abordagem sistem√°tica que Lineu usou para classifica√ß√£o biol√≥gica - organizada, previs√≠vel e f√°cil de trabalhar. Voc√™ pode solicitar JSON, estruturas de dados espec√≠ficas ou qualquer formato necess√°rio.

### Definindo esquemas de sa√≠da

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel, Field

class CodeReview(BaseModel):
    score: int = Field(description="Code quality score from 1-10")
    strengths: list[str] = Field(description="List of code strengths")
    improvements: list[str] = Field(description="List of suggested improvements")
    overall_feedback: str = Field(description="Summary feedback")

# Set up the parser
parser = JsonOutputParser(pydantic_object=CodeReview)

# Create prompt with format instructions
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a code reviewer. {format_instructions}"),
    ("human", "Review this code: {code}")
])

# Format the prompt with instructions
chain = prompt | llm | parser

# Get structured response
code_sample = """
def calculate_average(numbers):
    return sum(numbers) / len(numbers)
"""

result = chain.invoke({
    "code": code_sample,
    "format_instructions": parser.get_format_instructions()
})

print(f"Score: {result['score']}")
print(f"Strengths: {', '.join(result['strengths'])}")
```

**Por que sa√≠da estruturada √© um divisor de √°guas:**
- **Nada de** adivinhar o formato que voc√™ receber√° - √© consistente todas as vezes
- **Conecta-se** diretamente aos seus bancos de dados e APIs sem trabalho extra
- **Detecta** respostas estranhas da IA antes que elas quebrem seu aplicativo
- **Torna** seu c√≥digo mais limpo porque voc√™ sabe exatamente com o que est√° lidando

## Chamadas de ferramentas

Agora chegamos a um dos recursos mais poderosos: ferramentas. √â assim que voc√™ d√° √† sua IA capacidades pr√°ticas al√©m da conversa. Como as guildas medievais desenvolveram ferramentas especializadas para of√≠cios espec√≠ficos, voc√™ pode equipar sua IA com instrumentos focados. Voc√™ descreve quais ferramentas est√£o dispon√≠veis e, quando algu√©m solicita algo que corresponda, sua IA pode agir.

### Usando Python

Vamos adicionar algumas ferramentas assim:

```python
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

tools = [add]

functions = {
    "add": lambda a, b: a + b
}
```

Ent√£o, o que est√° acontecendo aqui? Estamos criando um modelo para uma ferramenta chamada `add`. Ao herdar de `TypedDict` e usar esses tipos elegantes `Annotated` para `a` e `b`, estamos dando ao LLM uma imagem clara do que essa ferramenta faz e do que ela precisa. O dicion√°rio `functions` √© como nossa caixa de ferramentas - ele informa ao c√≥digo exatamente o que fazer quando a IA decide usar uma ferramenta espec√≠fica.

Vamos ver como chamamos o LLM com essa ferramenta a seguir:

```python
llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)
```

Aqui chamamos `bind_tools` com nosso array `tools` e, assim, o LLM `llm_with_tools` agora tem conhecimento dessa ferramenta.

Para usar esse novo LLM, podemos digitar o seguinte c√≥digo:

```python
query = "What is 3 + 12?"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

Agora que chamamos `invoke` nesse novo LLM, que tem ferramentas, talvez a propriedade `tool_calls` seja preenchida. Se for, qualquer ferramenta identificada ter√° uma propriedade `name` e `args` que identifica qual ferramenta deve ser chamada e com quais argumentos. O c√≥digo completo √© assim:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

tools = [add]

functions = {
    "add": lambda a, b: a + b
}

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)

query = "What is 3 + 12?"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

Ao executar este c√≥digo, voc√™ deve ver uma sa√≠da semelhante a:

```text
TOOL CALL:  15
CONTENT: 
```

A IA examinou "Qual √© 3 + 12" e reconheceu isso como uma tarefa para a ferramenta `add`. Como um bibliotec√°rio habilidoso sabe qual refer√™ncia consultar com base no tipo de pergunta feita, ela fez essa determina√ß√£o a partir do nome, descri√ß√£o e especifica√ß√µes de campo da ferramenta. O resultado de 15 vem do nosso dicion√°rio `functions` executando a ferramenta:

```python
print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
```

### Uma ferramenta mais interessante que chama uma API web
Adicionar n√∫meros demonstra o conceito, mas ferramentas reais geralmente realizam opera√ß√µes mais complexas, como chamar APIs da web. Vamos expandir nosso exemplo para que a IA busque conte√∫do da internet - semelhante a como operadores de tel√©grafo conectavam locais distantes:

```python
class joke(TypedDict):
    """Tell a joke."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    category: Annotated[str, ..., "The joke category"]

def get_joke(category: str) -> str:
    response = requests.get(f"https://api.chucknorris.io/jokes/random?category={category}", headers={"Accept": "application/json"})
    if response.status_code == 200:
        return response.json().get("value", f"Here's a {category} joke!")
    return f"Here's a {category} joke!"

functions = {
    "add": lambda a, b: a + b,
    "joke": lambda category: get_joke(category)
}

query = "Tell me a joke about animals"

# the rest of the code is the same
```

Agora, se voc√™ executar este c√≥digo, receber√° uma resposta dizendo algo como:

```text
TOOL CALL:  Chuck Norris once rode a nine foot grizzly bear through an automatic car wash, instead of taking a shower.
CONTENT:  
```

```mermaid
flowchart TD
    A[User Query: "Tell me a joke about animals"] --> B[LangChain Analysis]
    B --> C{Tool Available?}
    C -->|Yes| D[Select joke tool]
    C -->|No| E[Generate direct response]
    
    D --> F[Extract Parameters]
    F --> G[Call joke(category="animals")]
    G --> H[API Request to chucknorris.io]
    H --> I[Return joke content]
    I --> J[Display to user]
    
    E --> K[AI-generated response]
    K --> J
    
    subgraph "Tool Definition Layer"
        L[TypedDict Schema]
        M[Function Implementation]
        N[Parameter Validation]
    end
    
    D --> L
    F --> N
    G --> M
```

Aqui est√° o c√≥digo completo:

```python
from langchain_openai import ChatOpenAI
import requests
import os
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

class joke(TypedDict):
    """Tell a joke."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    category: Annotated[str, ..., "The joke category"]

tools = [add, joke]

def get_joke(category: str) -> str:
    response = requests.get(f"https://api.chucknorris.io/jokes/random?category={category}", headers={"Accept": "application/json"})
    if response.status_code == 200:
        return response.json().get("value", f"Here's a {category} joke!")
    return f"Here's a {category} joke!"

functions = {
    "add": lambda a, b: a + b,
    "joke": lambda category: get_joke(category)
}

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)

query = "Tell me a joke about animals"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        # print("TOOL CALL: ", tool)
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

## Embeddings e processamento de documentos

Embeddings representam uma das solu√ß√µes mais elegantes na IA moderna. Imagine se voc√™ pudesse pegar qualquer texto e convert√™-lo em coordenadas num√©ricas que capturam seu significado. √â exatamente isso que os embeddings fazem - transformam texto em pontos em um espa√ßo multidimensional onde conceitos semelhantes se agrupam. √â como ter um sistema de coordenadas para ideias, semelhante a como Mendeleev organizou a tabela peri√≥dica com base nas propriedades at√¥micas.

### Criando e usando embeddings

```python
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter

# Initialize embeddings
embeddings = OpenAIEmbeddings(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="text-embedding-3-small"
)

# Load and split documents
loader = TextLoader("documentation.txt")
documents = loader.load()

text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(documents)

# Create vector store
vectorstore = FAISS.from_documents(texts, embeddings)

# Perform similarity search
query = "How do I handle user authentication?"
similar_docs = vectorstore.similarity_search(query, k=3)

for doc in similar_docs:
    print(f"Relevant content: {doc.page_content[:200]}...")
```

### Carregadores de documentos para v√°rios formatos

```python
from langchain_community.document_loaders import (
    PyPDFLoader,
    CSVLoader,
    JSONLoader,
    WebBaseLoader
)

# Load different document types
pdf_loader = PyPDFLoader("manual.pdf")
csv_loader = CSVLoader("data.csv")
json_loader = JSONLoader("config.json")
web_loader = WebBaseLoader("https://example.com/docs")

# Process all documents
all_documents = []
for loader in [pdf_loader, csv_loader, json_loader, web_loader]:
    docs = loader.load()
    all_documents.extend(docs)
```

**O que voc√™ pode fazer com embeddings:**
- **Construir** buscas que realmente entendem o que voc√™ quer dizer, n√£o apenas correspond√™ncia de palavras-chave
- **Criar** IA que pode responder perguntas sobre seus documentos
- **Fazer** sistemas de recomenda√ß√£o que sugerem conte√∫do verdadeiramente relevante
- **Organizar automaticamente** e categorizar seu conte√∫do

```mermaid
flowchart LR
    A[Documents] --> B[Text Splitter]
    B --> C[Create Embeddings]
    C --> D[Vector Store]
    
    E[User Query] --> F[Query Embedding]
    F --> G[Similarity Search]
    G --> D
    D --> H[Relevant Documents]
    H --> I[AI Response]
    
    subgraph "Vector Space"
        J[Document A: [0.1, 0.8, 0.3...]]
        K[Document B: [0.2, 0.7, 0.4...]]
        L[Query: [0.15, 0.75, 0.35...]]
    end
    
    C --> J
    C --> K
    F --> L
    G --> J
    G --> K
```

## Construindo uma aplica√ß√£o completa de IA

Agora vamos integrar tudo o que voc√™ aprendeu em uma aplica√ß√£o abrangente - um assistente de codifica√ß√£o que pode responder perguntas, usar ferramentas e manter mem√≥ria de conversa√ß√£o. Assim como a prensa de impress√£o combinou tecnologias existentes (tipo m√≥vel, tinta, papel e press√£o) em algo transformador, vamos combinar nossos componentes de IA em algo pr√°tico e √∫til.

### Exemplo de aplica√ß√£o completa

```python
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_community.vectorstores import FAISS
from typing_extensions import Annotated, TypedDict
import os
import requests

class CodingAssistant:
    def __init__(self):
        self.llm = ChatOpenAI(
            api_key=os.environ["GITHUB_TOKEN"],
            base_url="https://models.github.ai/inference",
            model="openai/gpt-4o-mini"
        )
        
        self.conversation_history = [
            SystemMessage(content="""You are an expert coding assistant. 
            Help users learn programming concepts, debug code, and write better software.
            Use tools when needed and maintain a helpful, encouraging tone.""")
        ]
        
        # Define tools
        self.setup_tools()
    
    def setup_tools(self):
        class web_search(TypedDict):
            """Search for programming documentation or examples."""
            query: Annotated[str, "Search query for programming help"]
        
        class code_formatter(TypedDict):
            """Format and validate code snippets."""
            code: Annotated[str, "Code to format"]
            language: Annotated[str, "Programming language"]
        
        self.tools = [web_search, code_formatter]
        self.llm_with_tools = self.llm.bind_tools(self.tools)
    
    def chat(self, user_input: str):
        # Add user message to conversation
        self.conversation_history.append(HumanMessage(content=user_input))
        
        # Get AI response
        response = self.llm_with_tools.invoke(self.conversation_history)
        
        # Handle tool calls if any
        if response.tool_calls:
            for tool_call in response.tool_calls:
                tool_result = self.execute_tool(tool_call)
                print(f"üîß Tool used: {tool_call['name']}")
                print(f"üìä Result: {tool_result}")
        
        # Add AI response to conversation
        self.conversation_history.append(response)
        
        return response.content
    
    def execute_tool(self, tool_call):
        tool_name = tool_call['name']
        args = tool_call['args']
        
        if tool_name == 'web_search':
            return f"Found documentation for: {args['query']}"
        elif tool_name == 'code_formatter':
            return f"Formatted {args['language']} code: {args['code'][:50]}..."
        
        return "Tool execution completed"

# Usage example
assistant = CodingAssistant()

print("ü§ñ Coding Assistant Ready! Type 'quit' to exit.\n")

while True:
    user_input = input("You: ")
    if user_input.lower() == 'quit':
        break
    
    response = assistant.chat(user_input)
    print(f"ü§ñ Assistant: {response}\n")
```

**Arquitetura da aplica√ß√£o:**

```mermaid
graph TD
    A[User Input] --> B[Coding Assistant]
    B --> C[Conversation Memory]
    B --> D[Tool Detection]
    B --> E[LLM Processing]
    
    D --> F[Web Search Tool]
    D --> G[Code Formatter Tool]
    
    E --> H[Response Generation]
    F --> H
    G --> H
    
    H --> I[User Interface]
    H --> C
```

**Principais recursos que implementamos:**
- **Lembra** toda a sua conversa para continuidade de contexto
- **Realiza a√ß√µes** atrav√©s de chamadas de ferramentas, n√£o apenas conversa
- **Segue** padr√µes de intera√ß√£o previs√≠veis
- **Gerencia** tratamento de erros e fluxos de trabalho complexos automaticamente

### üéØ Verifica√ß√£o Pedag√≥gica: Arquitetura de IA para Produ√ß√£o

**Compreens√£o da Arquitetura**: Voc√™ construiu uma aplica√ß√£o completa de IA que combina gerenciamento de conversa√ß√£o, chamadas de ferramentas e fluxos de trabalho estruturados. Isso representa o desenvolvimento de aplica√ß√µes de IA em n√≠vel de produ√ß√£o.

**Conceitos-chave dominados**:
- **Arquitetura baseada em classes**: Estrutura organizada e sustent√°vel para aplica√ß√µes de IA
- **Integra√ß√£o de ferramentas**: Funcionalidade personalizada al√©m da conversa
- **Gerenciamento de mem√≥ria**: Contexto persistente de conversa√ß√£o
- **Tratamento de erros**: Comportamento robusto da aplica√ß√£o

**Conex√£o com a ind√∫stria**: Os padr√µes de arquitetura que voc√™ implementou (classes de conversa√ß√£o, sistemas de ferramentas, gerenciamento de mem√≥ria) s√£o os mesmos usados em aplica√ß√µes de IA empresariais como o assistente de IA do Slack, GitHub Copilot e Microsoft Copilot. Voc√™ est√° construindo com pensamento arquitet√¥nico de n√≠vel profissional.

**Pergunta de Reflex√£o**: Como voc√™ estenderia esta aplica√ß√£o para lidar com m√∫ltiplos usu√°rios, armazenamento persistente ou integra√ß√£o com bancos de dados externos? Considere os desafios de escalabilidade e gerenciamento de estado.

## Tarefa: Construa seu pr√≥prio assistente de estudo com IA

**Objetivo**: Crie uma aplica√ß√£o de IA que ajude estudantes a aprender conceitos de programa√ß√£o fornecendo explica√ß√µes, exemplos de c√≥digo e question√°rios interativos.

### Requisitos

**Recursos principais (obrigat√≥rios):**
1. **Interface de conversa√ß√£o**: Implemente um sistema de chat que mantenha o contexto em v√°rias perguntas
2. **Ferramentas educacionais**: Crie pelo menos duas ferramentas que ajudem no aprendizado:
   - Ferramenta de explica√ß√£o de c√≥digo
   - Gerador de question√°rios sobre conceitos
3. **Aprendizado personalizado**: Use mensagens do sistema para adaptar respostas a diferentes n√≠veis de habilidade
4. **Formata√ß√£o de respostas**: Implemente sa√≠da estruturada para perguntas de question√°rio

### Etapas de implementa√ß√£o

**Etapa 1: Configure seu ambiente**
```bash
pip install langchain langchain-openai
```

**Etapa 2: Funcionalidade b√°sica de chat**
- Crie uma classe `StudyAssistant`
- Implemente mem√≥ria de conversa√ß√£o
- Adicione configura√ß√£o de personalidade para suporte educacional

**Etapa 3: Adicione ferramentas educacionais**
- **Explicador de C√≥digo**: Divide o c√≥digo em partes compreens√≠veis
- **Gerador de Question√°rios**: Cria perguntas sobre conceitos de programa√ß√£o
- **Rastreador de Progresso**: Acompanha os t√≥picos abordados

**Etapa 4: Recursos avan√ßados (opcional)**
- Implemente respostas em streaming para melhor experi√™ncia do usu√°rio
- Adicione carregamento de documentos para incorporar materiais de curso
- Crie embeddings para recupera√ß√£o de conte√∫do baseada em similaridade

### Crit√©rios de avalia√ß√£o

| Recurso               | Excelente (4) | Bom (3) | Satisfat√≥rio (2) | Precisa melhorar (1) |
|-----------------------|---------------|---------|------------------|-----------------------|
| **Fluxo de Conversa√ß√£o** | Respostas naturais e com contexto | Boa reten√ß√£o de contexto | Conversa b√°sica | Sem mem√≥ria entre trocas |
| **Integra√ß√£o de Ferramentas** | V√°rias ferramentas √∫teis funcionando perfeitamente | 2+ ferramentas implementadas corretamente | 1-2 ferramentas b√°sicas | Ferramentas n√£o funcionais |
| **Qualidade do C√≥digo** | Limpo, bem documentado, com tratamento de erros | Boa estrutura, alguma documenta√ß√£o | Funcionalidade b√°sica funciona | Estrutura ruim, sem tratamento de erros |
| **Valor Educacional** | Realmente √∫til para aprendizado, adaptativo | Bom suporte ao aprendizado | Explica√ß√µes b√°sicas | Benef√≠cio educacional limitado |

### Estrutura de c√≥digo de exemplo

```python
class StudyAssistant:
    def __init__(self, skill_level="beginner"):
        # Initialize LLM, tools, and conversation memory
        pass
    
    def explain_code(self, code, language):
        # Tool: Explain how code works
        pass
    
    def generate_quiz(self, topic, difficulty):
        # Tool: Create practice questions
        pass
    
    def chat(self, user_input):
        # Main conversation interface
        pass

# Example usage
assistant = StudyAssistant(skill_level="intermediate")
response = assistant.chat("Explain how Python functions work")
```

**Desafios b√¥nus:**
- Adicione capacidades de entrada/sa√≠da de voz
- Implemente uma interface web usando Streamlit ou Flask
- Crie uma base de conhecimento a partir de materiais de curso usando embeddings
- Adicione rastreamento de progresso e caminhos de aprendizado personalizados

## üìà Linha do tempo de dom√≠nio do desenvolvimento de frameworks de IA

```mermaid
timeline
    title Production AI Framework Development Journey
    
    section Framework Foundations
        Understanding Abstractions
            : Master framework vs API decisions
            : Learn LangChain core concepts
            : Implement message type systems
        
        Basic Integration
            : Connect to AI providers
            : Handle authentication
            : Manage configuration
    
    section Conversation Systems
        Memory Management
            : Build conversation history
            : Implement context tracking
            : Handle session persistence
        
        Advanced Interactions
            : Master streaming responses
            : Create prompt templates
            : Implement structured output
    
    section Tool Integration
        Custom Tool Development
            : Design tool schemas
            : Implement function calling
            : Handle external APIs
        
        Workflow Automation
            : Chain multiple tools
            : Create decision trees
            : Build agent behaviors
    
    section Production Applications
        Complete System Architecture
            : Combine all framework features
            : Implement error boundaries
            : Create maintainable code
        
        Enterprise Readiness
            : Handle scalability concerns
            : Implement monitoring
            : Build deployment strategies
```

**üéì Marco de Gradua√ß√£o**: Voc√™ dominou com sucesso o desenvolvimento de frameworks de IA usando as mesmas ferramentas e padr√µes que alimentam aplica√ß√µes modernas de IA. Essas habilidades representam o estado da arte no desenvolvimento de aplica√ß√µes de IA e preparam voc√™ para construir sistemas inteligentes de n√≠vel empresarial.

**üîÑ Capacidades de pr√≥ximo n√≠vel**:
- Pronto para explorar arquiteturas avan√ßadas de IA (agentes, sistemas multiagentes)
- Preparado para construir sistemas RAG com bancos de dados vetoriais
- Equipado para criar aplica√ß√µes de IA multimodais
- Base estabelecida para escalabilidade e otimiza√ß√£o de aplica√ß√µes de IA

## Resumo

üéâ Voc√™ agora dominou os fundamentos do desenvolvimento de frameworks de IA e aprendeu como construir aplica√ß√µes sofisticadas de IA usando LangChain. Como completar um aprendizado abrangente, voc√™ adquiriu um conjunto substancial de habilidades. Vamos revisar o que voc√™ conquistou.

### O que voc√™ aprendeu

**Conceitos principais do framework:**
- **Benef√≠cios do framework**: Entender quando escolher frameworks em vez de chamadas diretas de API
- **Fundamentos do LangChain**: Configurar e conectar modelos de IA
- **Tipos de mensagens**: Usar `SystemMessage`, `HumanMessage` e `AIMessage` para conversas estruturadas

**Recursos avan√ßados:**
- **Chamadas de ferramentas**: Criar e integrar ferramentas personalizadas para capacidades aprimoradas de IA
- **Mem√≥ria de conversa√ß√£o**: Manter o contexto em v√°rias intera√ß√µes
- **Respostas em streaming**: Implementar entrega de respostas em tempo real
- **Templates de prompts**: Construir prompts reutiliz√°veis e din√¢micos
- **Sa√≠da estruturada**: Garantir respostas consistentes e analis√°veis da IA
- **Embeddings**: Criar busca sem√¢ntica e capacidades de processamento de documentos

**Aplica√ß√µes pr√°ticas:**
- **Constru√ß√£o de aplicativos completos**: Combinar m√∫ltiplos recursos em aplica√ß√µes prontas para produ√ß√£o
- **Tratamento de erros**: Implementar gerenciamento robusto de erros e valida√ß√£o
- **Integra√ß√£o de ferramentas**: Criar ferramentas personalizadas que ampliam as capacidades da IA

### Principais aprendizados

> üéØ **Lembre-se**: Frameworks de IA como LangChain s√£o basicamente seus melhores amigos para esconder complexidade e oferecer recursos avan√ßados. Eles s√£o perfeitos quando voc√™ precisa de mem√≥ria de conversa√ß√£o, chamadas de ferramentas ou quer trabalhar com v√°rios modelos de IA sem perder a sanidade.

**Framework de decis√£o para integra√ß√£o de IA:**

```mermaid
flowchart TD
    A[AI Integration Need] --> B{Simple single query?}
    B -->|Yes| C[Direct API calls]
    B -->|No| D{Need conversation memory?}
    D -->|No| E[SDK Integration]
    D -->|Yes| F{Need tools or complex features?}
    F -->|No| G[Framework with basic setup]
    F -->|Yes| H[Full framework implementation]
    
    C --> I[HTTP requests, minimal dependencies]
    E --> J[Provider SDK, model-specific]
    G --> K[LangChain basic chat]
    H --> L[LangChain with tools, memory, agents]
```

### Para onde ir a partir daqui?

**Comece a construir agora mesmo:**
- Pegue esses conceitos e crie algo que te empolgue!
- Experimente diferentes modelos de IA atrav√©s do LangChain - √© como ter um playground de modelos de IA
- Crie ferramentas que resolvam problemas reais que voc√™ enfrenta no trabalho ou em projetos

**Pronto para o pr√≥ximo n√≠vel?**
- **Agentes de IA**: Construa sistemas de IA que possam planejar e executar tarefas complexas por conta pr√≥pria
- **RAG (Gera√ß√£o Aumentada por Recupera√ß√£o)**: Combine IA com suas pr√≥prias bases de conhecimento para aplica√ß√µes superpotentes
- **IA Multimodal**: Trabalhe com texto, imagens e √°udio juntos - as possibilidades s√£o infinitas!
- **Implanta√ß√£o em Produ√ß√£o**: Aprenda como escalar suas aplica√ß√µes de IA e monitor√°-las no mundo real

**Junte-se √† comunidade:**
- A comunidade LangChain √© fant√°stica para se manter atualizado e aprender as melhores pr√°ticas
- Modelos do GitHub oferecem acesso a capacidades de IA de ponta - perfeito para experimenta√ß√£o
- Continue praticando com diferentes casos de uso - cada projeto ensinar√° algo novo

Agora voc√™ tem o conhecimento para construir aplica√ß√µes inteligentes e conversacionais que podem ajudar as pessoas a resolver problemas reais. Como os artes√£os do Renascimento que combinavam vis√£o art√≠stica com habilidade t√©cnica, voc√™ agora pode unir as capacidades da IA com aplica√ß√µes pr√°ticas. A pergunta √©: o que voc√™ vai criar? üöÄ

## Desafio do Agente do GitHub Copilot üöÄ

Use o modo Agente para completar o seguinte desafio:

**Descri√ß√£o:** Construa um assistente avan√ßado de revis√£o de c√≥digo com IA que combine m√∫ltiplos recursos do LangChain, incluindo chamadas de ferramentas, sa√≠da estruturada e mem√≥ria de conversa√ß√£o para fornecer feedback abrangente sobre submiss√µes de c√≥digo.

**Prompt:** Crie uma classe CodeReviewAssistant que implemente:
1. Uma ferramenta para analisar a complexidade do c√≥digo e sugerir melhorias
2. Uma ferramenta para verificar o c√≥digo em rela√ß√£o √†s melhores pr√°ticas
3. Sa√≠da estruturada usando modelos Pydantic para formato consistente de revis√£o
4. Mem√≥ria de conversa√ß√£o para acompanhar sess√µes de revis√£o
5. Uma interface principal de chat que possa lidar com submiss√µes de c√≥digo e fornecer feedback detalhado e acion√°vel

O assistente deve ser capaz de revisar c√≥digo em v√°rias linguagens de programa√ß√£o, manter o contexto em v√°rias submiss√µes de c√≥digo em uma sess√£o e fornecer tanto pontua√ß√µes resumidas quanto sugest√µes detalhadas de melhorias.

Saiba mais sobre o [modo agente](https://code.visualstudio.com/blogs/2025/02/24/introducing-copilot-agent-mode) aqui.

---

**Aviso Legal**:  
Este documento foi traduzido usando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos pela precis√£o, esteja ciente de que tradu√ß√µes automatizadas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autoritativa. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional humana. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes do uso desta tradu√ß√£o.